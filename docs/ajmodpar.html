<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Análise de Dados Amostrais Complexos</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Análise de dados de pesquisas amostrais complexas.">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Análise de Dados Amostrais Complexos" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="Figuras/capa.png" />
  <meta property="og:description" content="Análise de dados de pesquisas amostrais complexas." />
  <meta name="github-repo" content="djalmapessoa/adac" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Análise de Dados Amostrais Complexos" />
  
  <meta name="twitter:description" content="Análise de dados de pesquisas amostrais complexas." />
  <meta name="twitter:image" content="Figuras/capa.png" />

<meta name="author" content="Djalma Pessoa e Pedro Nascimento Silva">


<meta name="date" content="2017-02-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="epa.html">
<link rel="next" href="modreg.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Análise de Dados Amostrais Complexos</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimentos"><i class="fa fa-check"></i>Agradecimentos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduc.html"><a href="introduc.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="introduc.html"><a href="introduc.html#motivacao"><i class="fa fa-check"></i><b>1.1</b> Motivação</a></li>
<li class="chapter" data-level="1.2" data-path="introduc.html"><a href="introduc.html#objetivos-do-livro"><i class="fa fa-check"></i><b>1.2</b> Objetivos do Livro</a></li>
<li class="chapter" data-level="1.3" data-path="introduc.html"><a href="introduc.html#epa"><i class="fa fa-check"></i><b>1.3</b> Laboratório de R do Capítulo 1.</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduc.html"><a href="introduc.html#estimativa-do-efeito-de-plano-amostral-epa"><i class="fa fa-check"></i><b>1.3.1</b> Estimativa do efeito de plano amostral (EPA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="refinf.html"><a href="refinf.html"><i class="fa fa-check"></i><b>2</b> Referencial para Inferência</a><ul>
<li class="chapter" data-level="2.1" data-path="refinf.html"><a href="refinf.html#classic"><i class="fa fa-check"></i><b>2.1</b> Modelagem - Primeiras Idéias</a><ul>
<li class="chapter" data-level="2.1.1" data-path="refinf.html"><a href="refinf.html#abordagem-1---modelagem-classica"><i class="fa fa-check"></i><b>2.1.1</b> Abordagem 1 - Modelagem Clássica</a></li>
<li class="chapter" data-level="2.1.2" data-path="refinf.html"><a href="refinf.html#abordagem-2---amostragem-probabilistica"><i class="fa fa-check"></i><b>2.1.2</b> Abordagem 2 - Amostragem Probabilística</a></li>
<li class="chapter" data-level="2.1.3" data-path="refinf.html"><a href="refinf.html#discussao-das-abordagens-1-e-2"><i class="fa fa-check"></i><b>2.1.3</b> Discussão das Abordagens 1 e 2</a></li>
<li class="chapter" data-level="2.1.4" data-path="refinf.html"><a href="refinf.html#modelsuperpop"><i class="fa fa-check"></i><b>2.1.4</b> Abordagem 3 - Modelagem de Superpopulação</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="refinf.html"><a href="refinf.html#fontes-de-variacao"><i class="fa fa-check"></i><b>2.2</b> Fontes de Variação</a></li>
<li class="chapter" data-level="2.3" data-path="refinf.html"><a href="refinf.html#modelos-de-superpopulacao"><i class="fa fa-check"></i><b>2.3</b> Modelos de Superpopulação</a></li>
<li class="chapter" data-level="2.4" data-path="refinf.html"><a href="refinf.html#planamo"><i class="fa fa-check"></i><b>2.4</b> Planejamento Amostral</a></li>
<li class="chapter" data-level="2.5" data-path="refinf.html"><a href="refinf.html#inform"><i class="fa fa-check"></i><b>2.5</b> Planos Amostrais Informativos e Ignoráveis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="capplanamo.html"><a href="capplanamo.html"><i class="fa fa-check"></i><b>3</b> Estimação Baseada no Plano Amostral</a><ul>
<li class="chapter" data-level="3.1" data-path="capplanamo.html"><a href="capplanamo.html#estimatotais"><i class="fa fa-check"></i><b>3.1</b> Estimação de Totais</a></li>
<li class="chapter" data-level="3.2" data-path="capplanamo.html"><a href="capplanamo.html#por-que-estimar-variancias"><i class="fa fa-check"></i><b>3.2</b> Por que Estimar Variâncias</a></li>
<li class="chapter" data-level="3.3" data-path="capplanamo.html"><a href="capplanamo.html#taylor"><i class="fa fa-check"></i><b>3.3</b> Linearização de Taylor para Estimar variâncias</a></li>
<li class="chapter" data-level="3.4" data-path="capplanamo.html"><a href="capplanamo.html#metodo-do-conglomerado-primario"><i class="fa fa-check"></i><b>3.4</b> Método do Conglomerado Primário</a></li>
<li class="chapter" data-level="3.5" data-path="capplanamo.html"><a href="capplanamo.html#metodos-de-replicacao"><i class="fa fa-check"></i><b>3.5</b> Métodos de Replicação</a></li>
<li class="chapter" data-level="3.6" data-path="capplanamo.html"><a href="capplanamo.html#laboratorio-de-r"><i class="fa fa-check"></i><b>3.6</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduc.html"><a href="introduc.html#epa"><i class="fa fa-check"></i><b>4</b> Efeitos do Plano Amostral</a><ul>
<li class="chapter" data-level="4.1" data-path="epa.html"><a href="epa.html"><i class="fa fa-check"></i><b>4.1</b> Introdução</a></li>
<li class="chapter" data-level="4.2" data-path="epa.html"><a href="epa.html#efeito-do-plano-amostral-epa-de-kish"><i class="fa fa-check"></i><b>4.2</b> Efeito do Plano Amostral (EPA) de Kish</a></li>
<li class="chapter" data-level="4.3" data-path="epa.html"><a href="epa.html#efeito-do-plano-amostral-ampliado"><i class="fa fa-check"></i><b>4.3</b> Efeito do Plano Amostral Ampliado</a></li>
<li class="chapter" data-level="4.4" data-path="epa.html"><a href="epa.html#intervalos-de-confianca-e-testes-de-hipoteses"><i class="fa fa-check"></i><b>4.4</b> Intervalos de Confiança e Testes de Hipóteses</a></li>
<li class="chapter" data-level="4.5" data-path="epa.html"><a href="epa.html#efeitos-multivariados-de-plano-amostral"><i class="fa fa-check"></i><b>4.5</b> Efeitos Multivariados de Plano Amostral</a></li>
<li class="chapter" data-level="4.6" data-path="epa.html"><a href="epa.html#laboratorio-de-r-1"><i class="fa fa-check"></i><b>4.6</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ajmodpar.html"><a href="ajmodpar.html"><i class="fa fa-check"></i><b>5</b> Ajuste de Modelos Paramétricos</a><ul>
<li class="chapter" data-level="5.1" data-path="ajmodpar.html"><a href="ajmodpar.html#modpar1"><i class="fa fa-check"></i><b>5.1</b> Introdução</a></li>
<li class="chapter" data-level="5.2" data-path="ajmodpar.html"><a href="ajmodpar.html#metodo-de-maxima-verossimilhanca-mv"><i class="fa fa-check"></i><b>5.2</b> Método de Máxima Verossimilhança (MV)</a></li>
<li class="chapter" data-level="5.3" data-path="ajmodpar.html"><a href="ajmodpar.html#ponderacao-de-dados-amostrais"><i class="fa fa-check"></i><b>5.3</b> Ponderação de Dados Amostrais</a></li>
<li class="chapter" data-level="5.4" data-path="ajmodpar.html"><a href="ajmodpar.html#modpar3"><i class="fa fa-check"></i><b>5.4</b> Método de Máxima Pseudo-Verossimilhança label</a></li>
<li class="chapter" data-level="5.5" data-path="ajmodpar.html"><a href="ajmodpar.html#robustez-do-procedimento-mpv"><i class="fa fa-check"></i><b>5.5</b> Robustez do Procedimento MPV</a></li>
<li class="chapter" data-level="5.6" data-path="ajmodpar.html"><a href="ajmodpar.html#desvantagens-da-inferencia-de-aleatorizacao"><i class="fa fa-check"></i><b>5.6</b> Desvantagens da Inferência de Aleatorização</a></li>
<li class="chapter" data-level="5.7" data-path="ajmodpar.html"><a href="ajmodpar.html#laboratorio-de-r-2"><i class="fa fa-check"></i><b>5.7</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="modreg.html"><a href="modreg.html"><i class="fa fa-check"></i><b>6</b> Modelos de Regressão</a><ul>
<li class="chapter" data-level="6.1" data-path="modreg.html"><a href="modreg.html#modlinear"><i class="fa fa-check"></i><b>6.1</b> Modelo de Regressão Linear Normal</a><ul>
<li class="chapter" data-level="6.1.1" data-path="modreg.html"><a href="modreg.html#especificacao-do-modelo"><i class="fa fa-check"></i><b>6.1.1</b> Especificação do Modelo</a></li>
<li class="chapter" data-level="6.1.2" data-path="modreg.html"><a href="modreg.html#pseudo-parametros-do-modelo"><i class="fa fa-check"></i><b>6.1.2</b> Pseudo-parâmetros do Modelo</a></li>
<li class="chapter" data-level="6.1.3" data-path="modreg.html"><a href="modreg.html#estimadores-de-mpv-dos-parametros-do-modelo"><i class="fa fa-check"></i><b>6.1.3</b> Estimadores de MPV dos Parâmetros do Modelo</a></li>
<li class="chapter" data-level="6.1.4" data-path="modreg.html"><a href="modreg.html#estimacao-da-variancia-de-estimadores-de-mpv"><i class="fa fa-check"></i><b>6.1.4</b> Estimação da Variância de Estimadores de MPV</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="modreg.html"><a href="modreg.html#modlogist"><i class="fa fa-check"></i><b>6.2</b> Modelo de Regressão Logística</a></li>
<li class="chapter" data-level="6.3" data-path="modreg.html"><a href="modreg.html#teste-de-hipoteses"><i class="fa fa-check"></i><b>6.3</b> Teste de Hipóteses</a></li>
<li class="chapter" data-level="6.4" data-path="modreg.html"><a href="modreg.html#laboratorio-de-r-3"><i class="fa fa-check"></i><b>6.4</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="testqualajust.html"><a href="testqualajust.html"><i class="fa fa-check"></i><b>7</b> Testes de Qualidade de Ajuste</a><ul>
<li class="chapter" data-level="7.1" data-path="testqualajust.html"><a href="testqualajust.html#introducao-1"><i class="fa fa-check"></i><b>7.1</b> Introdução</a></li>
<li class="chapter" data-level="7.2" data-path="testqualajust.html"><a href="testqualajust.html#teste-para-uma-proporcao"><i class="fa fa-check"></i><b>7.2</b> Teste para uma Proporção</a><ul>
<li class="chapter" data-level="7.2.1" data-path="testqualajust.html"><a href="testqualajust.html#correcao-de-estatisticas-classicas"><i class="fa fa-check"></i><b>7.2.1</b> Correção de Estatísticas Clássicas</a></li>
<li class="chapter" data-level="7.2.2" data-path="testqualajust.html"><a href="testqualajust.html#estatistica-de-wald"><i class="fa fa-check"></i><b>7.2.2</b> Estatística de Wald</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="testqualajust.html"><a href="testqualajust.html#teste-para-varias-proporcoes"><i class="fa fa-check"></i><b>7.3</b> Teste para Várias Proporções</a><ul>
<li class="chapter" data-level="7.3.1" data-path="testqualajust.html"><a href="testqualajust.html#estatistica-de-wald-baseada-no-plano-amostral"><i class="fa fa-check"></i><b>7.3.1</b> Estatística de Wald Baseada no Plano Amostral</a></li>
<li class="chapter" data-level="7.3.2" data-path="testqualajust.html"><a href="testqualajust.html#raoscott"><i class="fa fa-check"></i><b>7.3.2</b> Estatística de Pearson com Ajuste de Rao-Scott</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="testqualajust.html"><a href="testqualajust.html#laboratorio-de-r-4"><i class="fa fa-check"></i><b>7.4</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="testetab2.html"><a href="testetab2.html"><i class="fa fa-check"></i><b>8</b> Testes em Tabelas de Duas Entradas</a><ul>
<li class="chapter" data-level="8.1" data-path="testetab2.html"><a href="testetab2.html#introducao-2"><i class="fa fa-check"></i><b>8.1</b> Introdução</a></li>
<li class="chapter" data-level="8.2" data-path="testetab2.html"><a href="testetab2.html#tabelas22"><i class="fa fa-check"></i><b>8.2</b> Tabelas 2x2</a><ul>
<li class="chapter" data-level="8.2.1" data-path="testetab2.html"><a href="testetab2.html#teste-de-independencia"><i class="fa fa-check"></i><b>8.2.1</b> Teste de Independência</a></li>
<li class="chapter" data-level="8.2.2" data-path="testetab2.html"><a href="testetab2.html#teste-de-homogeneidade"><i class="fa fa-check"></i><b>8.2.2</b> Teste de Homogeneidade</a></li>
<li class="chapter" data-level="8.2.3" data-path="testetab2.html"><a href="testetab2.html#efeitos-de-plano-amostral-nas-celas"><i class="fa fa-check"></i><b>8.2.3</b> Efeitos de Plano Amostral nas Celas</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="testetab2.html"><a href="testetab2.html#tabelas-de-duas-entradas-caso-geral"><i class="fa fa-check"></i><b>8.3</b> Tabelas de Duas Entradas (Caso Geral)</a><ul>
<li class="chapter" data-level="8.3.1" data-path="testetab2.html"><a href="testetab2.html#teste-de-homogeneidade-1"><i class="fa fa-check"></i><b>8.3.1</b> Teste de Homogeneidade</a></li>
<li class="chapter" data-level="8.3.2" data-path="testetab2.html"><a href="testetab2.html#teste-de-independencia-1"><i class="fa fa-check"></i><b>8.3.2</b> Teste de Independência</a></li>
<li class="chapter" data-level="8.3.3" data-path="testetab2.html"><a href="testetab2.html#estatistica-de-wald-baseada-no-plano-amostral-1"><i class="fa fa-check"></i><b>8.3.3</b> Estatística de Wald Baseada no Plano Amostral</a></li>
<li class="chapter" data-level="8.3.4" data-path="testetab2.html"><a href="testetab2.html#estatistica-de-pearson-com-ajuste-de-rao-scott"><i class="fa fa-check"></i><b>8.3.4</b> Estatística de Pearson com Ajuste de Rao-Scott</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="testetab2.html"><a href="testetab2.html#laboratorio-de-r-5"><i class="fa fa-check"></i><b>8.4</b> Laboratório de R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimacao-de-densidades.html"><a href="estimacao-de-densidades.html"><i class="fa fa-check"></i><b>9</b> Estimação de densidades</a><ul>
<li class="chapter" data-level="9.1" data-path="estimacao-de-densidades.html"><a href="estimacao-de-densidades.html#introducao-3"><i class="fa fa-check"></i><b>9.1</b> Introdução</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelos-hierarquicos.html"><a href="modelos-hierarquicos.html"><i class="fa fa-check"></i><b>10</b> Modelos Hierárquicos</a><ul>
<li class="chapter" data-level="10.1" data-path="modelos-hierarquicos.html"><a href="modelos-hierarquicos.html#introducao-4"><i class="fa fa-check"></i><b>10.1</b> Introdução</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="nao-resposta.html"><a href="nao-resposta.html"><i class="fa fa-check"></i><b>11</b> Não-Resposta</a><ul>
<li class="chapter" data-level="11.1" data-path="nao-resposta.html"><a href="nao-resposta.html#introducao-5"><i class="fa fa-check"></i><b>11.1</b> Introdução</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="diagnostico-de-ajuste-de-modelo.html"><a href="diagnostico-de-ajuste-de-modelo.html"><i class="fa fa-check"></i><b>12</b> Diagnóstico de ajuste de modelo</a><ul>
<li class="chapter" data-level="12.1" data-path="diagnostico-de-ajuste-de-modelo.html"><a href="diagnostico-de-ajuste-de-modelo.html#introducao-6"><i class="fa fa-check"></i><b>12.1</b> Introdução</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="agregdesag.html"><a href="agregdesag.html"><i class="fa fa-check"></i><b>13</b> Agregação vs. Desagregação</a><ul>
<li class="chapter" data-level="13.1" data-path="agregdesag.html"><a href="agregdesag.html#introducao-7"><i class="fa fa-check"></i><b>13.1</b> Introdução</a></li>
<li class="chapter" data-level="13.2" data-path="agregdesag.html"><a href="agregdesag.html#modelagem-da-estrutura-populacional"><i class="fa fa-check"></i><b>13.2</b> Modelagem da Estrutura Populacional</a></li>
<li class="chapter" data-level="13.3" data-path="agregdesag.html"><a href="agregdesag.html#modelos-hierarquicos-1"><i class="fa fa-check"></i><b>13.3</b> Modelos Hierárquicos</a></li>
<li class="chapter" data-level="13.4" data-path="agregdesag.html"><a href="agregdesag.html#analise-desagregada-pros-e-contras"><i class="fa fa-check"></i><b>13.4</b> Análise Desagregada: Prós e Contras</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="pacotes.html"><a href="pacotes.html"><i class="fa fa-check"></i><b>14</b> Pacotes para Analisar Dados Amostrais</a><ul>
<li class="chapter" data-level="14.1" data-path="pacotes.html"><a href="pacotes.html#introducao-8"><i class="fa fa-check"></i><b>14.1</b> Introdução</a></li>
<li class="chapter" data-level="14.2" data-path="pacotes.html"><a href="pacotes.html#pacotes-computacionais"><i class="fa fa-check"></i><b>14.2</b> Pacotes Computacionais</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referências</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Análise de Dados Amostrais Complexos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ajmodpar" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Ajuste de Modelos Paramétricos</h1>
<div id="modpar1" class="section level2">
<h2><span class="header-section-number">5.1</span> Introdução</h2>
<p>Nos primórdios do uso <code>moderno</code> de pesquisas por amostragem, os dados obtidos eram usados principalmente para estimar funções simples dos valores das variáveis de interesse nas populações finitas, tais como totais, médias, razões, etc. Isto caracterizava o uso dos dados dessas pesquisas para <code>inferência descritiva</code>. Recentemente, os dados de pesquisas amostrais têm sido cada vez mais utilizados também para propósitos analíticos. <code>Inferências analíticas</code> baseadas numa pesquisa amostral são aquelas que envolvem a estimação de parâmetros num modelo (de superpopulação) <span class="citation">(Kalton <a href="#ref-kalton83b">1983</a><a href="#ref-kalton83b">b</a>)</span>; <span class="citation">(Binder et al. <a href="#ref-binder87">1987</a>)</span>.</p>
<p>Quando os valores <code>amostrais</code> das variáveis da pesquisa podem ser considerados como realizações de vetores aleatórios independentes e identicamente distribuídos (IID), modelos podem ser especificados, ajustados, testados e reformulados usando procedimentos estatísticos padrões como os apresentados, por exemplo, em <span class="citation">(Bickel and Doksum <a href="#ref-bickel">1977</a>)</span> e <span class="citation">(Garthwaite, Jollife, and Jones <a href="#ref-garthwaite">1995</a>)</span>. Neste caso, métodos e pacotes estatísticos padrões podem ser usados para executar os cálculos de estimativas de parâmetros e medidas de precisão correspondentes, bem como diagnóstico e verificação da adequação das hipóteses dos modelos.</p>
<p>Na prática das pesquisas amostrais, contudo, as hipóteses de modelo IID para as observações amostrais são raramente adequadas. Com maior frequência, modelos alternativos com hipóteses mais complexas e/ou estimadores especiais devem ser considerados a fim de acomodar aspectos da estrutura da população e/ou do plano amostral. Além disso, usualmente estão disponíveis informações sobre variáveis auxiliares, utilizadas ou não na especificação do plano amostral, que podem ser incorporadas com proveito na estima ção dos parâmetros ou na própria formulação do modelo.</p>
<p>Os exemplos apresentados no Capítulo <a href="introduc.html#epa">1.3</a> demonstram claramente a inadequa ção de ignorar o plano amostral ao efetuar análises de dados de pesquisas amostrais. Os valores dos EPAs calculados, tanto para estimadores de medidas descritivas tais como médias e totais, como para estatísticas analíticas usadas em testes de hipóteses e os correspondentes efeitos nos níveis de significância reais, revelam que ignorar o plano amostral pode levar a decisões erradas e a avaliações inadequadas da precisão das estimativas amostrais.</p>
<p>Embora as medidas propostas no Capítulo <a href="introduc.html#epa">1.3</a> para os efeitos de plano amostral sirvam para avaliar o impacto de ignorar o plano amostral nas inferências descritivas ou mesmo analíticas baseadas em dados amostrais, elas não resolvem o problema de como incorporar o plano amostral nessas análises. No caso das inferências descritivas usuais para médias, totais e proporções, o assunto é amplamente tratado na literatura de amostragem e o interessado em maiores detalhes pode consultar livros clássicos como <span class="citation">(Cochran <a href="#ref-cochran">1977</a>)</span>, ou mais recentes como <span class="citation">(Särndal, Swensson, and Wretman <a href="#ref-SSW92">1992</a>)</span>. Já os métodos requeridos para inferências analíticas só recentemente foram consolidados em livro (<span class="citation">(Skinner, Holt, and Smith <a href="#ref-SHS89">1989</a>)</span>). Este capítulo apresenta um dos métodos centrais disponíveis para ajuste de modelos paramétricos regulares considerando dados amostrais complexos, baseado no trabalho de <span class="citation">(Binder et al. <a href="#ref-binder87">1987</a>)</span>. Antes de descrever esse método, entretanto, fazemos breve discussão sobre o papel dos pesos na análise de dados amostrais, considerando o trabalho de <span class="citation">(Pfeffermann <a href="#ref-Pfeff">1993</a>)</span>.</p>
<p>Primeiramente, porém, fazemos uma revisão sucinta do método de Máxima Verossimilhança (MV) para ajustar modelos dentro da abordagem de modelagem clássica, necessária para compreensão adequada do material subseqüente. Essa revisão não pretende ser exaustiva ou detalhada, mas tão somente recordar os principais resultados aqui requeridos. Para uma discussão mais detalhada do método de Máxima Verossimilhança para estimação em modelos paramétricos regulares veja, por exemplo, <span class="citation">(Garthwaite, Jollife, and Jones <a href="#ref-garthwaite">1995</a>)</span>.</p>
</div>
<div id="metodo-de-maxima-verossimilhanca-mv" class="section level2">
<h2><span class="header-section-number">5.2</span> Método de Máxima Verossimilhança (MV)</h2>
<p>Seja <span class="math inline">\(\mathbf{y}_{i}=\left(y_{i1},\ldots,y_{iR}\right)&#39;\)</span> um vetor <span class="math inline">\(R\times 1\)</span> dos valores observados das variáveis de interesse observadas para a unidade <span class="math inline">\(i\)</span> da amostra, gerado por um vetor aleatório <span class="math inline">\(\mathbf{Y}_{i}\)</span>, para <span class="math inline">\(i=1,\ldots ,n\)</span>, onde <span class="math inline">\(n\)</span> é o tamanho da amostra. Suponha que os vetores aleatórios <span class="math inline">\(\mathbf{Y}_{i}\)</span>, para <span class="math inline">\(i=1,\ldots ,n\)</span> , são independentes e identicamente distribuídos (IID) com distribuição comum <span class="math inline">\(f(\mathbf{y};\mathbf{\theta })\)</span>, onde <span class="math inline">\(\mathbf{\theta}=\left( \theta _{1},\ldots ,\theta _{K}\right) ^{^{\prime }}\)</span> é um vetor <span class="math inline">\(K\times 1\)</span> de parâmetros desconhecidos de interesse. Sob essas hipóteses, a verossimilhança amostral é dada por <span class="math display">\[
l\left( \mathbf{\theta }\right) =\prod\limits_{i=1}^{n}f\left( \mathbf{y}
_{i};\mathbf{\theta }\right) 
\]</span> e a correspondente log-verossimilhança por <span class="math display">\[
L\left( \mathbf{\theta }\right) =\sum_{i=1}^n\log \left[
f\left( \mathbf{y}_{i};\mathbf{\theta }\right) \right] \;. 
\]</span></p>
<p>Calculando as derivadas parciais de <span class="math inline">\(L\left(\mathbf{\theta}\right)\)</span> com relação a cada componente de <span class="math inline">\(\mathbf{\theta }\)</span> e igualando a <span class="math inline">\(0\)</span>, obtemos um sistema de equações <span class="math display">\[
\partial L\left( \mathbf{\theta }\right) /\partial \mathbf{\theta }=
\sum_{i=1}^n\mathbf{u}_{i}\left( \mathbf{\theta }\right) =\mathbf{0}, 
\]</span></p>
<p>onde, <span class="math inline">\(\mathbf{u}_{i}\left(\mathbf{\theta }\right) =\partial\log\left[f\left(\mathbf{y}_{i};\mathbf{\theta}\right) \right] /\partial \mathbf{\theta }\)</span> é o vetor dos escores da unidade <span class="math inline">\(i\)</span>, de dimensão <span class="math inline">\(K\times1\)</span>.</p>
<p>Sob condições de regularidade p. 281 <span class="citation">(Cox and Hinkley <a href="#ref-cox">1974</a>)</span>, a solução <span class="math inline">\(\mathbf{\hat{\theta}}\)</span> deste sistema de equações é o <strong>Estimador de Máxima Verossimilhança (EMV)</strong> de <span class="math inline">\(\mathbf{\theta}\)</span>. A variância assintótica do estimador <span class="math inline">\(\mathbf{\hat{\theta}}\)</span> sob o modelo adotado, denominado aqui abreviadamente modelo $M $, é dada por <span class="math display">\[
V_{M}\left( \mathbf{\hat{\theta}}\right) \simeq \left[ J\left( \mathbf{
\theta }\right) \right] ^{-1} 
\]</span> e um estimador consistente dessa variância é dado por <span class="math display">\[
\hat{V}_{M}\left( \mathbf{\hat{\theta}}\right) =\left[ J\left( \mathbf{\hat{
\theta}}\right) \right] ^{-1}\;, 
\]</span> onde <span class="math display">\[
J\left( \mathbf{\theta }\right) =\sum\limits_{i=1}^{n}\partial \mathbf{u}
_{i}\left( \mathbf{\theta }\right) /\partial \mathbf{\theta } 
\]</span> e <span class="math display">\[
J\left( \mathbf{\hat{\theta}}\right) =\left. J\left( \mathbf{\theta }\right)
\right| _{\mathbf{\theta =\hat{\theta}}}\;. 
\]</span></p>
</div>
<div id="ponderacao-de-dados-amostrais" class="section level2">
<h2><span class="header-section-number">5.3</span> Ponderação de Dados Amostrais</h2>
<p>O papel da ponderação <code>na análise de dados amostrais</code> é alvo de controvérsia entre os estatísticos. Apesar de incorporada comumente na inferência descritiva, não há concordância com respeito a seu uso na inferência analítica, havendo um espectro de opiniões entre dois extremos. Num extremo estão os <code>modelistas</code>, que consideram o uso de pesos irrelevante, e no outro os <code>amostristas</code>, que incorporam pesos em qualquer análise.</p>

<div class="example">
<span id="ex:unnamed-chunk-47" class="example"><strong>Exemplo 5.1 </strong></span>Uso analítico dos dados da Pesquisa Nacional por Amostra de Domicílios (PNAD)
</div>
<p></p>
<p>A título de ilustração, consideremos uma pesquisa com uma amostra complexa como a da PNAD do IBGE, que emprega uma amostra estratificada de domicílios em três estágios, tendo como unidades primárias de amostragem (UPAs) os municípios, que são estratificados segundo as unidades da federação (UFs), e regiões menores dentro das UFs (veja IBGE, 1981, p. 67).</p>
<p>A seleção de municípios dentro de cada estrato é feita com probabilidades desiguais, proporcionais ao tamanho, havendo inclusive municípios incluídos na amostra com certeza (chamados de municípios auto-representativos). Da mesma forma, a seleção de setores (unidades secundárias de amostragem ou USAs) dentro de cada município é feita com probabilidades proporcionais ao número de domicílios em cada setor segundo o último censo disponível. Dentro de cada setor, a seleção de domicílios é feita por amostragem sistemática simples (portanto, com eqüiprobabilidade). Todas as pessoas moradoras em cada domicílio da amostra são pesquisadas.</p>
<p>A amostra de domicílios e de pessoas dentro de cada estrato é <code>autoponderada</code>, isto é, tal que todos os domicílios e pessoas dentro de um mesmo estrato têm igual probabilidade de seleção. Entretanto, as probabilidades de inclusão (e conseqüentemente os pesos) variam bastante entre as várias regiões de pesquisa. A Tabela <a href="ajmodpar.html#tab:proselpnad">5.1</a> revela como variam essas probabilidades de seleção entre as regiões cobertas pela amostra da PNAD de 93. Como se pode observar, tais probabilidades de inclusão chegam a ser <span class="math inline">\(5\)</span> vezes maiores em Belém do que em São Paulo, e portanto variação semelhante será observada nos pesos.</p>
<!-- \begin{center} -->
<!-- \begin{table}[tbp] \centering -->
<!-- \caption{Probabilidades de seleção da amostra da PNAD de 1993 segundo -->
<!-- regiões }\bigskip \label{tab51}  -->
<!-- \begin{tabular}{|c|c|} -->
<!-- \hline\hline -->
<!-- Região da pesquisa &  -->
<!-- \begin{tabular}{l} -->
<!-- Probabilidade \\  -->
<!-- de seleção -->
<!-- \end{tabular} -->
<!-- \\ \hline\hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- RM de Belém -->
<!-- \end{tabular} -->
<!-- } & $1/150$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- RMs de Fortaleza, Recife, Salvador e Porto Alegre \\  -->
<!-- Distrito Federal -->
<!-- \end{tabular} -->
<!-- } & $1/200$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- RMs de Belo Horizonte e Curitiba -->
<!-- \end{tabular} -->
<!-- } & $1/250$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- Rond\^{o}nia, Acre, Amazonas, Roraima, Amapá, \\  -->
<!-- Tocantins, Sergipe, Mato Grosso do Sul, \\  -->
<!-- Mato Grosso e Goiás -->
<!-- \end{tabular} -->
<!-- } & $1/300$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- Pará -->
<!-- \end{tabular} -->
<!-- } & $1/350$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- RM do Rio de Janeiro, Piauí, Ceará, \\  -->
<!-- Rio Grande do Norte, Paraíba, Pernambuco, \\  -->
<!-- Alagoas, Bahia, Minas Gerais, \\  -->
<!-- Espírito Santo e Rio de Janeiro -->
<!-- \end{tabular} -->
<!-- } & $1/500$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- Paraná, Santa Catarina, Rio Grande do Sul -->
<!-- \end{tabular} -->
<!-- } & $1/550$ \\ \hline -->
<!-- \multicolumn{1}{|l|}{ -->
<!-- \begin{tabular}{l} -->
<!-- RM de São Paulo, Maranhão, São Paulo -->
<!-- \end{tabular} -->
<!-- } & $1/750$ \\ \hline\hline -->
<!-- \end{tabular} -->
<!-- \end{table} -->
<!-- \end{center} -->
<table>
<caption><span id="tab:proselpnad">Tabela 5.1: </span> Probabilidades de seleção da amostra da PNAD de 1993 segundo regiões</caption>
<colgroup>
<col width="80%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Região da pesquisa</th>
<th align="center">Probabilidade de seleção</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">RM de Belém</td>
<td align="center">1/150</td>
</tr>
<tr class="even">
<td align="left">RMs de Fortaleza, Recife, Salvador e Porto Alegre Distrito Federal</td>
<td align="center">1/200</td>
</tr>
<tr class="odd">
<td align="left">RMs de Belo Horizonte e Curitiba</td>
<td align="center">1/250</td>
</tr>
<tr class="even">
<td align="left">Rondô}nia, Acre, Amazonas, Roraima, Amapá, Tocantins, Sergipe, Mato Grosso do Sul, Mato Grosso e Goiás</td>
<td align="center">1/300</td>
</tr>
<tr class="odd">
<td align="left">Pará</td>
<td align="center">1/350</td>
</tr>
<tr class="even">
<td align="left">RM do Rio de Janeiro, Piauí, Ceará, Rio Grande do Norte, Paraíba, Pernambuco, Alagoas, Bahia, Minas Gerais, Espírito Santo e Rio de Janeiro</td>
<td align="center">1/500</td>
</tr>
<tr class="odd">
<td align="left">Paraná, Santa Catarina, Rio Grande do Sul</td>
<td align="center">1/550</td>
</tr>
<tr class="even">
<td align="left">RM de São Paulo, Maranhão, São Paulo</td>
<td align="center">1/750</td>
</tr>
</tbody>
</table>
<p>Se <span class="math inline">\({\ \pi }_{i}\)</span>representa a probabilidade de inclusão na amostra do <span class="math inline">\(i\)</span>-ésimo domicílio da população, <span class="math inline">\(i=1,...,N\)</span>, então <span class="math display">\[
\pi _{i}=\pi _{munic\acute{\imath}pio\left| estrato\right. }\times \pi
_{setor\left| munic\acute{\imath}pio\right. }\times \pi _{domic\acute{\imath}
lio\left| setor\right. } 
\]</span> isto é, a probabilidade global de inclusão de um domicílio (e conseqüentemente de todas as pessoas nele moradoras) é dada pelo produto das probabilidades condicionais de inclusão nos vários estágios de amostragem.</p>
<p>A estimação do total populacional <span class="math inline">\(Y\)</span> de uma variável de pesquisa <span class="math inline">\(y\)</span> num dado estrato usando os dados da PNAD é feita rotineiramente com estimadores ponderados de tipo razão <span class="math inline">\(\widehat{Y}_{R}=\widehat{Y}_{\pi }\,X\,/\,\widehat{X}_{\pi }=\sum_{i\in s}w_{i}^{R}y_{i}\)</span> (tal como definidos por <a href="capplanamo.html#eq:estpa15">(3.14)</a>, com pesos dados por <span class="math inline">\(w_{i}^{R}=\pi_{i}^{-1}X\,/\,\widehat{X}_{\pi }\)</span> (veja <a href="capplanamo.html#eq:estpa17">(3.16)</a>, onde <span class="math inline">\(X\)</span> é o total da população no estrato obtido por métodos demográficos de projeção, utilizado como variável auxiliar, e <span class="math inline">\(\widehat{X}_{\pi}\)</span> e <span class="math inline">\(\widehat{Y}_{\pi}\)</span> são os estimadores <span class="math inline">\(\pi\)</span>-ponderados de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> respectivamente. Para estimar para conjuntos de estratos basta somar as estimativas para cada estrato incluído no conjunto. Para estimar médias e proporções, os pesos são também incorporados da forma apropriada. No caso, a estimação de médias é feita usando estimadores ponderados da forma <span class="math display">\[
\overline{y}^{R}=\frac{\sum_{i\in s}w_{i}^{R}y_{i}}{\sum_{i\in s}w_{i}^{R}} 
\]</span> e a estimação de proporções é caso particular da estimação de médias quando a variável de pesquisa <span class="math inline">\(y\)</span> é do tipo indicador (isto é, só toma valores <span class="math inline">\(0\)</span> e <span class="math inline">\(1\)</span>).</p>
<p>Estimadores ponderados (como por exemplo os usados na PNAD) são preferidos pelos praticantes de amostragem por sua simplicidade e por serem não viciados (ao menos aproximadamente) com respeito à distribuição de aleatorização induzida pela seleção da amostra, independentemente dos valores assumidos pelas variáveis de pesquisa na população. Já para a modelagem de relações entre variáveis de pesquisa, o uso dos pesos induzidos pelo planejamento amostral ainda não é freqüente ou aceito sem controvérsia.</p>
<p>Um exemplo de modelagem desse tipo com dados da PNAD em que os pesos e o desenho amostral não foram considerados na análise é encontrado em <span class="citation">(Leote <a href="#ref-Leote">1996</a>)</span>. Essa autora empregou modelos de regressão logística para traçar um perfil sócio-econômico da mão-de-obra empregada no mercado informal de trabalho urbano no Rio de Janeiro, usando dados do suplemento sobre trabalho da PNAD-90. Todos os ajustes efetuados ignoraram os pesos e o plano amostral da pesquisa. O problema foi revisitado por <span class="citation">(Pessoa, Nascimento Silva, and Duarte <a href="#ref-Pessoa">1997</a>)</span>, quando então esses aspectos foram devidamente incorporados na análise. Um resumo desse trabalho é discutido no Capítulo <a href="modreg.html#modreg">6</a>.</p>
<p>Vamos supor que haja interesse em regredir uma determinada variável de pesquisa <span class="math inline">\(y\)</span> contra algumas outras variáveis de pesquisa num vetor de regressores <span class="math inline">\(\mathbf{z}\)</span>. Seria natural indagar se, como no caso do total e da média, os pesos amostrais poderiam desempenhar algum papel na estimação dos parâmetros do modelo (linear) de regressão. Uma possibilidade de incluir os pesos seria estimar os coeficientes da regressão por:</p>
<span class="math display" id="eq:modpar1">\[\begin{equation}
\widehat{\beta }_{w}=\left(\sum_{i\in s}w_{i}\mathbf{z}_{i}^{\prime }
\mathbf{z}_{i}\right) ^{-1}\sum_{i\in s}w_{i}\mathbf{z}_{i}^{\prime}y_{i}=
\left(\mathbf{Z}_{s}^{\prime }\mathbf{W}_{s}\mathbf{Z}_{s}\right)^{-1}\mathbf{Z}_{s}^{\prime }\mathbf{W}_{s}\mathbf{Y}_{s} 
\tag{5.1}
\end{equation}\]</span>
em lugar do estimador de mínimos quadrados ordinários (MQO) dado por
<span class="math display" id="eq:modpar2">\[\begin{equation}
\widehat{\beta}=\left( \sum_{i\in s}\mathbf{z}_{i}^{\prime }\mathbf{z}_{i}\right)^{-1}\sum_{i\in s}\mathbf{z}_{i}^{\prime }y_{i}=\left(\mathbf{Z}_{s}^{\prime }\mathbf{Z}_{s}\right)^{-1}\mathbf{Z}_{s}^{\prime }\mathbf{Y}_{s}  
\tag{5.2}
\end{equation}\]</span>
<p>onde <span class="math inline">\(w_{i}=\pi _{i}^{-1}\)</span>, <span class="math inline">\(y_{i}\)</span> é o valor da variável resposta e <span class="math inline">\(\mathbf{z}_{i}\)</span> é o vetor de regressores para a observação <span class="math inline">\(i\)</span>, <span class="math inline">\(\mathbf{Z}_{s}\)</span> e <span class="math inline">\(\mathbf{Y}_{s}\)</span> são respectivamente a matriz e vetor com os valores amostrais dos <span class="math inline">\(\mathbf{z}_{i}\)</span> e <span class="math inline">\(y_{i}\)</span>, e <span class="math inline">\(\mathbf{W}_{s}=diag\left\{ w_{i};i\in s\right\}\)</span> é a matriz diagonal com os pesos amostrais.</p>
<p>Não é possível justificar o estimador <span class="math inline">\(\widehat{\beta }_{w}\)</span> em <a href="ajmodpar.html#eq:modpar1">(5.1)</a> com base em critério de otimalidade, tal como ocorre com os estimadores usuais de Máxima Verossimilhança ou de Mínimos Quadrados Ordinários (MQO), se uma modelagem clássica IID fosse adotada para a amostra.</p>
<p>De um ponto de vista formal (matemático), o estimador <span class="math inline">\(\widehat{\beta }_{w}\)</span> em <a href="ajmodpar.html#eq:modpar1">(5.1)</a> é equivalente ao estimador de Mínimos Quadrados Ponderados (MQP) com pesos <span class="math inline">\(w_{i}\)</span>. Entretanto, esses estimadores diferem de maneira acentuada. Os estimadores de MQP são usualmente considerados quando o modelo de regressão é heteroscedástico, isto é, quando os resíduos têm variâncias desiguais. Nes-te caso, os pesos adequados seriam dados pelos inversos das variâncias dos resíduos correspondentes a cada uma das observações, e portanto em geral diferentes dos pesos iguais aos inversos das correspondentes probabilidades de seleção. Além desta diferença de interpretação do papel dos pesos no estimador, outro aspecto em que os dois estimadores diferem de forma acentuada é na estimação da precisão, com o estimador MQP acoplado a um estimador de variância baseado no modelo e o estimador <span class="math inline">\(\widehat{\beta }_{w}\)</span> acoplado a estimadores de variância que incorporam o planejamento amostral e os pesos, tal como se verá mais adiante.</p>
<p>O estimador <span class="math inline">\(\widehat{\beta }_{w}\)</span> foi proposto formalmente por <span class="citation">(Fuller <a href="#ref-fuller75">1975</a>)</span>, que o concebeu como uma função de estimadores de totais populacionais. A mesma idéia subsidiou vários outros autores que estudaram a estimação de coeficientes de regressão partindo de dados amostrais complexos, tais como <span class="citation">(Nathan and Holt <a href="#ref-NH80">1980</a>)</span>, <span class="citation">(Pfeffermann and Nathan <a href="#ref-PfefeNat">1981</a>)</span>. Uma revisão abrangente da literatura existente sobre estimação de parâmetros em modelos de regressão linear com dados amostrais complexos pode ser encontrada em cap. 6, <span class="citation">(Nascimento Silva <a href="#ref-Silva">1996</a>)</span>.</p>
<p>Apesar dessas dificuldades, será que é possível justificar o uso de pesos na inferência baseada em modelos? Se for o caso, sob que condições? Seria possível desenvolver diretrizes para o uso de pesos em inferência analítica partindo de dados amostrais complexos? A resposta para essas perguntas é afirmativa, ao menos quando a questão da robustez da inferência é relevante. Em inferências analíticas partindo de dados amostrais complexos, os pesos podem ser usados para proteger:</p>
<ol style="list-style-type: decimal">
<li><p>contra <code>planos amostrais não-ignoráveis</code>, que poderiam introduzir ou causar <code>vícios</code>;</p></li>
<li><p>contra a <code>má especificação do modelo</code>.</p></li>
</ol>
<p>A <code>robustez dos procedimentos</code> que incorporam pesos é obtida pela mudança de foco da inferência para <code>quantidades da população finita</code>, que definem parâmetros-alvo alternativos aos parâmetros do modelo de superpopulação, conforme já discutido na Seção <a href="refinf.html#modelsuperpop">2.1.4</a>.</p>
<p>A questão da construção dos pesos não será tratada neste texto, usando-se sempre como peso o inverso da probabilidade de inclusão na amostra. é possível utilizar pesos de outro tipo como, por exemplo, aqueles de razão empregados na estimação da PNAD, ou mesmo pesos de regressão. Para esses casos, há que fazer alguns ajustes da teoria aqui exposta (veja <span class="citation">(Nascimento Silva <a href="#ref-Silva">1996</a>)</span>, cap. 6).</p>
<p>Há várias formas alternativas de incorporar os pesos amostrais no processo de inferência. A principal que será adotada ao longo deste texto será o método de <code>Máxima Pseudo-Verossimilhança</code>, que descrevemos na próxima seção.</p>
</div>
<div id="modpar3" class="section level2">
<h2><span class="header-section-number">5.4</span> Método de Máxima Pseudo-Verossimilhança label</h2>
Suponha que os vetores observados <span class="math inline">\(\mathbf{y}_{i}\)</span> das variáveis de pesquisa do elemento<span class="math inline">\(\ i\)</span> são gerados por vetores aleatórios <span class="math inline">\(\mathbf{Y}_{i}\)</span> , para <span class="math inline">\(i\in U\)</span>. Suponha também que <span class="math inline">\(\mathbf{Y}_{1},\ldots ,\mathbf{Y}_{N}\)</span> são IID com densidade <span class="math inline">\(f\left( \mathbf{y},\mathbf{\theta }\right)\)</span>. Se todos os elementos da população finita <span class="math inline">\(U\)</span> fossem conhecidos, as funções de verossimilhança e de log-verossimilhança <code>populacionais</code> seriam dadas respectivamente por
<span class="math display" id="eq:modpar3">\[\begin{equation}
l_{U}\left( \mathbf{\theta }\right) =\prod\limits_{i\in U}f\left( \mathbf{y}
_{i};\mathbf{\theta }\right)  
\tag{5.3}
\end{equation}\]</span>
e
<span class="math display" id="eq:modpar4">\[\begin{equation}
L_{U}\left( \mathbf{\theta }\right) =\sum_{i\in U}\log \left[ f\left( 
\mathbf{y}_{i};\mathbf{\theta }\right) \right] \;\;.  
\tag{5.4}
\end{equation}\]</span>
As equações de verossimilhança <code>populacionais</code> correspondentes são dadas por
<span class="math display" id="eq:modpar5">\[\begin{equation}
\sum_{i\in U}\mathbf{u}_{i}\left( \mathbf{\theta }\right) =\mathbf{0}
\tag{5.5}
\end{equation}\]</span>
onde
<span class="math display" id="eq:modpar6">\[\begin{equation}
\mathbf{u}_{i}\left( \mathbf{\theta }\right) =\partial \log \left[ f\left( 
\mathbf{y}_{i};\mathbf{\theta }\right) \right] /\partial \mathbf{\theta }
\tag{5.6}
\end{equation}\]</span>
<p>é o vetor <span class="math inline">\(K\times 1\)</span> dos escores do elemento <span class="math inline">\(i,i\in U\)</span>.</p>
<p>Sob condições de regularidade <span class="citation">(Cox and Hinkley <a href="#ref-cox">1974</a>)</span>, p. 281, a solução <span class="math inline">\(\mathbf{\theta }_{U}\)</span> deste sistema é o <code>Estimador de Máxima Verossimilhança</code> de <span class="math inline">\(\mathbf{\theta }\)</span> no caso de um <code>censo</code>. Podemos considerar <span class="math inline">\(\mathbf{\theta }_{U}\)</span> como uma <code>Quantidade Descritiva Populacional Correspondente (QDPC)</code> a <span class="math inline">\(\mathbf{\theta }\)</span>, no sentido definido por <span class="citation">(Pfeffermann <a href="#ref-Pfeff">1993</a>)</span>, sobre a qual se deseja fazer inferências com base em informações da amostra. Essa definição da QDPC <span class="math inline">\(\mathbf{\theta }_{U}\)</span> pode ser generalizada para contemplar outras abordagens de inferência além da abordagem clássica baseada em maximização da verossimilhança. Basta para isso especificar outra regra ou critério a otimizar e então definir a QDPC como a solução ótima segundo essa nova regra. Tal generalização, discutida em <span class="citation">(Pfeffermann <a href="#ref-Pfeff">1993</a>)</span>, não será aqui considerada para manter a simplicidade.</p>
<p>A QDPC <span class="math inline">\(\mathbf{\theta }_{U}\)</span> definida com base em <a href="ajmodpar.html#eq:modpar5">(5.5)</a> não é calculável a menos que um censo seja realizado. Entretanto, desempenha papel fundamental nessa abordagem inferencial, por constituir-se num <code>pseudo-parâmetro</code>, eleito como alvo da inferência num esquema que incorpora o planejamento amostral. Isto se justifica porque, sob certas condições de regularidade, <span class="math inline">\(\mathbf{\theta }_{U}\mathbf{ -\theta }=o_{p}\left( 1\right)\)</span>. Como em pesquisas por amostragem o tamanho da população é geralmente grande, um estimador adequado para <span class="math inline">\(\mathbf{\theta}_{U}\)</span> será geralmente adequado também para <span class="math inline">\(\mathbf{\theta }\)</span>.</p>
<p>Seja <span class="math inline">\(\mathbf{T}=\sum_{i\in U}\mathbf{u}_{i}\left( \mathbf{\theta }\right)\)</span> a soma dos vetores de escores na população, o qual é um vetor de totais populacionais. Para estimar este vetor de totais, podemos então usar um estimador linear ponderado da forma <span class="math inline">\(\mathbf{\hat{T}}=\sum_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\theta }\right)\)</span> (veja Capítulo <a href="refinf.html#planamo">2.4</a>) onde <span class="math inline">\(w_{i}\)</span> são pesos propriamente definidos. Com essa notação, podemos agora obter um estimador para <span class="math inline">\(\mathbf{\theta }_{U}\)</span> resolvendo o sistema de equações obtido igualando o estimador <span class="math inline">\(\mathbf{\hat{T}}\)</span> do total <span class="math inline">\(\mathbf{T}\)</span> a zero.</p>

<div class="definition">
<span id="def:unnamed-chunk-48" class="definition"><strong>Definição 5.1 </strong></span>O estimador de Máxima Pseudo-Verossimilhança (MPV) <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}\)</span> de <span class="math inline">\(\mathbf{\theta }_{U}\)</span> (e consequentemente de <span class="math inline">\(\mathbf{\theta}\)</span>) será a solução das equações dePseudo-Verossimilhança dadas por
<span class="math display" id="eq:modpar7">\[\begin{equation}
\mathbf{\hat{T}}=\sum_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\theta }
\right) =\mathbf{0\;\;.}  
\tag{5.7}
\end{equation}\]</span>
</div>
<p></p>
Através da linearização de Taylor (veja Seção <a href="capplanamo.html#taylor">3.3</a> e considerando os resultados de <span class="citation">(Binder <a href="#ref-binder83">1983</a>)</span>, podemos obter a variância de aleatorização assintótica do estimador <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}\)</span> e seu estimador correspondente, dados respectivamente por:
<span class="math display" id="eq:modpar8">\[\begin{equation}
V_{p}\left( \mathbf{\hat{\theta}}_{MPV}\right) \simeq \left[ J\left( \mathbf{
\theta }_{U}\right) \right] ^{-1}V_{p}\left[ \sum_{i\in s}w_{i}\mathbf{u}
_{i}\left( \mathbf{\theta }_{U}\right) \right] \left[ J\left( \mathbf{\theta 
}_{U}\right) \right] ^{-1}  
\tag{5.8}
\end{equation}\]</span>
e
<span class="math display" id="eq:modpar9">\[\begin{equation}
\hat{V}_{p}\left( \mathbf{\hat{\theta}}_{MPV}\right) =\left[ \hat{J}\left( 
\mathbf{\hat{\theta}}_{MPV}\right) \right] ^{-1}\hat{V}_{p}\left[ \sum_{i\in
s}w_{i}\mathbf{u}_{i}\left( \mathbf{\hat{\theta}}_{MPV}\right) \right]
\left[ \hat{J}\left( \mathbf{\hat{\theta}}_{MPV}\right) \right] ^{-1}\;,
\tag{5.9}
\end{equation}\]</span>
<p>onde</p>
<span class="math display" id="eq:modpar10">\[\begin{equation}
J\left( \mathbf{\theta }_{U}\right) =\left. \frac{\partial T\left( \mathbf{
\theta }\right) }{\partial \mathbf{\theta }}\right| _{\mathbf{\theta =\theta 
}_{U}}=\sum_{i\in U}\left. \frac{\partial \mathbf{u}_{i}\left( \mathbf{
\theta }\right) }{\partial \left( \mathbf{\theta }\right) }\right| _{\mathbf{
\theta =\theta }_{U}},  
\tag{5.10}
\end{equation}\]</span>
<span class="math display" id="eq:modpar11">\[\begin{equation}
\hat{J}\left( \mathbf{\hat{\theta}}_{MPV}\right) =\left. \frac{\partial 
\widehat{T}\left( \mathbf{\theta }\right) }{\partial \mathbf{\theta }}
\right| _{\mathbf{\theta =\hat{\theta}}_{MPV}}=\sum_{i\in s}w_{i}\left. 
\frac{\partial \mathbf{u}_{i}\left( \mathbf{\theta }\right) }{\partial 
\mathbf{\theta }}\right| _{\mathbf{\theta =\hat{\theta}}_{MPV}},
\tag{5.11}
\end{equation}\]</span>
<span class="math inline">\(V_{p}\left[\sum_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\theta}_{U}\right) \right]\)</span> é a matriz de variância (de aleatorização) do estimador do total populacional dos escores e <span class="math inline">\(\hat{V}_{p}\left[\sum_{i\in s}w_{i}\mathbf{u}_{i}\left(\mathbf{\hat{\theta}}_{MPV}\right)\right]\)</span> é um estimador consistente para esta variância. Binder(1983) mostrou também que a distribuição assintótica de <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}\)</span> é Normal Multivariada, isto é, que
<span class="math display" id="eq:modpar12">\[\begin{equation}
\left[ \hat{V}_{p}\left( \mathbf{\hat{\theta}}_{MPV}\right) \right]^{-1/2}\left(\mathbf{\hat{\theta}}_{MPV}-\mathbf{\theta }_{U}\right) \sim  \mathbf{NM}\left(\mathbf{0};\mathbf{I}\right),  
\tag{5.12}
\end{equation}\]</span>
<p>o que fornece uma base para a inferência sobre <span class="math inline">\(\mathbf{\theta }_{U}\)</span> (ou <span class="math inline">\(\mathbf{\theta }\)</span>) usando amostras grandes.</p>
<p>Muitos modelos paramétricos, com vários planos amostrais e estimadores de totais diferentes, podem ser ajustados resolvendo-se as equa ções de Pseudo-Verossimilhança <a href="ajmodpar.html#eq:modpar7">(5.7)</a>, satisfeitas algumas condições de regularidade enunciadas no apêndice de <span class="citation">(Binder <a href="#ref-binder83">1983</a>)</span> e revistas em <span class="citation">(Nascimento Silva <a href="#ref-Silva">1996</a>)</span>, p. 126. Entretanto, os estimadores de MPV não serão únicos, já que existem diversas maneiras de se definir os pesos <span class="math inline">\(w_{i}\)</span>.</p>
<p>Os pesos <span class="math inline">\(w_{i}\)</span> devem ser tais que os estimadores de total em <a href="ajmodpar.html#eq:modpar7">(5.7)</a> sejam assintoticamente normais e não-viciados, e possuam estimadores de variância consistentes, conforme requerido para a obtenção da distribuição assintótica dos estimadores MPV. Os pesos mais usados são os do estimador <span class="math inline">\(\pi\)</span>-ponderado ou de Horvitz-Thompson para totais, dados pelo inverso das probabilidades de inclusão dos indivíduos, ou seja <span class="math inline">\(w_{i}=\pi _{i}^{-1}\)</span>. Tais pesos satisfazem essas condições sempre que <span class="math inline">\(\pi _{i}&gt;0\)</span> e <span class="math inline">\(\pi _{ij}&gt;0\quad \forall i,j\in U\)</span> e algumas condições adicionais de regularidade são satisfeitas (veja, <span class="citation">(Fuller <a href="#ref-fuller84">1984</a>)</span>).</p>
<p>Assim, um procedimento padrão para ajustar um modelo paramétrico regular <span class="math inline">\(f\left( \mathbf{y};\mathbf{\theta }\right)\)</span> pelo método da Máxima Pseudo-Verossimilhança seria dado pelos passos indicados a seguir.</p>
<ol style="list-style-type: decimal">
<li><p>Resolver <span class="math inline">\(\sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{u}_{i}\left( \mathbf{\theta }\right) =\mathbf{0}\)</span> e calcular o estimador pontual <span class="math inline">\(\mathbf{ \hat{\theta}}_{\pi }\)</span> do parâmetro <span class="math inline">\(\mathbf{\theta }\)</span>no modelo <span class="math inline">\(f\left( \mathbf{y;\theta }\right)\)</span> (ou do pseudo-parâmetro <span class="math inline">\(\mathbf{\theta }_{U}\)</span> correspondente).</p></li>
<li>Calcular a matriz de variância estimada
<span class="math display" id="eq:modpar13">\[\begin{equation}
\hat{V}_{p}\left( \mathbf{\hat{\theta}}_{\pi }\right) =\left[ \hat{J}\left( 
\mathbf{\hat{\theta}}_{\pi }\right) \right] ^{-1}\hat{V}_{p}\left[
\sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{u}_{i}\left( \mathbf{\hat{\theta}}
_{\pi }\right) \right] \left[ \hat{J}\left( \mathbf{\hat{\theta}}_{\pi
}\right) \right] ^{-1},  
\tag{5.13}
\end{equation}\]</span>
<p>onde</p></li>
</ol>
<span class="math display" id="eq:modpar14">\[\begin{equation}
\hat{V}_{p}\left[ \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{u}_{i}\left( 
\mathbf{\hat{\theta}}_{\pi }\right) \right] =\sum\limits_{i\in
s}\sum\limits_{j\in s}\frac{\pi _{ij}-\pi _{i}\pi _{j}}{\pi _{i}\pi _{j}}
\left[ \mathbf{u}_{i}\left( \mathbf{\hat{\theta}}_{\pi }\right) \right]
\left[ \mathbf{u}_{j}\left( \mathbf{\hat{\theta}}_{\pi }\right) \right]
^{^{\prime }}  
\tag{5.14}
\end{equation}\]</span>
<p>e</p>
<span class="math display" id="eq:modpar15">\[\begin{equation}
\hat{J}\left( \mathbf{\hat{\theta}}_{\pi }\right) =\left. \frac{\partial 
\widehat{T}\left( \mathbf{\theta }\right) }{\partial \mathbf{\theta }}
\right| _{\mathbf{\theta }=\mathbf{\hat{\theta}}_{\pi }}=\sum\limits_{i\in
s}\pi _{i}^{-1}\left. \frac{\partial \mathbf{u}_{i}\left( \mathbf{\theta }
\right) }{\partial \mathbf{\theta }}\right| _{\mathbf{\theta }=\mathbf{\hat{
\theta}}_{\pi }}\;\;.  
\tag{5.15}
\end{equation}\]</span>
<ol start="3" style="list-style-type: decimal">
<li>Usar <span class="math inline">\(\mathbf{\hat{\theta}}_{\pi }\)</span> e <span class="math inline">\(\hat{V}_{p}\left( \mathbf{\hat{\theta}}_{\pi }\right)\)</span> para calcular regiões ou intervalos de confiança e/ou estatísticas de teste baseadas na distribuição normal e utilizá-las para fazer inferência sobre os componentes de <span class="math inline">\(\mathbf{\theta}\)</span>.</li>
</ol>

<div class="remark">
<span class="remark"><em>Observação </em></span> No Método de Máxima Pseudo-Verossimilhança, os pesos amostrais são incorporados na análise através das equações de estimação dos parâmetros <a href="ajmodpar.html#eq:modpar7">(5.7)</a> e através das equações de estimação da matriz de covariância dos estimadores <a href="ajmodpar.html#eq:modpar13">(5.13)</a>-<a href="ajmodpar.html#eq:modpar15">(5.15)</a>.
</div>
<p></p>

<div class="remark">
<span class="remark"><em>Observação </em></span> O plano amostral é também incorporado no método de estimação MPV através da expressão para a variância do total dos escores sob o plano amostral <a href="ajmodpar.html#eq:modpar14">(5.14)</a>, onde as propriedades do plano amostral estão resumidas nas probabilidades de inclusão de primeira e segunda ordem, isto é, os <span class="math inline">\(\pi _{i}\)</span> e os <span class="math inline">\(\pi _{ij}\)</span> respectivamente.
</div>
<p></p>

<div class="remark">
<span class="remark"><em>Observação </em></span> Sob probabilidades de seleção iguais, os pesos <span class="math inline">\(\pi _{i}^{-1}\)</span> serão constantes e o estimador pontual <span class="math inline">\(\hat{\theta}_{\pi }\)</span> será idêntico ao estimador de Máxima Verossimilhança (MV) ordinário para uma amostra de observações IID com distribuição <span class="math inline">\(f\left(\mathbf{y;\theta }\right)\)</span>. Entretanto, o mesmo não ocorre em se tratando da variância do estimador <span class="math inline">\(\hat{\theta}_{\pi }\)</span> , que difere da variância sob o modelo do estimador usual de MV.
</div>
<p></p>
<p><strong>Vantagens do procedimento de MPV</strong></p>
<p>O procedimento MPV proporciona estimativas <code>baseadas no plano amostral</code> para a variância assintótica dos estimadores dos parâmetros, as quais são razoavelmente simples de calcular e são consistentes sob <code>condições fracas</code> no plano amostral e na especificação do modelo. Mesmo quando o estimador pontual de MPV coincide com o estimador usual de Máxima Verossimilhança, a estimativa da variância obtida pelo procedimento de MPV pode ser preferível aos estimadores usuais da variância baseados no modelo, que ignoram o plano amostral.</p>
<p>O procedimento MPV fornece estimativas <code>robustas</code>, no sentido de que em muitos casos a quantidade <span class="math inline">\(\mathbf{\theta }_{U}\)</span> da população finita permanece um alvo válido para inferência, mesmo quando o modelo especificado por <span class="math inline">\(f\left( \mathbf{y};\mathbf{\theta }\right)\)</span> não proporciona uma descrição adequada para a distribuição das variáveis de pesquisa na população.</p>
<p><strong>Desvantagens do método de MPV</strong></p>
<p>Este procedimento requer conhecimento de informações detalhadas sobre os elementos da amostra, tais como pertinência a estratos e conglomerados ou unidades primárias de amostragem, e suas probabilidades de inclusão ou pesos. Tais informações nem sempre estão disponíveis para usuários de dados de pesquisas amostrais, seja por razões operacionais ou devido às regras de proteção do sigilo de informações individuais.</p>
<p>As propriedades dos estimadores MPV não são conhecidas para pequenas amostras. Este problema pode não ser importante em análises que usam os dados de pesquisas feitas pelas agências oficiais de estatística, desde que em tais análises seja utilizada a amostra inteira, ou no caso de subdomínios estudados separadamente, que as amostras usadas sejam suficientemente grandes nestes domínios.</p>
<p>Outra dificuldade é que métodos usuais de diagnóstico de ajuste de modelos (tais como gráficos de resíduos) e outros procedimentos da inferência clássica (tais como testes estatísticos de Razões de Verossimilhança) não podem ser utilizados.</p>
</div>
<div id="robustez-do-procedimento-mpv" class="section level2">
<h2><span class="header-section-number">5.5</span> Robustez do Procedimento MPV</h2>
<p>Nesta seção vamos examinar a questão da robustez dos estimadores obtidos pelo procedimento MPV. é essa robustez que justifica o emprego desses estimadores frente aos estimadores usuais de MV, pois nas situações práticas da análise de dados amostrais complexos as hipóteses usuais de modelo IID para as observações amostrais raramente são verificadas.</p>
<p>Vamos agora analisar com mais detalhes a terceira abordagem para a inferência analítica. Nela, postulamos um modelo como na primeira abordagem e a inferência é direcionada aos parâmetros do modelo. Porém, em vez de acharmos um estimador ótimo sob o modelo, achamos um estimador na classe dos estimadores consistentes para a QDPC, onde a consistência é referida à distribuição de aleatorização do estimador. Por que usar a QDPC? A resposta é exatamente para obter maior robustez. Para entender porque essa abordagem oferece maior robustez, vamos considerar dois casos.</p>
<ul>
<li>Caso 1: o modelo para a população é adequado.</li>
</ul>
<p>Então quando <span class="math inline">\(N\rightarrow \infty\)</span> a QDPC <span class="math inline">\(\mathbf{\theta }_{U}\)</span> converge para o parâmetro <span class="math inline">\(\mathbf{\theta }\)</span>, isto é, <span class="math inline">\(\mathbf{\theta }_{U}-\mathbf{\theta }\rightarrow \mathbf{0}\)</span> em probabilidade, segundo a distribuição de probabilidades do modelo <span class="math inline">\(M\)</span>. Se <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}\)</span> for consistente, então quando <span class="math inline">\(n\rightarrow \infty\)</span> temos que <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}-\mathbf{\theta }_{U}\rightarrow\mathbf{0}\)</span> em probabilidade, segundo a distribuição de aleatorização <span class="math inline">\(p\)</span>. Juntando essas condições obtemos que</p>
<p><span class="math display">\[
\mathbf{\hat{\theta}}_{MPV}\stackrel{P}{\rightarrow }\mathbf{\theta } 
\]</span> em probabilidade segundo a mistura <span class="math inline">\(Mp\)</span>. Esse resultado segue porque</p>
<span class="math display">\[\begin{eqnarray*}
\mathbf{\hat{\theta}}_{MPV}-\mathbf{\theta } &amp;=&amp;(\mathbf{\hat{\theta}}_{MPV}-
\mathbf{\theta }_{U})+\left( \mathbf{\theta }_{U}-\mathbf{\theta }\right) \\
&amp;=&amp;O_{p}(n^{-1/2})+O_{p}(N^{-1/2})=O_{p}(n^{-1/2})\;.
\end{eqnarray*}\]</span>
<ul>
<li>Caso 2: o modelo para a população não é válido.</li>
</ul>
<p>Nesse caso, o parâmetro <span class="math inline">\(\mathbf{\theta }\)</span> do modelo não tem interpretação substantiva significante, porém a QDPC <span class="math inline">\(\mathbf{\theta }_{U}\)</span> é uma entidade definida na população finita (real) com interpretação clara, independente da validade do modelo. Como <span class="math inline">\(\mathbf{\hat{\theta}}_{MPV}\)</span> é consistente para a QDPC <span class="math inline">\(\mathbf{\theta}_{U}\)</span>, a inferência baseada no procedimento MPV segue válida para este pseudo-parâmetro, independente da inadequação do modelo para a população. <span class="citation">(Skinner 1989b)</span>, p. 81, discute essa situação, mostrando que <span class="math inline">\(\mathbf{\theta }_{U}\)</span> pode ainda ser um alvo válido para inferência mesmo quando o modelo <span class="math inline">\(f\left( \mathbf{y};\mathbf{\theta }\right)\)</span> especificado para a população é inadequado, ao menos no sentido de que <span class="math inline">\(f\left( \mathbf{y};\mathbf{\theta}_{U}\right)\)</span> forneceria a <code>melhor aproximação possível</code> (em certo sentido) para o verdadeiro modelo que gera as observações populacionais (<span class="math inline">\(f^{*}\left( \mathbf{y};\mathbf{\eta }\right)\)</span>, digamos). Skinner(1989b) reconhece que a <code>melhor aproximação possível</code> entre um conjunto de aproximações ruins ainda seria uma aproximação ruim, e portanto que a escolha do elenco de modelos especificados pela distribuição <span class="math inline">\(f\left( \mathbf{y};\mathbf{\theta }\right)\)</span> deve seguir os cuidados necessários para garantir que esta escolha forneça uma aproximação razoável da realidade.</p>

<div class="remark">
<span class="remark"><em>Observação </em></span> Consistência referente à distribuição de aleatorização.
</div>
<p></p>
<p>Consistência na teoria clássica tem a ver com comportamento limite de um estimador quando o tamanho da amostra cresce, isto é, quando <span class="math inline">\(n\rightarrow \infty\)</span>. No caso de populações finitas, temos que considerar o que ocorre quando crescem o tamanho da amostra e também o tamanho da população, isto é, quando <span class="math inline">\(n\rightarrow \infty\)</span> e <span class="math inline">\(N\rightarrow \infty\)</span>. Neste caso, é preciso definir a maneira pela qual <span class="math inline">\(N\uparrow\)</span> e <span class="math inline">\(n\uparrow\)</span> preservando a estrutura do plano amostral. Para evitar um desvio indesejado que a discussão deste problema traria, vamos supor que <span class="math inline">\(N\uparrow\)</span> e <span class="math inline">\(n\uparrow\)</span> de uma forma bem definida. Os leitores interessados poderão consultar: <span class="citation">(Särndal, Swensson, and Wretman <a href="#ref-SSW92">1992</a>)</span>, p. 166, <span class="citation">(Brewer <a href="#ref-brewer">1979</a>)</span>, <span class="citation">(Isaki and Fuller <a href="#ref-Isaki">1982</a>)</span>, <span class="citation">(Robinson and Särndal <a href="#ref-Robin">1983</a>)</span>, <span class="citation">(Hájek <a href="#ref-hajek">1960</a>)</span> e <span class="citation">(Skinner, Holt, and Smith <a href="#ref-SHS89">1989</a>)</span>, p. 18-19.</p>
</div>
<div id="desvantagens-da-inferencia-de-aleatorizacao" class="section level2">
<h2><span class="header-section-number">5.6</span> Desvantagens da Inferência de Aleatorização</h2>
<p>Se o modelo postulado para os dados amostrais for correto, o uso de estimadores ponderados pode resultar em perda substancial de eficiência comparado com o estimador ótimo, sob o modelo. Em geral, a perda de eficiência aumenta quando diminui o tamanho da amostra e aumenta a varia ção dos pesos. Há casos onde a ponderação é a única alternativa. Por exemplo, se os dados disponíveis já estão na forma de estimativas amostrais ponderadas, então o uso de pesos é inevitável. Um exemplo clássico é discutido a seguir.</p>

<div class="example">
<span id="ex:Analisec" class="example"><strong>Exemplo 5.2 </strong></span>Análise secundária de tabelas de contingência.
</div>
<p></p>
<p>A pesquisa <code>Canada Health Survey</code> usa um plano amostral estratificado com vários estágios de seleção. Nessa pesquisa, a estimativa de contagem na cela <span class="math inline">\(k\)</span> de uma tabela de contingência qualquer é dada por <span class="math display">\[
\widehat{N}_{k}=\sum_{a}\left( N_{a}/\widehat{N}_{a}\right) \left[
\sum_{h}\sum_{i}\sum_{j}w_{hij}Y_{ka\left( hij\right) }\right]
=\sum_{a}\left( N_{a}/\widehat{N}_{a}\right) \widehat{N}_{ka} 
\]</span> onde <span class="math inline">\(Y_{ka\left( hij\right)}=1\)</span> se a <span class="math inline">\(j\)</span>-ésima unidade da UPA <span class="math inline">\(i\)</span> do estrato <span class="math inline">\(h\)</span> pertence à <span class="math inline">\(k\)</span>-ésima cela e ao <span class="math inline">\(a\)</span>-ésimo grupo de idade-sexo, e <span class="math inline">\(0\)</span> (zero) caso contrário;</p>
<p><span class="math inline">\(N_{a}/\widehat{N}_{a}-\)</span> são fatores de ajustamento de pós-estratificação que usam contagens censitárias <span class="math inline">\(N_{a}\)</span> de idade-sexo para diminuir as variâncias dos estimadores.</p>
<p>Quando as contagens <code>expandidas</code> <span class="math inline">\(\widehat{N}_{k}\)</span> são usadas, os testes de homogeneidade e de qualidade de ajuste de modelos loglineares baseados em amostragem Multinomial e Poisson independentes não são mais válidos. A estatística clássica <span class="math inline">\(X^{2}\)</span> não tem mais distribuição <span class="math inline">\(\chi ^{2}\)</span> e sim uma soma ponderada <span class="math inline">\(\sum_{k}\delta _{k}X_{k}\)</span> de variáveis <span class="math inline">\(X_{k}\)</span> IID com distribuição <span class="math inline">\(\chi ^{2}\left( 1\right)\)</span>. Esse exemplo será rediscutido com mais detalhes na Seção <a href="testqualajust.html#raoscott">7.3.2</a>.</p>
<p>A importância desse exemplo é ilustrar que mesmo quando o usuário pensa estar livre das complicações causadas pelo plano amostral e pesos, ele precisa estar atento à forma como foram gerados os dados que pretende modelar ou analisar, sob pena de realizar inferências incorretas. Este exemplo tem também grande importância prática, pois um grande número de pesquisas domiciliares por amostragem produz como principal resultado conjunto de tabelas com contagens e proporções, as quais foram obtidas mediante ponderação pelas agências produtoras. Este é o caso, por exemplo, da PNAD, da amostra do Censo Demográfico e de inúmeras outras pesquisas do IBGE e de agências estatísticas congêneres.</p>
</div>
<div id="laboratorio-de-r-2" class="section level2">
<h2><span class="header-section-number">5.7</span> Laboratório de R</h2>
<p>Usar função svymle da library survey para incluir exemplo de estimador MPV?</p>
<p>Possibilidade: explorar o exemplo 2.1?</p>

</div>
</div>
<h3>Referências</h3>
<div id="refs" class="references">
<div id="ref-kalton83b">
<p>Kalton, G. 1983b. “Models in the Practice of Survey Sampling.” <em>International Statistical Review</em> 51: 175–88.</p>
</div>
<div id="ref-binder87">
<p>Binder, D. A., J. G. Kovar, S. Kumar, D. Paton, and A. V. Baaren. 1987. “Analytic Uses of Survey Data: A Review.” In <em>Applied Probability, Stochastic Processes and Sampling Theory</em>, edited by I. B. MacNeil and G. J. Umphrey, 243–64. John Wiley.</p>
</div>
<div id="ref-bickel">
<p>Bickel, P. J., and K. A. Doksum. 1977. <em>Mathematical Statistics: Basic Ideas and Selected Topics</em>. San Francisco: Holden-Day.</p>
</div>
<div id="ref-garthwaite">
<p>Garthwaite, P. H., I. T. Jollife, and B Jones. 1995. <em>Statistical Inference</em>. Nova Iorque: Prentice Hall.</p>
</div>
<div id="ref-cochran">
<p>Cochran, W. G. 1977. <em>Sampling Techniques</em>. Nova Iorque: John Wiley.</p>
</div>
<div id="ref-SSW92">
<p>Särndal, C-E., B. Swensson, and J. H. Wretman. 1992. <em>Model Assisted Survey Sampling</em>. Nova Iorque: Springer-Verlag.</p>
</div>
<div id="ref-SHS89">
<p>Skinner, C. J., D. Holt, and T. M. F. Smith, eds. 1989. <em>Analysis of Complex Surveys</em>. Chichester: John Wiley; Sons.</p>
</div>
<div id="ref-Pfeff">
<p>Pfeffermann, D. 1993. “The Role of Sampling Weights When Modelling Survey Data.” <em>International Statistical Review</em> 61: 317–37.</p>
</div>
<div id="ref-cox">
<p>Cox, D. R., and D. V. Hinkley. 1974. <em>Theoretical Statistics</em>. Londres: Chapman &amp; Hall.</p>
</div>
<div id="ref-Leote">
<p>Leote, R. M. D. 1996. “Um Perfil Sócio-Econômico Das Pessoas Ocupadas No Setor Informal Na área Urbana Do Rio de Janeiro.” 2. Rio de Janeiro: IBGE, Escola Nacional de Ciências Estatísticas.</p>
</div>
<div id="ref-Pessoa">
<p>Pessoa, D. G. C., P. L. D. Nascimento Silva, and R. P. N. Duarte. 1997. “Análise Estatística de Dados de Pesquisas Por Amostragem: Problemas No Uso de Pacotes Padrões.” <em>Revista Brasileira de Estatística</em> 33: 44–57.</p>
</div>
<div id="ref-fuller75">
<p>Fuller, W. A. 1975. “Regression Analysis for Sample Survey.” <em>Sankhyā C</em> 37: 117–32.</p>
</div>
<div id="ref-NH80">
<p>Nathan, G., and D. Holt. 1980. “The Effect of Survey Design on Regression Analysis.” <em>Journal of the Royal Statistical Society B</em> 42: 377–86.</p>
</div>
<div id="ref-PfefeNat">
<p>Pfeffermann, D., and G. Nathan. 1981. “Regression Analysis of Data from Complex Samples.” <em>Journal of the American Statistical Association</em> 76: p. 681–89.</p>
</div>
<div id="ref-Silva">
<p>Nascimento Silva, P. L. D. 1996. “Utilizing Auxiliary Information for Estimation and Analysis in Sample Surveys.” PhD thesis, University of Southampton, Department of Social Statistics.</p>
</div>
<div id="ref-binder83">
<p>Binder, D. A. 1983. “On the Variances of Asymptotically Normal Estimators from Complex Surveys.” <em>International Statistical Review</em> 51: 279–92.</p>
</div>
<div id="ref-fuller84">
<p>Fuller, W. 1984. “Least Squares and Related Analyses for Complex Survey Designs.” <em>Survey Methodology</em> 10: 97–118.</p>
</div>
<div id="ref-brewer">
<p>Brewer, K. W. R. 1979. “A Class of Robust Sampling Designs for Large Scale Surveys.” <em>Journal of the American Statistical Association</em> 74: 911–15.</p>
</div>
<div id="ref-Isaki">
<p>Isaki, C. T., and W. A. Fuller. 1982. “Survey Design Under the Regression Superpopulation Model.” <em>Journal of the American Statistical Association</em> 77: 89–96.</p>
</div>
<div id="ref-Robin">
<p>Robinson, P. M., and C. E. Särndal. 1983. “Asymptotic Properties of the Generalized Regression Estimator in Probability Sampling.” <em>Sankhyā B</em> 45: 240–48.</p>
</div>
<div id="ref-hajek">
<p>Hájek, J. 1960. “Limiting Distributions in Simple Random Sampling from Finite Populations.” <em>Pub.Math. Inst. Hung. Acad. Sci.</em> 5: 361–74.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="epa.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modreg.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-Cap5.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
