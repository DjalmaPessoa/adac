\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Análise de Dados Amostrais Complexos},
            pdfauthor={Djalma Pessoa e Pedro Nascimento Silva},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Análise de Dados Amostrais Complexos}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Djalma Pessoa e Pedro Nascimento Silva}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{2017-03-29}

\usepackage{booktabs}
\usepackage[brazil]{babel}
\newtheorem{example}{Exemplo}
\numberwithin{example}{chapter}
\newtheorem{remark}{Observação}
\numberwithin{remark}{chapter}
\newtheorem{definition}{Definição}
\numberwithin{definition}{chapter}

\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{Prefácio}\label{prefacio}
\addcontentsline{toc}{chapter}{Prefácio}

\chapter{Introdução}\label{introduc}

\section{Motivação}\label{motivacao}

Este livro trata de problema de grande importância para os usuários de
dados obtidos através de pesquisas amostrais por agências produtoras de
informações estatísticas. Tais dados são comumente utilizados em
análises descritivas envolvendo o cálculo de estimativas para totais,
proporções, médias e razões, nas quais, em geral, são devidamente
considerados os pesos distintos das observações e o planejamento da
amostra que lhes deu origem.

Outro uso destes dados, denominado secundário, é a construção e ajuste
de modelos, feita geralmente por analistas que trabalham fora das
agências produtoras dos dados. Neste caso, o foco é, essencialmente,
estabelecer a natureza de relações ou associações entre variáveis. Para
isto, a estatística clássica conta com um arsenal de ferramentas de
análise, já incorporado aos principais pacotes estatísticos disponíveis.
O uso destes pacotes se faz, entretanto, sob condições que não refletem
a complexidade usualmente envolvida nas pesquisas amostrais de
populações finitas. Em geral, partem de hipóteses básicas que só são
válidas quando os dados são obtidos através de amostras aleatórias
simples com reposição (AASC). Tais pacotes estatísticos não consideram
os seguintes aspectos relevantes no caso de amostras complexas:

i.) \textbf{probabilidades distintas de seleção das unidades};

ii.) \textbf{conglomeração das unidades};

iii.) \textbf{estratificação};

iv.) \textbf{calibração ou imputação para não-resposta e outros
ajustes}.

As estimativas pontuais de parâmetros da população ou de modelos são
influenciadas por pesos distintos das observações. Além disso, as
estimativas de variância (ou da precisão dos estimadores) são
influenciadas pela conglomeração, estratificação e pesos, ou no caso de
não resposta, também por eventual imputação de dados faltantes. Ao
ignorar estes aspectos, os pacotes tradicionais de análise podem
produzir estimativas incorretas das variâncias das estimativas pontuais.

A seguir vamos apresentar um exemplo de uso de dados de uma pesquisa
amostral real para ilustrar como os pontos i) a iv) acima mencionados
afetam a inferência sobre quantidades descritivas populacionais tais
como médias, proporções, razões e totais.

\BeginKnitrBlock{example}
\protect\hypertarget{ex:unnamed-chunk-1}{}{\label{ex:unnamed-chunk-1}}Distribuição
dos pesos da amostra da PPV
\EndKnitrBlock{example}

Os dados deste exemplo são relativos à distribuição dos pesos na amostra
da Pesquisa sobre Padrões de Vida (PPV), realizada pelo IBGE nos anos
1996-97. \citep{albieri} descrevem resumidamente a Pesquisa sobre
Padrões de Vida (PPV), que foi realizada nas Regiões Nordeste e Sudeste
do País, considerando 10 estratos geográficos, a saber: Região
Metropolitana de Fortaleza, Região Metropolitana de Recife, Região
Metropolitana de Salvador, restante da área urbana do Nordeste, restante
da área rural do Nordeste, Região Metropolitana de Belo Horizonte,
Região Metropolitana do Rio de Janeiro, Região Metropolitana de São
Paulo, restante da área urbana do Sudeste e restante da área rural do
Sudeste.

O plano amostral empregado na seleção da amostra da PPV foi de dois
estágios, com estratificação das unidades primárias de amostragem (no
caso os setores censitários da base geográfica do IBGE conforme usada
para o Censo Demográfico de 1991), seleção destes setores com
probabilidade proporcional ao tamanho, e seleção aleatória das unidades
de segundo estágio (domicílios). O tamanho da amostra para cada estrato
geográfico foi fixado em 480 domicílios, e o número de setores
selecionados foi fixado em 60, com 8 domicílios selecionados em cada
setor. A exceção ficou por conta dos estratos que correspondem ao
restante da área rural de cada Região, onde foram selecionados 30
setores e 16 domicílios por setor, em função da dificuldade de acesso a
esses setores, o que implicaria em aumento de custo da coleta.

Os setores de cada um dos 10 estratos geográficos foram subdivididos em
3 estratos de acordo com a renda média mensal do chefe do domicílio por
setor, perfazendo um total de 30 estratos geográficos versus renda. Em
seguida foi feita uma alocação proporcional, com base no número de
domicílios particulares permanentes ocupados do estrato de renda no
universo de cada estrato geográfico, obtidos pelo Censo de 1991. No
final foram obtidos 554 setores na amostra, distribuídos tal como revela
a Tabela \ref{table:Tab11}.

\begin{center}
\begin{table}[htbp] \centering

\caption{Número de setores na população e na amostra, por estrato geográfico}
\bigskip \label{table:Tab11}
\begin{tabular}{|l|c|c|}
\hline\hline
& \multicolumn{2}{|l|}{Número de setores} \\ \cline{2-3}
\multicolumn{1}{|c|}{Estrato Geográfico} & População & Amostra
\\ \hline\hline
1-RM Fortaleza & \multicolumn{1}{|r|}{$2.263$} & \multicolumn{1}{|r|}{$62$}
\\ \hline
2-RM Recife & \multicolumn{1}{|r|}{$2.309$} & \multicolumn{1}{|r|}{$61$} \\
\hline
3-RM Salvador & \multicolumn{1}{|r|}{$2.186$} & \multicolumn{1}{|r|}{$61$}
\\ \hline
4-Restante Nordeste Urbano & \multicolumn{1}{|r|}{$15.057$} &
\multicolumn{1}{|r|}{$61$} \\ \hline
5-Restante Nordeste Rural & \multicolumn{1}{|r|}{$23.711$} &
\multicolumn{1}{|r|}{$33$} \\ \hline
6-RM Belo Horizonte & \multicolumn{1}{|r|}{$3.283$} & \multicolumn{1}{|r|}{$%
62$} \\ \hline
7-RM Rio de Janeiro & \multicolumn{1}{|r|}{$10.420$} & \multicolumn{1}{|r|}{$%
61$} \\ \hline
8-RM São Paulo & \multicolumn{1}{|r|}{$14.931$} & \multicolumn{1}{|r|}{$%
61$} \\ \hline
9-Restante Sudeste Urbano & \multicolumn{1}{|r|}{$25.855$} &
\multicolumn{1}{|r|}{$61$} \\ \hline
10-Restante Sudeste Rural & \multicolumn{1}{|r|}{$12.001$} &
\multicolumn{1}{|r|}{$31$} \\ \hline\hline
Total & \multicolumn{1}{|r|}{$112.016$} & \multicolumn{1}{|r|}{$554$} \\
\hline\hline
\end{tabular}
\end{table}
\end{center}

A Tabela \ref{table:Tab12} apresenta um resumo das distribuições dos
pesos amostrais para as Regiões Nordeste (5 estratos geográficos) e
Sudeste (5 estratos geográficos) separadamente e para o conjunto da
amostra da PPV.

\begin{center}
\begin{table}[htbp] \centering

\caption{Distribuição dos pesos da amostra da PPV}\bigskip \label{table:Tab12} 
\begin{tabular}{|c|r|c|r|c|r|}
\hline\hline
Região & Mínimo & Q1 & Mediana & Q3 & Máximo \\ \hline\hline
Nordeste & $724$ & \multicolumn{1}{|r|}{$1.159$} & $1.407$ & 
\multicolumn{1}{|r|}{$6.752$} & $15.348$ \\ 
Sudeste & $991$ & \multicolumn{1}{|r|}{$2.940$} & $5.892$ & 
\multicolumn{1}{|r|}{$10.496$} & $29.234$ \\ 
Nordeste + Sudeste & $724$ & \multicolumn{1}{|r|}{$1.364$} & $4.034$ & 
\multicolumn{1}{|r|}{$8.481$} & $29.234$ \\ \hline\hline
\end{tabular}

\end{table}

\end{center}

No cálculo dos pesos foram consideradas as probabilidades de inclusão
dos elementos na amostra bem como correções devido a não-resposta.
Contudo, a grande variabilidade dos pesos amostrais da PPV é devida à
variabilidade das probabilidades de inclusão na amostra, ilustrando
desta forma o ponto i) citado anteriormente nesta seção.

Na análise de dados desta pesquisa, deve-se considerar que há elementos
da amostra com pesos bem distintos. Por exemplo, a razão entre o maior e
o menor peso é cerca de 40 vezes. Tais pesos são utilizados para
\texttt{expandir} os dados, multiplicando-se cada observação pelo seu
respectivo peso. Assim, por exemplo, para \texttt{estimar} quantos
elementos \texttt{da\ população} pertencem a determinado conjunto
(domínio), basta somar os pesos dos elementos da amostra que pertencem a
este conjunto. É possível ainda incorporar os pesos, de maneira simples
e natural, quando estimamos medidas descritivas simples da população
tais como totais, médias, proporções, razões, etc.

Por outro lado, quando utilizamos a amostra para estudos analíticos, as
opções padrão disponíveis nos pacotes estatísticos usuais para levar em
conta os pesos distintos das observações são apropriadas somente para
observações independentes e identicamente distribuídas (IID). Por
exemplo, os procedimentos padrão disponíveis para estimar a média
populacional permitem utilizar pesos distintos das observações
amostrais, mas tratariam tais pesos como se fossem frequências de
observações repetidas na amostra, e portanto interpretariam a soma dos
pesos como tamanho amostral, situação que na maioria das vezes gera
inferências incorretas sobre a precisão das estimativas, pois o tamanho
da amostra é muito menor que a soma dos pesos amostrais usualmente
encontrados nos arquivos de microdados de pesquisas disseminados por
agências de estatísticas oficiais. Em tais pesquisas, a opção mais
freqüente é disseminar pesos que somados estimam o total de unidades
\texttt{da\ população}.

Além disso, a variabilidade dos pesos para distintas observações
amostrais produz impactos tanto na estimação pontual quanto na estimação
das variâncias dessas estimativas, que sofre ainda influência da
conglomeração e estratificação - pontos ii) e iii) mencionados
anteriormente.

Para exemplificar o impacto de ignorar os pesos e o plano amostral ao
estimar quantidades descritivas populacionais, tais como totais, médias,
proporções e razões, calculamos estimativas de quantidades desses
diferentes tipos usando a amostra da PPV juntamente com estimativas das
respectivas variâncias. Essas estimativas de variâncias foram calculadas
sob duas estratégias: considerando amostragem aleatória simples
(portanto ignorando o plano amostral efetivamente adotado), e
considerando o plano amostral da pesquisa e os pesos diferenciados das
unidades. A razão entre as estimativas de variância obtidas sob o plano
amostral verdadeiro e sob amostragem aleatória simples foi calculada
para cada uma das estimativas consideradas usando a library
\texttt{survey} do R \citep{R-survey} . Essa razão fornece uma medida do
efeito de ignorar o plano amostral . Os resultados das estimativas
ponderadas e variâncias considerando o plano amostral são apresentados
na Tabela \ref{table:Tab13}, juntamente com as medidas dos efeitos de
plano amostral (EPA). Exemplos de utilização da library \texttt{survey}
para obtenção de estimativas apresentadas na \ref{table:Tab13} estão na
Seção \ref{epa}. As outras estimativas da Tabela \ref{table:Tab13} podem
ser obtidas de maneira análoga.

\begin{center}

\begin{table}[htbp] \centering

\caption{Estimativas de Efeitos de Plano Amostral (EPAs)
para variáveis selecionadas da PPV - Região Sudeste }\bigskip \label{table:Tab13}
\begin{tabular}{|c|c|c|c|}
\hline\hline
\begin{tabular}{l}
Parâmetro \\
Populacional
\end{tabular}
\  & Estimativa &
\begin{tabular}{l}
Desvio \\
padrão
\end{tabular}
& \textbf{EPA } \\ \hline\hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
1) Número médio de \\
pessoas por domicílio
\end{tabular}
} & \multicolumn{1}{|r|}{$3,62$} & \multicolumn{1}{|r|}{$0,05$} &
\multicolumn{1}{|r|}{$2,64$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{r}
2) \% de domicílios alugados
\end{tabular}
} & \multicolumn{1}{|r|}{$16,70$} & \multicolumn{1}{|r|}{$1,15$} &
\multicolumn{1}{|r|}{$2,97$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
3) Número total de pessoas \\
que avaliaram seu estado de \\
de saúde como ruim
\end{tabular}
} & \multicolumn{1}{|r|}{$1.208.123$} & \multicolumn{1}{|r|}{$146.681$} &
\multicolumn{1}{|r|}{$3,37$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
4) Total de analfabetos \\
de 7 a 14 anos
\end{tabular}
} & \multicolumn{1}{|r|}{$1.174.220$} & \multicolumn{1}{|r|}{$127.982$} &
\multicolumn{1}{|r|}{$2,64$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
5) Total de analfabetos \\
de mais de 14 anos
\end{tabular}
} & \multicolumn{1}{|r|}{$4.792.344$} & \multicolumn{1}{|r|}{$318.877$} &
\multicolumn{1}{|r|}{$4,17$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
6) \% de analfabetos \\
de 7 a 14 anos
\end{tabular}
} & \multicolumn{1}{|r|}{$11,87$} & \multicolumn{1}{|r|}{$1,18$} &
\multicolumn{1}{|r|}{$2,46$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
7) \% de analfabetos \\
de mais de 14 anos
\end{tabular}
} & \multicolumn{1}{|r|}{$10,87$} & \multicolumn{1}{|r|}{$0,67$} &
\multicolumn{1}{|r|}{$3,86$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
8) Total de mulheres \\
de 12 a 49 anos \\
que tiveram filhos
\end{tabular}
} & \multicolumn{1}{|r|}{$10.817.590$} & \multicolumn{1}{|r|}{$322.947$} &
\multicolumn{1}{|r|}{$2,02$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
9) Total de mulheres \\
de 12 a 49 anos que \\
tiveram filhos vivos
\end{tabular}
} & \multicolumn{1}{|r|}{$10.804.511$} & \multicolumn{1}{|r|}{$323.182$} &
\multicolumn{1}{|r|}{$2,02$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
10) Total de mulheres \\
de 12 a 49 anos que \\
tiveram filhos mortos
\end{tabular}
} & \multicolumn{1}{|r|}{$709.145$} & \multicolumn{1}{|r|}{$87.363$} &
\multicolumn{1}{|r|}{$2,03$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
11) Número médio de \\
filhos tidos por mulheres \\
de 12 a 49 anos
\end{tabular}
} & \multicolumn{1}{|r|}{$1,39$} & \multicolumn{1}{|r|}{$0,03$} &
\multicolumn{1}{|r|}{$1,26$} \\ \hline
\multicolumn{1}{|l|}{
\begin{tabular}{l}
12) Razão de dependência
\end{tabular}
} & \multicolumn{1}{|r|}{$0,53$} & \multicolumn{1}{|r|}{$0,01$} &
\multicolumn{1}{|r|}{$1,99$} \\ \hline\hline
\end{tabular}
\end{table}
\end{center}

Como se pode observar da quarta coluna da Tabela \ref{table:Tab13}, os
valores do efeito do plano amostral variam de um modesto 1,26 para o
número médio de filhos tidos por mulheres em idade fértil (12 a 49 anos
de idade) até um substancial 4,17 para o total de analfabetos entre
pessoas de mais de 14 anos. Nesse último caso, usar a estimativa de
variância como se o plano amostral fosse amostragem aleatória simples
implicaria em subestimar consideravelmente a variância da estimativa
pontual, que é mais que 4 vezes maior se consideramos o plano amostral
efetivamente utilizado.

Note que as variáveis e parâmetros cujas estimativas são apresentadas na
Tabela \ref{table:Tab13} não foram escolhidas de forma a acentuar os
efeitos ilustrados, mas tão somente para representar distintos
parâmetros (médias, razões, totais, proporções) e variáveis de
interesse. Os resultados apresentados para as estimativas de EPA
ilustram bem o cenário típico em pesquisas amostrais complexas: o
impacto do plano amostral sobre a inferência varia conforme a variável e
o tipo de parâmetro de interesse. Note ainda que à exceção do menor
valor, todas as demais estimativas de EPA apresentaram valores
superiores a 2.

\section{Objetivos do Livro}\label{objetivos-do-livro}

Este livro tem três objetivos principais:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \textbf{ilustrar e analisar o impacto das simplificações feitas ao
  utilizar pacotes usuais de análise de dados quando estes são
  provenientes de pesquisas amostrais complexas};
\item
  \textbf{apresentar uma coleção de métodos e recursos computacionais
  disponíveis para análise de dados amostrais complexos, equipando o
  analista para trabalhar com tais dados, reduzindo assim o risco de
  inferências incorretas};
\item
  \textbf{ilustrar o potencial analítico de muitas das pesquisas
  produzidas por agências de estatísticas oficiais para responder
  questões de interesse, mediante uso de ferramentas de análise
  estatística agora já bastante difundidas, aumentando assim o valor
  adicionado destas pesquisas}.
\end{enumerate}

Para alcançar tais objetivos, adota-se uma abordagem fortemente ancorada
na apresentação de exemplos de análises de dados obtidos em pesquisas
amostrais complexas, usando pacotes clássicos e também recursos do
pacote estatístico R (\url{http://www.r-project.org/}). A comparação dos
resultados das análises feitas das duas formas permite avaliar o impacto
de não se considerar os pontos i) a iv) anteriormente citados. O ponto
iv) não será tratado de forma completa neste texto. O leitor interessado
na análise de dados sujeitos a não-resposta pode consultar
\citep{kalton83a}, \citep{LR2002}, \citep{Rubin87}, \citep{SSW92}, ou
Schafer (1997), por exemplo.

\textbf{Estrutura do Livro}

O livro está organizado em catorze capítulos. Este primeiro capítulo
discute a motivação para estudar o assunto e apresenta uma idéia geral
dos objetivos e da estrutura do livro.

No segundo capítulo, procuramos dar uma visão das diferentes abordagens
utilizadas na análise estatística de dados de pesquisas amostrais
complexas. Apresentamos um referencial para inferência com ênfase no
\texttt{Modelo\ de\ Superpopulação} que incorpora, de forma natural,
tanto uma estrutura estocástica para descrever a geração dos dados
populacionais (modelo) como o plano amostral efetivamente utilizado para
obter os dados amostrais (plano amostral). As referências básicas para
seguir este capítulo são cap2 em \citep{Silva}, cap1 em \citep{SHS89} e
caps 1 e 2 em \citep{CHSK2003}.

Esse referencial tem evoluído ao longo dos anos como uma forma de
permitir a incorporação de idéias e procedimentos de análise e
inferência usualmente associados à Estatística Clássica à prática da
interpretação de dados provenientes de pesquisas amostrais. Apesar dessa
evolução, sua adoção não é livre de controvérsia e uma breve revisão
dessa discussão é apresentada no Capítulo \ref{refinf}.

No Capítulo \ref{capplanamo} apresentamos uma revisão sucinta, a título
de recordação, de alguns resultados básicos da Teoria de Amostragem,
requeridos nas partes subseqüentes do livro. São discutidos os
procedimentos básicos para estimação de totais considerando o plano
amostral, e em seguida revistas algumas técnicas para estimação de
variâncias úteis para o caso de estatísticas complexas, tais como razões
e outras estatísticas requeridas na inferência analítica com dados
amostrais. As referências centrais para este capítulo são caps 2 e 3 em
\citep{SSW92}, \citep{W85} e \citep{cochran}.

No Capítulo \ref{epa} introduzimos o conceito de
\texttt{Efeito\ do\ Plano\ Amostral\ (EPA)}, que permite avaliar o
impacto de ignorar a estruturação dos dados populacionais ou do plano
amostral sobre a estimativa da variância de um estimador. Para isso,
comparamos o estimador da variância apropriado para dados obtidos por
amostragem aleatória simples (hipótese de AAS) com o valor esperado
deste mesmo estimador sob a distribuição de aleatorização induzida pelo
plano amostral efetivamente utilizado (plano amostral verdadeiro). Aqui
a referência principal foi o livro \citep{SHS89}, complementado com o
texto de \citep{lethonen}.

No Capítulo \ref{ajmodpar} estudamos a questão do uso de pesos ao
analisar dados provenientes de pesquisas amostrais complexas, e
introduzimos um método geral, denominado
\texttt{Método\ de\ Máxima\ Pseudo\ Verossimilhança(MPV)}, para
incorporar os pesos e o plano amostral na obtenção não só de estimativas
de parâmetros dos modelos regulares de interesse, como também das
variâncias dessas estimativas. As referências básicas utilizadas nesse
capítulo foram \citep{SHS89}, \citep{Pfeff}, \citep{binder83} e cap.6 em
\citep{Silva}.

O Capítulo \ref{modreg} trata da obtenção de
\texttt{Estimadores\ de\ Máxima\ Pseudo-Verossimilhança\ (EMPV)} e da
respectiva matriz de covariância para os parâmetros em modelos de
regressão linear e de regressão logística, quando os dados vêm de
pesquisas amostrais complexas. Apresentamos um exemplo de aplicação com
dados do Suplemento Trabalho da Pesquisa Nacional por Amostra de
Domicílios (PNAD) de 90, onde ajustamos um modelo de regressão
logística. Neste exemplo, são feitas comparações entre resultados de
ajustes obtidos através de um programa especializado, a library
\texttt{survey} (Lumley, 2004), e através de um programa de uso geral, a
library glm do pacote R. As referências centrais são cap6 em
\citep{Silva} e Binder(1983), além de \citep{Pessoa}.

Os Capítulos \ref{testqualajust} e \ref{testetab2} tratam da análise de
dados categóricos com ênfase na adaptação dos testes clássicos para
proporções, de independência e de homogeneidade em tabelas de
contingência, para dados provenientes de pesquisas amostrais complexas.
Apresentamos correções das estatísticas clássicas e a estatística de
Wald baseada no plano amostral. As referências básicas usadas nesses
capítulos foram os livros cap. 4, \citep{SHS89} e cap. 7
\citep{lethonen}. Também são apresentadas as idéias básicas de como
efetuar ajuste de modelos log-lineares a dados de freqüências em tabelas
de múltiplas entradas.

O Capítulo \ref{estimacao-de-densidades} trata da estimação de
densidades e funções de distribuição, ferramentas que tem assumido
importância cada dia maior com a maior disponibilidade de microdados de
pesquisas amostrais para analistas fora das agências produtoras.

O Capítulo \ref{modelos-hierarquicos} trata da estimação e ajuste de
modelos hierárquicos considerando o plano amostral. Modelos hierárquicos
(ou modelos multinível) têm sido bastante utilizados para explorar
situações em que as relações entre variáveis de interesse em uma certa
população de unidades elementares (por exemplo, crianças em escolas,
pacientes em hospitais, empregados em empresas, moradores em regiões,
etc.) são afetadas por efeitos de grupos determinados ao nível de
unidades conglomeradas (os grupos). Ajustar e interpretar tais modelos é
tarefa mais difícil que o mero ajuste de modelos lineares mesmo em casos
onde os dados são obtidos de forma exaustiva, mas ainda mais complicada
quando se trata de dados obtidos através de pesquisas amostrais
complexas. Várias alternativas de métodos para ajuste de modelos
hierárquicos estão disponíveis, e este capítulo apresenta uma revisão de
tais abordagens, ilustrando com aplicações a dados de pesquisas
amostrais de escolares.

O Capítulo \ref{nao-resposta} trata da não resposta e suas conseqüências
sobre a análise de dados. As abordagens de tratamento usuais,
reponderação e imputação, são descritas de maneira resumida, com
apresentação de alguns exemplos ilustrativos, e referências à ampla
literatura existente sobre o assunto. Em seguida destacamos a
importância de considerar os efeitos da não-resposta e dos tratamentos
compensatórios aplicados nas análises dos dados resultantes, destacando
em particular as ferramentas disponíveis para a estimação de variâncias
na presença de dados incompletos tratados mediante reponderação e/ou
imputação.

O Capítulo \ref{diagnostico-de-ajuste-de-modelo} trata de assunto ainda
emergente: diagnósticos do ajuste de modelos quando os dados foram
obtidos de amostras complexas. A literatura sobre o assunto ainda é
incipiente, mas o assunto é importante e procura-se estimular sua
investigação com a revisão do estado da arte no assunto.

O Capítulo \ref{agregdesag} discute algumas formas alternativas de
analisar dados de pesquisas complexas, contrapondo algumas abordagens
distintas à que demos preferência nos capítulos anteriores, para dar aos
leitores condições de apreciar de forma crítica o material apresentado
no restante deste livro. Entre as abordagens discutidas, há duas
principais: a denominada \texttt{análise\ desagregada}, e a abordagem
denominada \texttt{obtenção\ \ do\ modelo\ amostral} proposta por
\citep{PKR}. A chamada \texttt{análise\ desagregada} incorpora
explicitamente na análise vários aspectos do plano amostral utilizado
através do emprego de modelos hierárquicos \citep{bryk}. Em contraste, a
abordagem adotada nos oito primeiros capítulos é denominada
\texttt{análise\ agregada}, e procura \texttt{eliminar} da análise
efeitos tais como conglomeração induzida pelo plano amostral,
considerando tais efeitos como \texttt{ruídos} ou fatores de perturbação
que \texttt{atrapalham} o emprego dos procedimentos clássicos de
estimação, ajuste de modelos e teste de hipóteses.

A abordagem de \texttt{obtenção\ do\ modelo\ amostral} parte de um
modelo de superpopulação e procura derivar o modelo amostral (ou que
valeria para as observações da amostra obtida) considerando modelos para
as probabilidades de inclusão dadas as variáveis auxiliares e as
variáveis resposta de interesse. Uma vez obtidos tais modelos, seu
ajuste prossegue por métodos convencionais tais como máxima
verossimilhança ou mesmo MCMC (Markov Chain Monte Carlo).

Por último, no Capítulo \ref{pacotes}, listamos alguns pacotes
computacionais especializados disponíveis para a análise de dados de
pesquisas amostrais complexas. Sem pretender ser exaustiva ou detalhada,
essa revisão dos pacotes procura também apresentar suas características
mais importantes. Vários destes programas podem ser adquiridos
gratuitamente via \texttt{internet}, nos endereços fornecidos de seus
produtores. Com isto pretendemos indicar aos leitores o caminho mais
curto para permitir a implementação prática das técnicas e métodos aqui
discutidos.

Uma das características que procuramos dar ao livro foi o emprego de
exemplos com dados reais, retirados principalmente da experiência do
IBGE com pesquisas amostrais complexas. Embora a experiência de fazer
inferência analítica com dados desse tipo seja ainda incipiente no
Brasil, acreditamos ser fundamental difundir essas idéias para alimentar
um processo de melhoria do aproveitamento dos dados das inúmeras
pesquisas realizadas pelo IBGE e instituições congêneres, que permita ir
além da tradicional estimação de médias, totais, proporções e razões.
Esperamos com esse livro fazer uma contribuição a esse processo.

Uma dificuldade em escrever um livro como este vem do fato de que não é
possível começar do zero: é preciso assumir algum conhecimento prévio de
idéias e conceitos necessários à compreensão do material tratado.
Procuramos tornar o livro acessível para um estudante de fim de curso de
graduação em Estatística. Por essa razão optamos por não apresentar
provas de resultados e sempre que possível, apresentar os conceitos e
idéias de maneira intuitiva, juntamente com uma discussão mais formal
para dar solidez aos resultados apresentados. As provas de vários dos
resultados aqui discutidos se restringem a material disponível apenas em
artigos em periódicos especializados estrangeiros e portanto, são de
acesso mais difícil. Ao leitor em busca de maior detalhamento e rigor,
sugerimos consultar diretamente as inúmeras referências incluídas ao
longo do texto. Para um tratamento mais profundo do assunto, os livros
de \citep{SHS89} e \citep{CHSK2003} são as referências centrais a
pesquisar. Para aqueles querendo um tratamento ainda mais prático que o
nosso, o livro de \citep{lethonen} pode ser uma opção interessante.

\section{Laboratório de R do Capítulo 1.}\label{epa}

\BeginKnitrBlock{example}
\protect\hypertarget{ex:unnamed-chunk-2}{}{\label{ex:unnamed-chunk-2}}Utilização
da library survey do R para estimar totais e razões na PPV
\EndKnitrBlock{example} Os exemplos a seguir utilizam dados da Pesquisa
de Padrões de Vida (\texttt{PPV}) de 2004 do IBGE, cujo plano amostral
encontra-se descrito no Exemplo \ref{ex:distppv} . Inicialmente, vamos
ler os dados do arquivo \texttt{ppv1.R}, através do comando
\texttt{source}. Em seguida, vamos definir variáveis de interesse por
meio de transformação de variáveis existentes.

Criação das variáveis analf1,analf2, faixa1 e faixa2:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ppv1 <-}\StringTok{ }\KeywordTok{transform}\NormalTok{(ppv1, }\DataTypeTok{analf1 =} \NormalTok{((v04a01 ==}\StringTok{ }\DecValTok{2} \NormalTok{|}\StringTok{    }\NormalTok{v04a02 ==}\StringTok{ }\DecValTok{2}\NormalTok{) &}\StringTok{ }\NormalTok{(v02a08 >=}\StringTok{ }\DecValTok{7} \NormalTok{&}\StringTok{ }
\NormalTok{v02a08 <=}\StringTok{ }\DecValTok{14}\NormalTok{)) *}\StringTok{   }\DecValTok{1}\NormalTok{, }\DataTypeTok{analf2 =} \NormalTok{((v04a01 ==}\StringTok{ }\DecValTok{2} \NormalTok{|}\StringTok{ }\NormalTok{v04a02 ==}\StringTok{ }\DecValTok{2}\NormalTok{) &}\StringTok{ }
\NormalTok{(v02a08 >}\DecValTok{14}\NormalTok{)) *}\StringTok{ }\DecValTok{1}\NormalTok{, }\DataTypeTok{faixa1 =} \NormalTok{(v02a08 >=}\StringTok{ }\DecValTok{7} \NormalTok{&}\StringTok{ }\NormalTok{v02a08 <=}\StringTok{ }\DecValTok{14}\NormalTok{) *}\DecValTok{1}\NormalTok{, }\DataTypeTok{faixa2 =} \NormalTok{(v02a08 >}\StringTok{ }\DecValTok{14}\NormalTok{) *}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

A seguir, mostramos a utilização da library survey do R para obter
algumas estimativas da Tabela \ref{table:Tab13}. Vamos supor que os
dados da pesquisa estão contidos no data frame \texttt{ppv1}, que contém
as variáveis que caracterizam o plano amostral

\begin{itemize}
\tightlist
\item
  nsetor - conglomerados;
\item
  estratof - estratos;
\item
  pesof - pesos do plano amostral;
\end{itemize}

e variáveis de interesse tais como:

\begin{itemize}
\tightlist
\item
  regiao - regiões de abrangência: 1- Nordeste, 2- Sudeste;
\item
  analf1 - indicador de analfabeto na faixa etária de 7 a 14 anos;
\item
  analf2 - indicador de analfabeto na faixa etária acima de 14 anos;
\item
  faixa1 - indicador de idade entre 7 e 14 anos;
\item
  faixa2 - indicador de idade acima de 14 anos;
\end{itemize}

O passo fundamental para utilização da library \texttt{survey} é criar
um objeto que guarde as informações relevantes do plano amostral. Isso é
feito por meio da função \texttt{svydesign}. As variáveis que definem
estratos, conglomerados e pesos na \texttt{PPV} são respectivamente,
\texttt{estratof}, \texttt{nsetor} e \texttt{pesof}. O objeto de desenho
amostral, \texttt{ppv.des} incorpora as informações do plano amostral
adotado na \texttt{PPV}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(survey)}
\NormalTok{ppv.des<-}\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =} \NormalTok{~nsetor, }\DataTypeTok{strata =} \NormalTok{~estratof,}
\DataTypeTok{data =} \NormalTok{ppv1, }\DataTypeTok{nest =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{weights =} \NormalTok{~pesof)}
\end{Highlighting}
\end{Shaded}

Como todos os exemplos a seguir serão relativos a estimativas na Região
Sudeste, vamos restringir o desenho a esse domínio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ppv.se.des <-}\StringTok{ }\KeywordTok{subset}\NormalTok{(ppv.des, regiao ==}\StringTok{ }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para exemplificar, vamos estimar algumas características da população,
descritas na Tabela \ref{table:Tab13}. Os totais das variáveis
\texttt{analf1} e \texttt{analf2} para a região Sudeste fornecem os
resultados nas linhas 4) e 5 da Tabela \ref{table:Tab13}:

Vamos estimar os totais de analfabetos nas faixas etárias de 7 a 14 anos
e acima de 14 anos.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svytotal}\NormalTok{(~analf1, ppv.se.des, }\DataTypeTok{deff =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          total      SE   DEff
## analf1 1174220  127982 2.0543
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svytotal}\NormalTok{(~analf2, ppv.se.des, }\DataTypeTok{deff =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          total      SE   DEff
## analf2 4792344  318877 3.3237
\end{verbatim}

Queremos ainda estimar o percentual de analfabetos nas faixas etárias
consideradas, que fornece os resultados nas linhas 6 e 7 da Tabela
\ref{table:Tab13}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svyratio}\NormalTok{(~analf1, ~faixa1, ppv.se.des)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Ratio estimator: svyratio.survey.design2(~analf1, ~faixa1, ppv.se.des)
## Ratios=
##          faixa1
## analf1 0.118689
## SEs=
##            faixa1
## analf1 0.01178896
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svyratio}\NormalTok{(~analf2, ~faixa2, ppv.se.des)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Ratio estimator: svyratio.survey.design2(~analf2, ~faixa2, ppv.se.des)
## Ratios=
##           faixa2
## analf2 0.1086871
## SEs=
##             faixa2
## analf2 0.006732254
\end{verbatim}

Na library \texttt{survey}, uma alternativa para estimar por domínio é
utililizar a função \texttt{svyby}. Poderíamos estimar os totais da
variável \texttt{analf1} para as regiões \texttt{Nordeste\ (1)} e
\texttt{Sudeste(2)} da seguinte forma:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svyby}\NormalTok{(~analf1, ~regiao, ppv.des, svytotal, }\DataTypeTok{deff =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   regiao  analf1       se DEff.analf1
## 1      1 3512866 352619.5    9.660561
## 2      2 1174220 127982.2    2.054345
\end{verbatim}

Observe que as estimativas de totais e desvios padrão obtidas coincidem
com as Tabela \ref{table:Tab13}, porém as estimativas de Efeitos de
Plano Amostral(DEff) são distintas.

\subsection{Estimativa do efeito de plano amostral
(EPA)}\label{estimativa-do-efeito-de-plano-amostral-epa}

Esse assunto será tratado em detalhes no Capítulo \ref{epa} . Por
enquanto, apresentaremos uma introdução necessária para compreender os
valores na Tabela \ref{table:Tab13}.

O efeito de plano amostral (EPA) de Kish é definido na fórmula
\eqref{eq:epa1}, na página 54 do livro. Vamos considerar o caso particular
em que \(\hat{\theta}\) é um estimador de total de uma variável \(Y\).Ou
seja \[
EPA_{Kish}\left(\widehat{Y}\right)=\frac{V_{VERD}\left(\widehat{Y}\right)}{V_{AAS}\left(\widehat{Y}\right)}
\]

Na definição do EPA, a estimativa do numerador pode ser obtida
diretamente a partir da library \texttt{survey}, a partir do objeto de
\texttt{ppv.se.des} que incorpora as características do plano amostral
utilizado para coletar os dados. Não é possível estimar diretamente o
denominador, pois o plano amostral AAS (Amostragem Aleatória Simples)
não foi adotado na coleta dos dados. Devemos estimar o denominador a
partir de dados obtidos através do plano amostral VERD, como se eles
tivessem sido obtidos através de AAS. Supondo conhecido o tamanho da
população \(N\) e a fração amostral \(f=n/N\) pequena, a estimativa da
variância de \(\widehat{Y}\) é dada na expressão @ref:\label{eq:estpa9} \[
\widehat{V}_{AAS}\left(\widehat{Y}\right)=N^2\frac{\widehat{S}_y}{n-1}
\] onde
\(\widehat{S}_y= n^{-1}\sum_{i\in s}\left(y_i-\overline{y}\right)^2\) é
a estimativa de
\(S_y=N^{-1}\sum_{i\in U}\left(y_i-\overline{Y}\right)^2\), com
\(\overline{Y}=N^{-1}Y\).

No lugar dessa estimativa, vamos utilizar os pesos do plano amostral
verdadeiro para estimar \(S_y\). Vamos ainda estimar \(N\), em geral é
desconhecido, por \(\widehat{N}=\sum_{i \in s} w_i\). Dessa forma
obtemos a estimativa

\begin{eqnarray*}
\widehat{V}_{w-AAS}\left(\widehat{Y}\right)&=& \widehat{N}^2\left[\sum_{i \in s}w_i\left(y_i-\overline{y}\right)^2/\widehat{N}\right]/(n-1)\\
&=&\frac{\widehat{N}}{n-1}\left[\sum_{i \in s}w_iy_i^2-\left(\sum_{i \in s}w_iy_i\right)^2/\widehat{N}\right],
\end{eqnarray*}

onde \(\overline{y}=\sum_{i \in s}w_iy_i/n\).

A expressão acima pode ser calculada facilmente através da seguinte
função do R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Vwaas<-function(y,w)}
\NormalTok{\{}
\CommentTok{#função auxiliar usada em outras funções}
\CommentTok{#entrada:}
\CommentTok{#y - valores de variavel na amostra;}
\CommentTok{#w - pesos amostrais;}
\CommentTok{#saida:  estimativa de variância de desenho para o total (segundo o SUDAAN)}

\NormalTok{n1<-}\KeywordTok{length}\NormalTok{(y)-}\DecValTok{1}
\NormalTok{wsum<-}\KeywordTok{sum}\NormalTok{(y*w)}
\NormalTok{wsum2<-}\KeywordTok{sum}\NormalTok{((y^}\DecValTok{2}\NormalTok{)*w)}
\NormalTok{nhat<-}\KeywordTok{sum}\NormalTok{(w)}
\NormalTok{vwaas<-(nhat/n1)*(wsum2-wsum^}\DecValTok{2}\NormalTok{/nhat)}
\NormalTok{vwaas}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Vamos utilizar a função \texttt{Vwaas} para estimar os valores de
\texttt{Efeitos\ do\ Plano\ Amostral} das estimativas de totais
apresentadas anteriormente. Consideremos o plano amostral
\texttt{ppv.se.des} anteriormente definido. Vamos usar a função
\texttt{Vwaas} para obter uma estimativa da variância do total estimado
da variável \texttt{analf1}. Todos os elementos os elementos necessários
estão contidos no objeto \texttt{ppv.se.des}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VAAS1<-}\StringTok{ }\KeywordTok{Vwaas}\NormalTok{(ppv.se.des$variables[,}\StringTok{"analf1"}\NormalTok{],}\KeywordTok{weights}\NormalTok{(ppv.se.des))}
\NormalTok{VAAS2<-}\StringTok{ }\KeywordTok{Vwaas}\NormalTok{(ppv.se.des$variables[,}\StringTok{"analf2"}\NormalTok{],}\KeywordTok{weights}\NormalTok{(ppv.se.des))}
\end{Highlighting}
\end{Shaded}

O efeito de plano amostral da estimativa do total de \texttt{analf1}
pode agora ser calculada por

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{attr}\NormalTok{(}\KeywordTok{svytotal}\NormalTok{(~analf1, ppv.se.des),}\StringTok{"var"}\NormalTok{)/VAAS1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          analf1
## analf1 2.054049
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{attr}\NormalTok{(}\KeywordTok{svytotal}\NormalTok{(~analf2, ppv.se.des),}\StringTok{"var"}\NormalTok{)/VAAS2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         analf2
## analf2 3.32324
\end{verbatim}

Esses valores do EPA coicidem com os obtidos acima através da library
survey e são distintos daqueles apresentados na Tabela
\ref{table:Tab13}. Para obter os valores correspondentes aos da Tabela
\ref{table:Tab13}, através da library survey, vamos definir as
variáveis:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{analf1.se<-}\KeywordTok{with}\NormalTok{(ppv1,((v04a01==}\DecValTok{2}\NormalTok{|v04a02==}\DecValTok{2}\NormalTok{) &}\StringTok{ }\NormalTok{(v02a08>=}\DecValTok{7}\NormalTok{&v02a08<=}\DecValTok{14}\NormalTok{))&(regiao==}\DecValTok{2}\NormalTok{))}
\NormalTok{analf2.se<-}\KeywordTok{with}\NormalTok{(ppv1,((v04a01==}\DecValTok{2}\NormalTok{|v04a02==}\DecValTok{2}\NormalTok{) &}\StringTok{ }\NormalTok{(v02a08>}\DecValTok{14}\NormalTok{))&(regiao==}\DecValTok{2}\NormalTok{))}
\NormalTok{ppv.des <-}\StringTok{ }\KeywordTok{update} \NormalTok{(ppv.des,}\DataTypeTok{analf1.se=}\NormalTok{analf1.se,}\DataTypeTok{analf2.se=}\NormalTok{analf2.se  )}
\KeywordTok{svytotal}\NormalTok{(analf1.se,ppv.des,}\DataTypeTok{deff=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        total      SE   DEff
## [1,] 1174220  127982 2.6426
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svytotal}\NormalTok{(analf2.se,ppv.des,}\DataTypeTok{deff=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        total      SE   DEff
## [1,] 4792344  318877 4.1667
\end{verbatim}

Ou, alternativamente,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svytotal}\NormalTok{(~}\KeywordTok{I}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{(regiao==}\DecValTok{2}\NormalTok{,analf1,}\DecValTok{0}\NormalTok{)),ppv.des,}\DataTypeTok{deff=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                     total      SE   DEff
## I(ifelse(regiao == 2, analf1, 0)) 1174220  127982 2.6426
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{svytotal}\NormalTok{(~}\KeywordTok{I}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{(regiao==}\DecValTok{2}\NormalTok{,analf2,}\DecValTok{0}\NormalTok{)),ppv.des,}\DataTypeTok{deff=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                     total      SE   DEff
## I(ifelse(regiao == 2, analf2, 0)) 4792344  318877 4.1667
\end{verbatim}

Observe que as estimativas de variância para o desenho verdadeiro
(numerador do EPA) são iguais quando usamos: a variável
\texttt{analf1.se} com o objeto de desenho \texttt{ppv.des} ou a
variável \texttt{analf1} com o objeto \texttt{ppv.se.des}. Porém na
estimativa do denominador do EPA, obtida a partir da função
\texttt{Vwaas}, obtemos resultados diferentes quando usamos
\texttt{analf1.se} ou \texttt{analf1}, com os pesos correspondentes. No
segundo caso, a soma dos pesos não estima \(N\). Deve-se ter o cuidado,
quando estimamos em um domínio, de trabalhar com pesos cuja soma seja um
estimador do tamanho da população.

\BeginKnitrBlock{example}
\protect\hypertarget{ex:unnamed-chunk-15}{}{\label{ex:unnamed-chunk-15}}Utilização
da library survey do R para estimar taxa de desocupação para um
trimestre na PNADC
\EndKnitrBlock{example}

\begin{itemize}
\tightlist
\item
  Instala library lodown do github:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(devtools)}
\KeywordTok{install_github}\NormalTok{(}\StringTok{"ajdamico/lodown"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  carrega a library para ler os dados da PNADC
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lodown)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Baixa catálogo da PNADC com arquivos disponíveis:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pnadc_cat <-}\StringTok{ }\KeywordTok{get_catalog}\NormalTok{( }\StringTok{"pnadc"} \NormalTok{, }\DataTypeTok{output_dir =}\KeywordTok{tempdir}\NormalTok{() )}
\end{Highlighting}
\end{Shaded}

Os microdados de interesse são terceiro trimestre de 2016. Vamos ler os
microdados e salvá-los em um data frame \texttt{x}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lodown}\NormalTok{( }\StringTok{"pnadc"} \NormalTok{, }\KeywordTok{subset}\NormalTok{( pnadc_cat , year ==}\StringTok{ }\DecValTok{2016} \NormalTok{&}\StringTok{ }\NormalTok{quarter ==}\StringTok{ '03'} \NormalTok{) )}
\NormalTok{x <-}\StringTok{ }\KeywordTok{readRDS}\NormalTok{( }\KeywordTok{paste0}\NormalTok{( }\KeywordTok{tempdir}\NormalTok{() , }\StringTok{"/pnadc 2016 03.rds"} \NormalTok{) )}
\end{Highlighting}
\end{Shaded}

vamos salvar o data frame \texttt{x} para uso posterior, :

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{saveRDS}\NormalTok{(x, }\DataTypeTok{file=}\StringTok{"C:/adac/pnadc/pnadc 2016 03.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Partindo do arquivo \texttt{pnadc\ 2016\ 03.rds}, podemos recuperar o
data frame \texttt{x}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x <-}\StringTok{ }\KeywordTok{readRDS}\NormalTok{(}\StringTok{"C:/adac/pnadc/pnadc 2016 03.rds"}\NormalTok{)}
\KeywordTok{dim}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 572023    170
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Carrega a library \texttt{survey}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(survey)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Fixa opção para caso de UPA única no estrato
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{options}\NormalTok{( }\DataTypeTok{survey.lonely.psu =} \StringTok{"adjust"} \NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Cria versão inicial de objeto de desenho:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pre_w <-}\StringTok{ }\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =}\NormalTok{~upa, }\DataTypeTok{strata=}\NormalTok{~estrato, }
  \DataTypeTok{weights=}\NormalTok{~v1027, }\DataTypeTok{data =} \NormalTok{x, }\DataTypeTok{nest=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Especifica totais de pós-estratos na população:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df_pos <-}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{posest=}\KeywordTok{unique}\NormalTok{(x$posest), }
  \DataTypeTok{Freq=}\KeywordTok{unique}\NormalTok{(x$v1029))}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Pós-estratifica objeto de desenho inicial:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w <-}\KeywordTok{postStratify}\NormalTok{(pre_w, ~posest, df_pos)}
\end{Highlighting}
\end{Shaded}

Para calcular a taxa de desocupação, o IBGE considera pessoas de 14 anos
ou mais (PIA) na semana de referência e calcula a razão de dois totais:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Numerador: total de pessoas desocupadas (vd4002==2)
\item
  Denominador: total de pessoas na força de trabalho (vd4001==1)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# estima taxa de desocupação}
\NormalTok{taxa_des <-}\StringTok{ }\KeywordTok{svyratio}\NormalTok{(~}\StringTok{ }\NormalTok{vd4002==}\StringTok{"2"} \NormalTok{,}
  \NormalTok{~}\StringTok{ }\NormalTok{vd4001 ==}\StringTok{ "1"} \NormalTok{, w , }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{# organiza saída}
\NormalTok{result <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DecValTok{100}\NormalTok{*}\KeywordTok{coef}\NormalTok{(taxa_des),}
  \DecValTok{100}\NormalTok{*}\KeywordTok{SE}\NormalTok{(taxa_des), }
  \DecValTok{100}\NormalTok{*}\KeywordTok{cv}\NormalTok{(taxa_des)}
\NormalTok{)}
\KeywordTok{row.names}\NormalTok{(result)<-}\StringTok{ }\OtherTok{NULL}
\KeywordTok{names}\NormalTok{(result) <-}\OtherTok{NULL}
\KeywordTok{names}\NormalTok{(result) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Taxa"}\NormalTok{, }\StringTok{"Erro_Padrao"}\NormalTok{, }\StringTok{"CV"}\NormalTok{)}
\CommentTok{# taxa de desocupação}
\NormalTok{result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Taxa Erro_Padrao        CV
## 1 11.80303   0.1174791 0.9953299
\end{verbatim}

\chapter{Referencial para Inferência}\label{refinf}

\chapter{Estimação Baseada no Plano Amostral}\label{capplanamo}

\chapter{Efeitos do Plano Amostral}\label{epa}

\chapter{Ajuste de Modelos Paramétricos}\label{ajmodpar}

\chapter{Modelos de Regressão}\label{modreg}

\chapter{Testes de Qualidade de Ajuste}\label{testqualajust}

\chapter{Testes em Tabelas de Duas Entradas}\label{testetab2}

\chapter{Estimação de densidades}\label{estimacao-de-densidades}

\chapter{Modelos Hierárquicos}\label{modelos-hierarquicos}

\chapter{Não-Resposta}\label{nao-resposta}

\chapter{Diagnóstico de ajuste de
modelo}\label{diagnostico-de-ajuste-de-modelo}

\chapter{Agregação vs.~Desagregação}\label{agregdesag}

\chapter{Pacotes para Analisar Dados Amostrais}\label{pacotes}

\chapter{Placeholder}\label{placeholder}

\bibliography{packages,book}


\end{document}
