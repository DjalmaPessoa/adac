# Introdução {#introduc}


## Motivação

Este livro trata de problema de grande importância para os analistas
de dados obtidos através de pesquisas amostrais, tais como as conduzidas
por agências produtoras de informações estatísticas oficiais ou públicas. 
Tais dados são comumente utilizados em análises descritivas envolvendo 
a obtenção de estimativas para totais, médias, proporções e razões. 
Nessas análises, em geral, são devidamente incorporados os pesos distintos das
observações e a estrutura do plano amostral empregado para obter os dados
considerados.

Nas três últimas décadas tem se tornado mais frequente um outro tipo de uso 
de dados de pesquisas amostrais. Tal uso, denominado secundário e/ou analítico, 
envolve a construção e ajuste de modelos, geralmente feitos por analistas que 
trabalham fora das agências produtoras dos dados. Neste caso, o foco da análise 
busca estabelecer a natureza de relações ou associações entre variáveis ou testar
hipóteses. Para tais fins, a estatística clássica conta com um vasto arsenal 
de ferramentas de análise, já incorporado aos principais pacotes estatísticos
disponíveis (tais como MINITAB, R, SAS, SPSS, etc). 

As ferramentas de análise convencionais disponíveis nesses pacotes estatísticos
geralmente partem de hipóteses básicas que só são válidas quando os dados 
foram obtidos através de amostras aleatórias simples com reposição (AASC). 
Tais hipóteses são geralmente inadequadas para modelar observações provenientes 
de amostras de populações finitas, pois desconsideram os seguintes aspectos 
relevantes dos planos amostrais usualmente empregados nas pesquisas amostrais:


i.)  **probabilidades distintas de seleção das unidades**;

ii.) **conglomeração das unidades**;

iii.) **estratificação**;

iv.)  **calibração ou imputação para não-resposta e outros ajustes**.


As estimativas pontuais de parâmetros descritivos da população ou 
de modelos são influenciadas por pesos distintos das observações. Além disso,
as estimativas de variância (ou da precisão dos estimadores) são influenciadas
pela conglomeração, estratificação e pesos, ou no caso de não resposta, 
também por eventual imputação de dados faltantes ou reponderação das observações
disponíveis. Ao ignorar estes aspectos, os pacotes tradicionais de análise 
podem produzir estimativas incorretas das variâncias das estimativas pontuais.

O exemplo a seguir considera o uso de dados de uma pesquisa amostral real 
conduzida pelo IBGE para ilustrar como os pontos i) a iv) acima mencionados 
afetam a inferência sobre quantidades descritivas populacionais tais como
totais, médias, proporções e razões. 

```{example, label="distppv"}
Distribuição dos pesos da amostra da PPV
```

Os dados deste exemplo são relativos à distribuição dos
pesos na amostra da Pesquisa sobre Padrões de Vida (PPV), realizada pelo
IBGE nos anos 1996-97. [@albieri] descrevem resumidamente a PPV, que foi 
realizada nas Regiões Nordeste e Sudeste do País. 

O plano amostral empregado na seleção da amostra da PPV foi estratificado e
conglomerado em dois estágios, com alocação desproporcional da amostra 
nos estratos geográficos. A estratificação considerou inicialmente 10 estratos 
geográficos conforme listados na Tabela \@ref(tab:numset). 

As unidades primárias de amostragem (UPAs) foram os setores censitários 
da base geográfica do IBGE conforme usada para o Censo Demográfico de 1991. 
A seleção dos setores dentro de cada estrato foi feita com probabilidade 
proporcional ao tamanho. Os domicílios foram as unidades de segundo estágio, 
selecionados por amostragem aleatória simples sem reposição em cada setor 
selecionado, após a atualização do cadastro de domicílios do setor.

Em cada um dos 10 estratos geográficos, os setores foram subdivididos em
três estratos de acordo com a renda média mensal do chefe do domicílio
por setor, perfazendo um total de 30 estratos finais para seleção da amostra.

O tamanho da amostra para cada estrato geográfico foi fixado em 480 domicílios, 
e o número de setores selecionados foi fixado em 60, com 8 domicílios 
sendo selecionados em cada setor. A exceção ficou por conta dos estratos que 
correspondiam ao restante da área rural de cada Região, onde foram 
selecionados 30 setores e com 16 domicílios selecionados por setor, 
em função da maior dificuldade de acesso a esses setores, o que implicaria
em aumento de custo da coleta caso fosse mantido o mesmo tamanho da amostra
do segundo estágio em cada setor.

A alocação da amostra dentro de cada estrato geográfico foi proporcional ao 
número de domicílios particulares permanentes ocupados do estrato de renda 
no Censo de 1991. No final foram incluídos 554 setores na amostra, 
distribuídos tal como mostrado na Tabela \@ref(tab:numset).


```{r, numset, echo=FALSE}
estrat <- data.frame (
 Estrato_Geográfico =
 c("Região Metropolitana de Fortaleza", "Região Metropolitana de Recife", 
   "Região Metropolitana de Salvador", "Restante Nordeste Urbano", 
   "Restante Nordeste Rural", "Região Metropolitana de Belo Horizonte", 
   "Região Metropolitana do Rio de Janeiro", "Região Metropolitana de São Paulo",
   "Restante Sudeste Urbano", "Restante Sudeste Rural", "Total"),
 População = c(2263, 2309,2186,15057,23711,3283, 10420, 14931, 25855, 
               12001, 112016), 
 Amostra = c(62, 61, 61, 61, 33, 62, 61, 61, 61,31,554)
    )
knitr::kable(estrat, booktabs = TRUE, align= "lrr",
             format.args= list(big.mark = '.'),
  caption = "Número de setores na população e na amostra, por estrato geográfico"
  )
```

A Tabela \@ref(tab:dispesos) apresenta um resumo das distribuições dos pesos
amostrais para as Regiões Nordeste (5 estratos geográficos) e
Sudeste (5 estratos geográficos) separadamente, e para o conjunto da
amostra da PPV.


```{r, dispesos, echo=FALSE}
# leitura dos dados
library(tidyverse)
library(anamco)
ppv <- transform(ppv,
                 regiao=factor(regiao,  
                               labels = c("Nordeste", "Sudeste")))
regiao <- group_by(ppv, regiao) %>%
          summarise(Minimo=min(pesof),
                    Quartil_1    =quantile(pesof, 0.25),
                    Mediana=quantile(pesof, 0.50),
                    Quartil_3    =quantile(pesof, 0.75),
                    Maximo=max(pesof))
global <- summarise(ppv,
                    Minimo=min(pesof),
                    Quartil_1    =quantile(pesof, 0.25),
                    Mediana=quantile(pesof, 0.50),
                    Quartil_3    =quantile(pesof, 0.75),
                    Maximo=max(pesof))
global <- transform(global, 
                    regiao=factor("3", labels=c("Nordeste+Sudeste")))
resumo_pesos <- data.frame(rbind(regiao, global))
names(resumo_pesos) <- c("Região", "Mínimo", "Quartil 1",
                         "Mediana", "Quartil 3", "Máximo")
knitr::kable(resumo_pesos , booktabs = TRUE, 
             align = "lrrrrr",
             format.args= list(big.mark = '.'),
             caption = "Resumos da distribuição dos pesos da amostra da PPV")
```


No cálculo dos pesos amostrais foram consideradas as probabilidades de
inclusão dos elementos na amostra, bem como correções devido à
não-resposta. Contudo, a grande variabilidade dos pesos amostrais da PPV
é devida, principalmente, à variabilidade das probabilidades de inclusão na
amostra, ilustrando desta forma o ponto i) citado anteriormente nesta seção.

Na análise de dados desta pesquisa, deve-se considerar que há
elementos da amostra com pesos muito distintos. Por exemplo, a razão entre
o maior e o menor peso é cerca de 40 vezes. Os pesos também variam bastante 
entre as regiões, com mediana 3,5 vezes maior na região Sudeste quando 
comparada com a região Nordeste, em função da alocação desproporcional da
amostra nas regiões.

Tais pesos são utilizados para `expandir` os dados, multiplicando-se 
cada observação pelo seu respectivo peso. Assim, por exemplo, para `estimar`
quantos elementos `da população` pertencem a determinado conjunto (domínio), 
basta somar os pesos dos elementos da amostra que pertencem a este conjunto. 
É possível ainda incorporar os pesos, de maneira simples e natural, quando 
estimamos medidas descritivas simples da população tais como totais, médias, 
proporções, razões, etc.

Por outro lado, quando utilizamos a amostra para estudos analíticos, as
opções padrão disponíveis nos pacotes estatísticos usuais para
levar em conta os pesos distintos das observações são
apropriadas somente para observações independentes e identicamente
distribuídas (IID). Por exemplo, os procedimentos padrão disponíveis para
estimar a média populacional permitem utilizar pesos distintos das observações amostrais,
mas tratariam tais pesos como se fossem frequências de observações repetidas na amostra, 
e portanto interpretariam a soma dos pesos como tamanho amostral, situação que
na maioria das vezes gera inferências incorretas sobre a precisão das estimativas.
Isto ocorre pois o tamanho da amostra é muito menor que a soma dos pesos amostrais 
usualmente encontrados nos arquivos de microdados de pesquisas disseminados 
por agências de estatísticas oficiais. Em tais pesquisas, a opção mais freqüente 
é disseminar pesos que, quando somados, estimam o total de unidades `da população`. 

Além disso, a variabilidade dos pesos para distintas observações amostrais
produz impactos tanto na estimação pontual quanto na estimação das
variâncias dessas estimativas, que sofre ainda influência da conglomeração 
e da estratificação - pontos ii) e iii) mencionados anteriormente.

Para exemplificar o impacto de ignorar os pesos e o plano amostral ao
estimar quantidades descritivas populacionais, tais como totais, médias,
proporções e razões, calculamos estimativas de quantidades desses diferentes 
tipos usando a amostra da PPV juntamente com estimativas das
respectivas variâncias. Tais estimativas de variância foram
calculadas sob duas estratégias: a) considerando amostragem
aleatória simples (portanto ignorando o plano amostral efetivamente
adotado na pesquisa), e b) considerando o plano amostral da pesquisa e os pesos
diferenciados das unidades. 

A razão entre as estimativas de variância obtidas sob o plano amostral 
verdadeiro e sob amostragem aleatória simples foi calculada para cada uma
das estimativas consideradas usando o pacote `survey` do R [@R-survey]. 
Essa razão fornece uma medida do efeito de ignorar o plano amostral. 
Os resultados das estimativas ponderadas e variâncias considerando o plano 
amostral são apresentados na Tabela \@ref(tab:epas), juntamente com as 
medidas dos efeitos de plano amostral (EPA). 

Exemplos de utilização do pacote `survey` para obtenção de estimativas 
apresentadas na \@ref(tab:epas) estão na Seção \@ref(epa). As outras 
estimativas da Tabela \@ref(tab:epas) podem ser obtidas de maneira análoga.

Na Tabela \@ref(tab:epas) apresentamos as estimativas dos seguintes parâmetros populacionais:

 1. Número médio de pessoas por domicílio;
 2. % de domicílios alugados;
 3. Número total de pessoas que avaliaram seu estado de de saúde como ruim;
 4. Total de analfabetos de 7 a 14 anos;
 5. Total de analfabetos de mais de 14 anos;
 6. % de analfabetos de 7 a 14 anos;
 7. % de analfabetos de mais de 14 anos;
 8. Total de mulheres de 12 a 49 anos que tiveram filhos;
 9. Total de mulheres de 12 a 49 anos que tiveram filhos vivos;
10. Total de mulheres de 12 a 49 anos que tiveram filhos mortos;
11. Número médio de filhos tidos por mulheres de 12 a 49 anos;
12. Razão de dependência.



```{r,epas, echo=FALSE}
epas <- data.frame(
"Parâmetro" = c("1.", "2.", "3.", "4.", "5.", "6.", "7.",
  "8.", "9.", "10.", "11.","12."),  
Estimativa = c(3.62, 10.70, 1208123, 1174220,4792344, 11.87, 10.87, 10817590, 10804511,709145,1.39,0.53),
"Erro Padrão"=c(0.05, 1.15, 146681, 127982, 318877, 1.18, 0.67, 322947, 323182, 87363, 0.03, 0.01),
"EPA"= c(2.64, 2.97, 3.37,2.64, 4.17,2.46, 3.86, 2.02, 3.02, 2.03, 1.26, 1.99 )
)
knitr::kable(epas, booktabs=TRUE, align = "crrr",
             format.args= list(big.mark = '.', decimal.mark=","),
caption="Estimativas de Efeitos de Plano Amostral (EPAs)
para variáveis selecionadas da PPV - Região Sudeste"
)

```


Como se pode observar da quarta coluna da Tabela \@ref(tab:epas), os valores do
efeito do plano amostral variam de um modesto 1,26 para o número
médio de filhos tidos por mulheres em idade fértil (12 a 49 anos de
idade) até um substancial 4,17 para o total de analfabetos entre pessoas
de mais de 14 anos. Nesse último caso, usar a estimativa de
variância como se o plano amostral fosse amostragem aleatória
simples implicaria em subestimar consideravelmente a variância da
estimativa pontual, que é mais que 4 vezes maior se consideramos o plano
amostral efetivamente utilizado.

Note que as variáveis e parâmetros cujas estimativas são apresentadas 
na Tabela \@ref(tab:epas) não foram escolhidas de forma a acentuar os 
efeitos ilustrados, mas tão somente para representar distintos parâmetros 
(totais, médias, proporções, razões) e variáveis de interesse. Os resultados 
apresentados para as estimativas de EPA ilustram bem o cenário típico em pesquisas
amostrais complexas: o impacto do plano amostral sobre a inferência varia conforme
a variável e o tipo de parâmetro de interesse. Note ainda que, à exceção dos dois
menores valores (1,26 e 1,99), todas as demais estimativas de EPA apresentaram 
valores superiores a 2.

## Objetivos do Livro

Este livro tem três objetivos principais:

1)  **Ilustrar e analisar o impacto das simplificações feitas ao utilizar pacotes
usuais de análise de dados quando estes são provenientes de pesquisas amostrais 
complexas**;

2) **Apresentar uma coleção de métodos e recursos computacionais disponíveis para
análise de dados amostrais complexos, equipando o analista para trabalhar com 
tais dados, reduzindo assim o risco de inferências incorretas**;

3) **Ilustrar o potencial analítico de muitas das pesquisas produzidas por agências
de estatísticas oficiais para responder questões de interesse, mediante uso de 
ferramentas de análise estatística agora já bastante difundidas, aumentando assim
o valor adicionado destas pesquisas**.


Para alcançar tais objetivos, adotamos uma abordagem fortemente ancorada na 
apresentação de exemplos de análises de dados obtidos em pesquisas amostrais complexas,
usando os recursos do pacote estatístico R (http://www.r-project.org/). 

A comparação dos resultados de análises feitas das duas formas (considerando ou 
ignorando o plano amostral) permite avaliar o impacto de não se considerar os pontos i)
a iv) anteriormente citados. O ponto iv) não é tratado de forma completa neste texto. 
O leitor interessado na análise de dados sujeitos a não-resposta pode consultar 
[@kalton83a], [@LR2002], [@Rubin87], [@SSW92], ou Schafer (1997), por exemplo.

## Estrutura do Livro

O livro está organizado em catorze capítulos. Este primeiro capítulo
discute a motivação para estudar o assunto e apresenta uma ideia
geral dos objetivos e da estrutura do livro.

No segundo capítulo, procuramos dar uma visão das diferentes
abordagens utilizadas na análise estatística de dados de pesquisas
amostrais complexas. Apresentamos um referencial para inferência com
ênfase no `Modelo de Superpopulação` que incorpora, de forma natural, 
tanto uma estrutura estocástica para descrever a geração 
dos dados populacionais (modelo) como o plano amostral
efetivamente utilizado para obter os dados amostrais (plano
amostral). As referências básicas para seguir este capítulo
são o capítulo 2 em [@Silva], o capítulo 1 em [@SHS89] e os capítulos 
1 e 2 em [@CHSK2003]. 

Esse referencial tem evoluído ao longo dos anos como uma forma de
permitir a incorporação de ideias e procedimentos de análise
e inferência usualmente associados à Estatística Clássica
à prática da análise e interpretação de dados provenientes de
pesquisas amostrais. Apesar dessa evolução, sua adoção
não é livre de controvérsia e uma breve revisão dessa
discussão é apresentada no Capítulo \@ref(refinf).

No Capítulo \@ref(capplanamo) apresentamos uma revisão sucinta, para
recordação, de alguns resultados básicos da Teoria de 
Amostragem, requeridos nas partes subsequentes do livro. São
discutidos os procedimentos básicos para estimação de totais
considerando o plano amostral, e em seguida revistas algumas técnicas
para estimação de variâncias que são necessárias e úteis para o caso de
estatísticas complexas, tais como razões e outras estatísticas
requeridas na inferência analítica com dados amostrais. As
referências centrais para este capítulo são os capítulos 2 e 3 
em [@SSW92], [@W85] e [@cochran].

No Capítulo \@ref(epa) introduzimos o conceito de `Efeito do Plano Amostral
(EPA)`, que permite avaliar o impacto de ignorar a estrutura dos
dados populacionais ou do plano amostral sobre a estimativa da variância
de um estimador. Para isso, comparamos o estimador da variância
apropriado para dados obtidos por amostragem aleatória simples
(hipótese de AAS) com o valor esperado deste mesmo estimador sob a
distribuição de aleatorização induzida pelo plano amostral efetivamente utilizado
(plano amostral verdadeiro). Aqui a referência principal foi o livro
[@SHS89], complementado com o texto de [@lethonen].

No Capítulo \@ref(ajmodpar) estudamos a questão do uso de pesos ao analisar dados
provenientes de pesquisas amostrais complexas, e introduzimos um método geral, 
denominado `Método de Máxima Pseudo Verossimilhança(MPV)`, para incorporar os pesos
e o plano amostral na obtenção não só de estimativas de parâmetros dos modelos 
de interesse mais comuns, como também das variâncias dessas estimativas. As
referências básicas utilizadas nesse capítulo foram
[@SHS89], [@Pfeff], [@binder83] e o capítulo 6 em [@Silva].

O Capítulo \@ref(modreg) trata da obtenção de `Estimadores de
Máxima Pseudo-Verossimilhança (EMPV)` e da respectiva matriz de covariância
para os parâmetros em modelos de regressão linear e de regressão logística, quando 
os dados vêm de pesquisas amostrais complexas. Apresentamos um exemplo de aplicação 
com dados do Suplemento Trabalho da Pesquisa Nacional por
Amostra de Domicílios (PNAD) de 1990, onde ajustamos um modelo de
regressão logística. Neste exemplo, são feitas comparações entre 
resultados de ajustes obtidos através de um programa especializado, o pacote `survey` 
[@R-survey], e através de um programa de uso geral, a função `glm` do R. As referências 
centrais são o capítulo 6 em [@Silva] e Binder(1983), além de [@Pessoa].

Os Capítulos \@ref(testqualajust) e \@ref(testetab2) tratam da análise de dados
categóricos com ênfase na adaptação dos testes clássicos
para proporções, de independência e de homogeneidade em tabelas
de contingência, para dados provenientes de pesquisas amostrais
complexas. Apresentamos correções das estatísticas clássicas
e também a estatística de Wald baseada no plano amostral. As referências
básicas usadas nesses capítulos foram os o capítulo 4 em [@SHS89] e 
o capítulo 7 [@lethonen]. Também são apresentadas as ideias básicas de como
efetuar ajuste de modelos log-lineares a dados de frequências em tabelas de 
múltiplas entradas.

O Capítulo \@ref(estimacao-de-densidades) trata da estimação de densidades e 
funções de distribuição, ferramentas que tem assumido importância cada dia maior 
com a maior disponibilidade de microdados de pesquisas amostrais para analistas
fora das agências produtoras.

O Capítulo \@ref(modelos-hierarquicos) trata da estimação e ajuste de modelos hierárquicos 
considerando o plano amostral. Modelos hierárquicos (ou modelos multiníveis) têm sido
bastante utilizados para explorar situações em que as relações entre variáveis de
interesse em uma certa população de unidades elementares (por exemplo, crianças em escolas, 
pacientes em hospitais, empregados em empresas, moradores em regiões, etc.) são afetadas 
por efeitos de grupos determinados ao nível de unidades conglomeradas (os grupos). Ajustar 
e interpretar tais modelos é tarefa mais difícil que o mero ajuste de modelos lineares, 
mesmo em casos onde os dados são obtidos de forma exaustiva, mas ainda mais complicada 
quando se trata de dados obtidos através de pesquisas amostrais complexas. Várias 
alternativas de métodos para ajuste de modelos hierárquicos estão disponíveis, e este 
capítulo apresenta uma revisão de tais abordagens, ilustrando com aplicações a dados 
de pesquisas amostrais de escolares.

O Capítulo \@ref(nao-resposta) trata da não resposta e suas conseqüências sobre a análise
de dados. As abordagens de tratamento usuais, reponderação e imputação, são descritas de 
maneira resumida, com apresentação de alguns exemplos ilustrativos, e referências à ampla 
literatura existente sobre o assunto. Em seguida destacamos a importância de considerar 
os efeitos da não-resposta e dos tratamentos compensatórios aplicados nas análises dos 
dados resultantes, destacando em particular as ferramentas disponíveis para a estimação
de variâncias na presença de dados incompletos tratados mediante reponderação e/ou imputação.

O Capítulo \@ref(diagnostico-de-ajuste-de-modelo) trata de assunto ainda emergente: diagnósticos
do ajuste de modelos quando os dados foram obtidos de amostras complexas. A literatura sobre
o assunto ainda é incipiente, mas o assunto é importante e procura-se estimular sua investigação
com a revisão do estado da arte no assunto.
	
O Capítulo \@ref(agregdesag) discute algumas formas alternativas de analisar dados de
pesquisas complexas, contrapondo algumas abordagens distintas à que demos preferência
nos capítulos anteriores, para dar aos leitores condições de apreciar de forma crítica
o material apresentado no restante deste livro. Entre as abordagens discutidas, há duas 
principais: a denominada `análise desagregada`, e a abordagem denominada `obtenção 
do modelo amostral` proposta por [@PKR]. A chamada `análise desagregada` incorpora 
explicitamente na análise vários aspectos do plano amostral utilizado, através do emprego
de modelos hierárquicos [@bryk]. Em contraste, a abordagem adotada nos oito primeiros 
capítulos é denominada `análise agregada`, e procura `eliminar` da análise efeitos 
tais como conglomeração induzida pelo plano amostral, considerando tais efeitos como
`ruídos` ou fatores de perturbação que `atrapalham` o emprego dos procedimentos 
clássicos de estimação, ajuste de modelos e teste de hipóteses.

A abordagem de `obtenção do modelo amostral` parte de um modelo de superpopulação e
procura derivar o modelo amostral (ou que valeria para as observações da amostra obtida), 
considerando modelos para as probabilidades de inclusão dadas as variáveis auxiliares e
as variáveis resposta de interesse. Uma vez obtidos tais modelos, seu ajuste prossegue por
métodos convencionais tais como máxima verossimilhança ou mesmo MCMC (Markov Chain 
Monte Carlo).

Por último, no Capítulo \@ref(pacotes), listamos alguns pacotes computacionais
especializados disponíveis para a análise de dados de pesquisas amostrais complexas. 
Sem pretender ser exaustiva ou detalhada, essa revisão dos pacotes procura também 
apresentar suas características mais importantes. Alguns destes programas podem ser
adquiridos gratuitamente via `internet`, nos endereços fornecidos de seus produtores. 
Com isto, pretendemos indicar aos leitores o caminho mais curto para permitir a 
implementação prática das técnicas e métodos aqui discutidos.

Uma das características que procuramos dar ao livro foi o emprego de
exemplos com dados reais, retirados principalmente da experiência do
IBGE com pesquisas amostrais complexas. Embora a experiência de fazer
inferência analítica com dados desse tipo seja ainda incipiente no
Brasil, acreditamos ser fundamental difundir essas ideias para alimentar
um processo de melhoria do aproveitamento dos dados das inúmeras
pesquisas realizadas pelo IBGE e instituições congêneres, que
permita ir além da tradicional estimação de totais, médias, proporções 
e razões. Esperamos com esse livro fazer uma contribuição a esse processo.

Uma dificuldade em escrever um livro como este vem do fato de que não
é possível começar do zero: é preciso assumir algum conhecimento prévio 
de ideias e conceitos necessários à compreensão do material tratado. 
Procuramos tornar o livro acessível para um estudante de fim de curso de 
graduação em Estatística. Por essa razão, optamos por não apresentar provas 
de resultados e, sempre que possível, apresentar os conceitos e ideias de maneira
intuitiva, juntamente com uma discussão mais formal para dar solidez aos
resultados apresentados. As provas de vários dos resultados aqui
discutidos se restringem a material disponível apenas em artigos em
periódicos especializados estrangeiros e portanto, são de acesso
mais difícil. Ao leitor em busca de maior detalhamento e rigor,
sugerimos consultar diretamente as inúmeras referências
incluídas ao longo do texto. Para um tratamento mais profundo do
assunto, os livros de [@SHS89]  e [@CHSK2003] são as referências centrais 
a consultar. Para aqueles querendo um tratamento ainda mais prático que o 
nosso, os livro de [@lethonen] e [@heeringa] podem ser opções interessantes.

## Laboratório de R do Capítulo 1. {#epa}

XXX Parei aqui em 20/11/2017

```{example, label= "exe12"}
Utilização do pacote survey do R para estimar alguns totais e razões na Tabela \@ref(tab:epas)
```
Os exemplos a seguir utilizam dados da Pesquisa de Padrões de Vida (`PPV`) do IBGE, 
cujo plano amostral encontra-se descrito no Exemplo \@ref(exm:distppv). 
Os dados da `PPV` estão no arquivo (data frame) `ppv` do pacote `anamco`. 


```{r, message=FALSE, warning=FALSE}
# leitura dos dados
library(anamco)
ppv_dat <- ppv
dim(ppv_dat)
names(ppv_dat)
```
Inicialmente, vamos criar  variáveis de interesse por meio de transformação das variáveis existentes no data frame `ppv`. Agumas dessas variáveis são:

- analf1 - indicador de analfabeto na faixa etária de 7 a 14 anos;
- analf2 - indicador de analfabeto na faixa etária acima de 14 anos;
- faixa1 - indicador de idade entre 7 e 14 anos;
- faixa2 - indicador de idade acima de 14 anos;


```{r}
# cria novo data frame ppv1
ppv1_dat <- transform(ppv_dat, 
analf1 = ((v04a01 == 2 | v04a02 == 2) & (v02a08 >= 7 & v02a08 <= 14)) * 1, 
analf2 = ((v04a01 == 2 | v04a02 == 2) & (v02a08 >14)) * 1, 
faixa1 = (v02a08 >= 7 & v02a08 <= 14) *1, 
faixa2 = (v02a08 > 14) * 1)
```

A seguir, mostramos como utilizar a library `survey` [@R-survey] do R para obter algumas estimativas da Tabela \@ref(tab:epas). Os dados da pesquisa estão contidos no data frame `ppv1`, que contém as variáveis que caracterizam o plano amostral:

- nsetor - conglomerados;
- estratof - estratos;
- pesof - pesos do plano amostral;

O passo fundamental para utilização do pacote `survey` [@R-survey] é criar um objeto que guarde as informações relevantes do plano amostral. Isso é feito por meio da função `svydesign()`.
As variáveis que definem estratos, conglomerados e pesos na `PPV` são respectivamente, `estratof`, `nsetor` e `pesof`. O objeto de desenho amostral, `ppv_plan` incorpora as informações do plano amostral adotado na `PPV`.

```{r, message=FALSE, warning=FALSE}
# carrega library survey
library(survey)
# cria objeto de desenho
ppv_plan<-svydesign(ids = ~nsetor, strata = ~estratof,
data = ppv1_dat, nest = TRUE, weights = ~pesof)
```

Como todos os exemplos a seguir serão relativos a estimativas na Região Sudeste, vamos criar um objeto de desenho restrito a essa região:


```{r}
ppv_se_plan <- subset(ppv_plan, regiao == 2)
```
Para exemplificar, vamos estimar algumas características da população, descritas na Tabela \@ref(tab:epas). Os totais das variáveis `analf1` e `analf2` para a região Sudeste fornecem os resultados nas linhas 4 e 5 da  Tabela \@ref(tab:epas):

- total de analfabetos nas faixas etárias de 7 a 14 anos (`analf1`) e acima de 14 anos (`analf2`).


```{r}
svytotal(~analf1, ppv_se_plan, deff = TRUE)
svytotal(~analf2, ppv_se_plan, deff = TRUE)
```

-  percentual de analfabetos nas faixas etárias consideradas, que fornece os resultados nas linhas 6 e 7 da Tabela \@ref(tab:epas):

```{r}
svyratio(~analf1, ~faixa1, ppv_se_plan)
svyratio(~analf2, ~faixa2, ppv_se_plan)
```
Uma alternativa para obter estimativa por domínios  é utilizar a função `svyby()` do pacote `survey` [@R-survey]. Assim, poderíamos estimar os totais da variável `analf1` para as regiões `Nordeste (1)` e  `Sudeste(2)` da seguinte forma:

```{r}
svyby(~analf1, ~regiao, ppv_plan, svytotal, deff = TRUE)
```
Observe que as estimativas de totais e desvios padrão obtidas coincidem com as Tabela \@ref(tab:epas), porém as estimativas de Efeitos de Plano Amostral(EPA) são distintas.


## Laboratório de R do Capítulo 1 - Extra. 


```{example, label= "exe13"}
Exemplo anterior usando a library srvyr
```
- Carrega a library `srvyr`:

```{r, message=FALSE, warning=FALSE}
library(srvyr)
```

- Cria objeto de desenho:
```{r}
ppv_plan <- ppv_dat %>% as_survey_design (ids = nsetor, strata = estratof,
nest = TRUE, weights = pesof)
```

- Vamos criar novas variáveis:

```{r}
ppv_plan <- ppv_plan %>% 
mutate(
analf1 = as.numeric((v04a01 == 2 | v04a02 == 2) & (v02a08 >= 7 & v02a08 <= 14)), 
analf2 = as.numeric((v04a01 == 2 | v04a02 == 2) & (v02a08 >14)), 
faixa1 = as.numeric(v02a08 >= 7 & v02a08 <= 14), 
faixa2 = as.numeric(v02a08 > 14)   
)
```

- Estimar a taxa de analfabetos por região para as faixas etárias de 7-14 anos e mais de 14 anos.

```{r}
res <- ppv_plan %>%  
group_by(regiao) %>% 
summarise(
taxa_analf1 = survey_ratio(analf1, faixa1),
taxa_analf2 = survey_ratio(analf2, faixa2)  
)
knitr::kable(as.data.frame(res), booktabs = TRUE, row.names = FALSE, digits = 3, 
caption = "Proporção de analfabetos para faixas etárias 7-14 anos e mais de 14 anos")
```



```{example, label = "exe14"}
Utilização do pacote survey do R para estimar taxa de desocupação para um trimestre na  PNADC 
```

- Instala library `lodown` [@R-lodown] do github:


```{r, eval=FALSE}
library(devtools)
install_github("ajdamico/lodown")
```


- carrega a library para ler os dados da PNADC

```{r, eval=FALSE}
library(lodown)
```

- Baixa catálogo da PNADC com arquivos disponíveis:
  
```{r, eval=FALSE}
pnadc_cat <- get_catalog( "pnadc" , output_dir =tempdir() )
```

Os microdados de interesse são terceiro trimestre de 2016. Vamos ler os microdados
e salvá-los em um data frame `pnadc032016_dat`.

```{r, eval=FALSE}
lodown( "pnadc" , subset( pnadc_cat , year == 2016 & quarter == '03' ) )
pnadc032016_dat <- readRDS( paste0( tempdir() , "/pnadc201603.rds" ) )
```

vamos salvar o data frame `pnadc032016_dat` para uso posterior, :

```{r , eval=FALSE}
saveRDS(pnadc032016_dat, file="C:/adac/pnadc/pnadc201603.rds")
```


Partindo do arquivo `pnadc201603.rds`, podemos recuperar o data frame `pnadc032016_dat`: 

 
```{r, eval= FALSE}
pnadc032016_dat <- readRDS("C:/adac/pnadc/pnadc201603.rds")
```


-  Carrega a library `survey`

```{r, message=FALSE, warning=FALSE}
library(survey)
```

- Fixa opção para caso de UPA única no estrato
```{r}
options( survey.lonely.psu = "adjust" )
```
-  Cria versão inicial de objeto de desenho:
 

```{r , eval=FALSE}
pnadc032016_plan <- svydesign(ids =~upa, strata=~estrato, 
  weights=~v1027, data = pnadc032016_dat, nest=TRUE)
```


- Especifica totais de pós-estratos na população:
  
```{r, eval= FALSE}
df_pos <-data.frame(posest=unique(pnadc032016_dat$posest), 
  Freq=unique(pnadc032016_dat$v1029))
```
-   Pós-estratifica objeto de desenho inicial:

```{r, eval = FALSE}
pnadc032016_calib <-postStratify(pnadc032016_plan, ~posest, df_pos)
```
  
Para calcular a taxa de desocupação, o IBGE considera pessoas de 14 anos
ou mais na semana de referência(PIA) e calcula a razão de dois totais:

1. Numerador: total de pessoas desocupadas (vd4002==2)

2. Denominador: total de pessoas na força de trabalho (vd4001==1)

```{r, echo = FALSE, eval= FALSE }
saveRDS(pnadc032016_calib, file="C:/adac/pnadc/pnadc032016_calib.rds")
```

```{r, echo = FALSE}
pnadc032016_calib <- readRDS("C:/adac/pnadc/pnadc032016_calib.rds")
```

```{r}
# estima taxa de desocupação
taxa_des <- svyratio(~ vd4002=="2" ,
  ~ vd4001 == "1" , pnadc032016_calib , na.rm = TRUE)
# organiza saída
result <- data.frame(
  100*coef(taxa_des),
  100*SE(taxa_des), 
  100*cv(taxa_des)
)
row.names(result)<- NULL
names(result) <-NULL
names(result) <- c("Taxa", "Erro_Padrão", "CV")
# taxa de desocupação
result
```


```{example, label= "exe15"}
Utilização do pacote survey do R para análise de microdados da  PNS 
```

Leitura dos microdados usando a library `lodown`[@R-lodown]

```{r ,eval = FALSE}
#library(lodown)
#lodown( "pns" , output_dir = "C:/adac/PNS")
```

Depois de baixar os dados, são criados os seguintes arquivos no diretório `C:/adac/PNS` :

1. `2013 all questionnaire survey design.rds` que contém o objeto de desenho para todos as pessoas na amostra;

2. `2013 all questionnaire survey.rds` que contém os microdados para todos as pessoas da amostra

3. `2013 long questionnaire survey design.rds` que contém o objeto de desenho para uma subamostra de pessoas com 18 anos ou mais que responderam um questionário mais longo;

4. `2013 long questionnaire survey.rds` que contém os microdados para uma subamostra de pessoas com 18 anos ou mais que responderam um questionário mais longo;

```{remark}
Nos arquivos acima, além das variáveis contidas no dicionário da PNS, foram acrescentadas variáveis derivadas, utilizadas nos exemplos no site [asdfree.com](https://github.com/ajdamico/asdfree/tree/master/Pesquisa%20Nacional%20De%20Saude) 
```

Inicialmente, vamos estimar características de pessoas com 18 anos ou mais mais que responderam o questionário longo e salvar os microdados dessa amostra no data frame `pns_dat`.

```{r, cache=TRUE}
pns_dat <- readRDS("C:/adac/PNS/2013 long questionnaire survey.rds")
dim(pns_dat)
```

```{remark}
No data frame pns_dat o nome das variáveis, obtidos por `names(pns)`, estão em minúsculas. No dicionário da PNS os códigos correspondentes estão em maiúsculas.
```
O data frame `pns_dat` contém as variáveis descritas no dicionário da `PNS` e algumas variáveis obtidas derivadas. 

O passo inicial para a análise dos microdados é definir um objeto de desenho que salva
as características do plano amostral da pesquisa. Isso é feito por meio da função `svydesign()` do pacote `survey` [@R-survey]. 


```{r, message=FALSE, warning=FALSE}
library(survey)
pns_plan <-
	svydesign(
		id = ~ upa_pns ,
		strata = ~ v0024 ,
		data = pns_dat ,
		weights = ~ pre_pes_long ,
		nest = TRUE
	)
```

Os pesos do objeto de desenho `pns_plan` devem ser modificados de modo que as estimativas dos totais populacionais dos pós-estratos fixados coincidam com os  totais populacionais dos pós-estratos conhecidos a partir do Censo Demográfico. O data frame `post_pop` contém na primeira coluna a identidade dos pós-estratos e na segunda seus totais populacionais.

```{r}
post_pop <- unique( pns_dat[ c( 'v00293.y' , 'v00292.y' ) ] )
names( post_pop ) <- c( "v00293.y" , "Freq" )
```

Utilizando a função `postStratify()` do pacote `survey` [@R-survey] incorpora-se no objeto de desenho `pns_plan` as informações contidas no data frame `post_pop`.


```{r}
pns_calib <- postStratify( pns_plan , ~v00293.y , post_pop )
```

Salvar objeto de desenho pós-estratificado para posterior utilização:

```{r, eval= FALSE}
saveRDS(pns_calib, file = "C:/adac/PNS/pns_calib.rds" )
```

```{r, eval=FALSE}
pns_calib <- readRDS("C:/adac/PNS/pns_calib.rds")
```

Os comandos acima foram apresentados apenas para ilustrar como, a partir dos microdados da pesquisa, obtemos o objeto de desenho da pesquisa. Não seria necessária a execução desses comandos pois o  objeto de desenho `pns_calib` já se encontra disponível no arquivo 1 `2013 all questionnaire survey design.rds`. 

Para exemplificar, vamos agora reproduzir estimativas na Tabela 6.42.1.1 da publicação em ftp://ftp.ibge.gov.br/PNS/2013/pns2013.pdf.

A variável de interesse tem código Q092 e sua descrição é: 
"Algum médico ou profissional de saúde mental (como psiquiatra ou psicólogo) já lhe deu o diagnóstico de depressão?"

Essa variável é de classe `character` e tem dois valores "1" e "2". Vamos definir uma nova variável `diag_dep` que é igual a 1 se recebe diagnóstico de depressão e 0 caso contrário:

```{r}
diag_dep <- as.numeric (pns_dat$q092=="1")
```

Como mencionado, o objeto de desenho pós-estratificado `pns_calib` pode ser lido
do arquivo `2013 all questionnaire survey design.rds`. Vamos atualizar o objeto de desenho `pns_calib` para incluir a variável `diad_dep` na componente `variables`:

```{r}
pns_calib <- update (pns_calib, diag_dep = diag_dep )
```
Para calcular a proporção de pessoas que receberam diagnóstico de depressão para
o país inteiro usamos o seguinte comando:

```{r}
diagdepbr <- svymean(~diag_dep, pns_calib)
# estimativa e erro padrão, ambos em % 
round(100 * coef(diagdepbr),1)
round(100 * SE(diagdepbr)  ,1)
```


e para obter um intervalo de confiança aproximado com nível de confiança de 95%, usamos:

```{r}
round(100* c(coef(diagdepbr) - 2*SE(diagdepbr),coef(diagdepbr) + 2*SE(diagdepbr)  ), 1)
```

As estimativa de proporção e os limites do intervalo de confiança podem ser obtidos por meio da função:


```{r}
three_stats <- function(z) round(100 * c(coef(z), coef(z) - 
  2 * SE(z), coef(z) + 2 * SE(z)), 1)

```

Aplicando a função `three_stats` para estimar a proporção para o país inteiro:

```{r}
three_stats(diagdepbr)
```
que coincidem com os resultados já obtidos.



Para o país por sexo:


```{r, echo=FALSE}
diagdepsex <- svyby(~diag_dep, ~c006, design = pns_calib, svymean)
res <- three_stats(diagdepsex)
dfsex <- data.frame( sexo = names(res)[1:2], prop = res[1:2], l.i.c. = res[3:4],l.s.c =res[5:6])
knitr::kable(dfsex,booktabs = TRUE, row.names = FALSE,  
caption = "Proporção de diagnóstico de depressão por sexo")

```

Por situação (rural e urbano)

```{r, echo= FALSE, cache=TRUE}
diagdepsitu <- svyby(~diag_dep, ~situ, design = pns_calib, svymean)
res <- three_stats(diagdepsitu)
dfsitu <- data.frame( situ = names(res)[1:2], prop = res[1:2], l.i.c. = res[3:4],l.s.c =res[5:6])
knitr::kable(dfsitu,booktabs = TRUE, row.names = FALSE, 
caption = "Proporção de diagnóstico de depressão por situação")
```



```{r, eval=FALSE, echo= FALSE}
diagdepsitusex <- svyby(~diag_dep, ~situ + c006, design = pns_calib, svymean)
res <- three_stats(diagdepsitusex)
dfsitusex <- data.frame(situ.sex = names(res)[1:4],prop = res[1:4], 
  l.i.c = res[5:8], l.s.c=res[9:12] )
knitr::kable(dfsitusex,booktabs = TRUE, row.names = FALSE,
caption = "Proporção de diagnóstico de depressão por situação e sexo")
```

Por Unidade da Federação:

```{r, echo=FALSE, cache=TRUE}
diagdepuf <- svyby(~diag_dep, ~uf, design = pns_calib, svymean)
res <- three_stats(diagdepuf)
dfuf <- data.frame(uf = names(res)[1:27], prop = res[1:27], 
  l.i.c. = res[28:54], l.s.c =res[55:81]  )
knitr::kable(dfuf,booktabs = TRUE, row.names = FALSE, 
caption = "Proporção de diagnóstico de depressão por uf")
```

 
```{r, eval= FALSE, echo= FALSE , cache=TRUE}
diagdepufsex <- svyby(~diag_dep, ~uf + c006, design = pns_calib, 
  svymean)
res <- three_stats(diagdepufsex)
dfufsex <- data.frame (uf.sex =names(res)[1:54], prop = res[1: 54],
  l.i.c = res[55:108], l.s.c=res[109:162] )
knitr::kable(dfufsex,booktabs = TRUE, row.names = FALSE, 
caption = "Proporção de diagnóstico de depressão por uf e sexo")
```

Usando o objeto de desenho para todas as pessoas que reponderam o questionário curto, salvo no arquivo em `2013 all questionnaire survey design.rds`, vamos estimar a proporção de pessoas que possuem plano de saúde por grupos de nível de instrução.


```{r, eval=FALSE, echo=TRUE}
pns_all_calib <- readRDS("C:/adac/PNS/2013 all questionnaire survey design.rds")
```


Proporção de pessoas com seguro de saúde por nível de instrução:

```{r, eval=FALSE, echo=TRUE}
byeduc <- data.frame( svyby( ~ as.numeric( i001 == 1 ) , ~ educ ,
design = pns_all_des_pos , vartype = "ci" ,  level = 0.95 ,
svymean , na.rm = TRUE ) )
byeduc <- byeduc[,-1]
names(byeduc) <- c("Prop", "l.i.c.", "l.s.c.")
```


```{r, eval= FALSE , echo=FALSE}
saveRDS(byeduc, file = "C:/adac/PNS/byeduc.rds" )
```


```{r, eval=TRUE, echo=FALSE}
byeduc <- readRDS("C:/adac/PNS/byeduc.rds")
```

Imprime tabela: 

```{r}
knitr::kable(byeduc,booktabs = TRUE,  
digits= 3, caption = "Proporção de pessoas com seguro de saúde por nível de instrução")
```

Gráfico de barras usando a library `ggplot2` [@R-ggplot2]:

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
ggplot(
	byeduc,
	aes( x = c("SinstFundi", "FundcMedi", "MedcSupi", "Supc") , y = 100*Prop )
	) +
	geom_bar( stat = "identity" ) +
	geom_errorbar( aes( ymin = 100*l.i.c. , ymax = 100*l.s.c. ))  +
  ylim(c(0,100))+
	xlab( "nível de instrução" ) +
	ylab( "% com seguro de saúde" )+
  ggtitle("% de pessoas com plano de saúde, com indicação do intervalo de
  confiança de 95%, segundo grupos de nível de instrução - Brasil - 2013")
```


## Apêndice: Estimativa do efeito de plano amostral (EPA)

Esse assunto será tratado em detalhes no Capítulo \@ref(epa) . Por enquanto, apresentaremos uma introdução necessária para compreender os valores na Tabela \@ref(tab:epas).

O efeito de plano amostral (EPA) de Kish é definido na fórmula 
\@ref(eq:epa1). Vamos considerar o caso particular em que $\hat{\theta}$ é um estimador de total de uma variável $Y$.Ou seja
\[
EPA_{Kish}\left(\widehat{Y}\right)=\frac{V_{VERD}\left(\widehat{Y}\right)}{V_{AAS}\left(\widehat{Y}\right)}
\]

Na definição do EPA,  a estimativa do numerador pode ser obtida usando-se a library `survey` [@R-survey], a partir do objeto de `ppv_se_plan` que incorpora as características do plano amostral utilizado para coletar os dados. Não é possível estimar diretamente o denominador, pois o plano amostral AAS (Amostragem Aleatória Simples) não foi adotado na coleta dos dados. Devemos estimar o denominador a partir de dados obtidos através do plano amostral VERD, como se eles tivessem sido obtidos através de AAS.

Supondo conhecido o tamanho da população $N$ e a fração amostral $f=n/N$ pequena, a estimativa da variância de $\widehat{Y}$ é dada na expressão \@ref(eq:estpa9)
\[
\widehat{V}_{AAS}\left(\widehat{Y}\right)=N^2\frac{\widehat{S}_y}{n-1}
\]
onde $\widehat{S}_y= n^{-1}\sum_{i\in s}\left(y_i-\overline{y}\right)^2$ é a estimativa de $S_y=N^{-1}\sum_{i\in U}\left(y_i-\overline{Y}\right)^2$, com $\overline{Y}=N^{-1}Y$.

No lugar dessa estimativa, vamos utilizar os pesos do plano amostral verdadeiro 
para estimar $S_y$. Vamos ainda estimar $N$, em geral é desconhecido, por 
$\widehat{N}=\sum_{i \in s} w_i$. Dessa forma obtemos a estimativa
\begin{eqnarray*}
\widehat{V}_{w-AAS}\left(\widehat{Y}\right)&=& \widehat{N}^2\left[\sum_{i \in s}w_i\left(y_i-\overline{y}\right)^2/\widehat{N}\right]/(n-1)\\
&=&\frac{\widehat{N}}{n-1}\left[\sum_{i \in s}w_iy_i^2-\left(\sum_{i \in s}w_iy_i\right)^2/\widehat{N}\right],
\end{eqnarray*}
onde $\overline{y}=\sum_{i \in s}w_iy_i/n$.

A expressão acima pode ser calculada facilmente através da seguinte função do R:
```{r}
Vwaas<-function(y,w)
{
#função auxiliar usada em outras funções
#entrada:
#y - valores de variavel na amostra;
#w - pesos amostrais;
#saida:  estimativa de variância de desenho para o total (segundo o SUDAAN)

n1<-length(y)-1
wsum<-sum(y*w)
wsum2<-sum((y^2)*w)
nhat<-sum(w)
vwaas<-(nhat/n1)*(wsum2-wsum^2/nhat)
vwaas
}
```

Vamos utilizar a função `Vwaas` para estimar os valores de `Efeitos do Plano Amostral`das estimativas de totais apresentadas anteriormente.
Consideremos o plano amostral `ppv_se_plan` anteriormente definido. 
Vamos usar a função `Vwaas` para obter uma estimativa da variância do total estimado da variável `analf1`. Todos os elementos os elementos necessários estão contidos no objeto `ppv_se_plan`:


```{r}
VAAS1<- Vwaas(ppv_se_plan$variables[,"analf1"],weights(ppv_se_plan))
VAAS2<- Vwaas(ppv_se_plan$variables[,"analf2"],weights(ppv_se_plan))
```

O efeito de plano amostral da estimativa do total de `analf1` pode agora ser calculada por

```{r}
attr(svytotal(~analf1, ppv_se_plan),"var")/VAAS1
attr(svytotal(~analf2, ppv_se_plan),"var")/VAAS2
```

Esses valores do EPA coincidem com os obtidos acima através do pacote `survey`[@R-survey] e 
são distintos daqueles apresentados na Tabela \@ref(tab:epas). Para obter os valores 
correspondentes aos da Tabela \@ref(tab:epas), através do pacote `survey`[@R-survey], vamos definir as variáveis:

```{r}
analf1.se<-with(ppv1_dat,((v04a01==2|v04a02==2) & (v02a08>=7&v02a08<=14))&(regiao==2))
analf2.se<-with(ppv1_dat,((v04a01==2|v04a02==2) & (v02a08>14))&(regiao==2))
ppv_plan <- update (ppv_plan,analf1.se=analf1.se,analf2.se=analf2.se  )
svytotal(analf1.se,ppv_plan,deff=T)
svytotal(analf2.se,ppv_plan,deff=T)
```

Ou, alternativamente,

```{r}
svytotal(~I(ifelse(regiao==2,analf1,0)),ppv_plan,deff=T)
svytotal(~I(ifelse(regiao==2,analf2,0)),ppv_plan,deff=T)
```


Observe que as estimativas de variância para o desenho verdadeiro (numerador do EPA)
são iguais quando usamos: a variável  `analf1.se` com o objeto de desenho `ppv_plan` 
ou a variável `analf1` com o objeto `ppv_se_plan`. Porém na estimativa do denominador do EPA, obtida a partir da função `Vwaas`, obtemos resultados diferentes quando usamos `analf1.se` ou `analf1`,  
com os pesos correspondentes. No segundo caso, a soma dos pesos não estima $N$. Deve-se ter o cuidado, quando estimamos em um domínio, de trabalhar com pesos cuja soma seja um estimador do tamanho da população.

