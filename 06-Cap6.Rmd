---
output:
  html_document: default
  pdf_document: default
---
# Modelos de Regressão {#modreg}

## Modelo de Regressão Linear Normal {#modlinear}


O problema considerado nesta seção é o de estimar os
parâmetros num modelo de regressão linear normal especificado para
um subconjunto das variáveis da pesquisa. O procedimento de máxima
pseudo-verossimilhança, descrito na Seção \@ref(modpar3), é
aplicado. Os resultados são derivados considerando pesos ordinários
dados pelo inverso das probabilidades de inclusão das unidades na
amostra. Resultados mais gerais considerando outros tipos de pesos (tais
como os derivados de estimadores de razão ou regressão, por exemplo)
estão discutidos em [@Silva], Cap. 6.

### Especificação do Modelo

Vamos supor que os dados da $i$-ésima unidade da população
pesquisada incluam um vetor $\mathbf{z}_{i}=\left( z_{i1},\ldots
,z_{iP}\right) ^{^{\prime }}$ de dimensão $P\times 1$ com os valores de
variáveis $\mathbf{z}$, que são `preditoras` ou
explanatórias num modelo de regressão $M$. Este modelo tem o
objetivo de predizer ou explicar os valores de uma variável da pesquisa $y$, que é considerada como variável `resposta`.
Denotemos por $Y_{i}$ e $\mathbf{Z}_{i}$ a variável e o vetor
aleatórios que geram $y_{i}$ e $\mathbf{z}_{i}$, para $i\in U$. Sem
perda de generalidade, suponhamos também que a primeira componente do
vetor $\mathbf{z}_{i}$ de variáveis preditoras é sempre igual a $1$,
de modo a incluir sempre um termo de intercepto nos modelos de regressão
linear considerados (tal hipótese não é essencial, mas será
adotada no restante deste capítulo). Suponhamos agora que 
$\left( Y_{i},\mathbf{Z}_{i}^{^{\prime }}\right) ^{^{\prime }},\;i\in U$, são vetores aleatórios independentes e identicamente distribuídos tais que 
\begin{equation}
f\left( \left. y_{i}\right|\mathbf{z}_{i};\mathbf{\beta },\sigma_{e}\right) =\left( 2\pi \sigma _{e}\right) ^{-1/2}\exp \left[ -\left( y_{i}-\mathbf{z}_{i}^{^{\prime }}\mathbf{\beta }\right) ^{2}/2\sigma _{e}\right]
(\#eq:norm1)
\end{equation}
onde $\mathbf{\beta }=\left( \beta _{1},\ldots ,\beta _{P}\right) ^{^{\prime
}}$ e $\sigma_{e}>0$ são parâmetros desconhecidos do modelo.

Observe que \@ref(eq:norm1) constitui-se numa especificação (parcial) de
um modelo marginal para um conjunto de variáveis da pesquisa, e não
faz nenhuma referência direta à forma como elas se relacionam com
variáveis auxiliares $\mathbf{x}$ que eventualmente possam estar
disponíveis. A atenção é focalizada na estimação de $\mathbf{\beta }$ e $\sigma_{e}$ e sua interpretação com respeito ao
modelo agregado \@ref(eq:norm1).

Modelos como \@ref(eq:norm1) já foram considerados por vários autores,
por exemplo [@holt80b], [@NH80], pág. 81 de [@Sk89b] , [@chambers86], [@chambers95]. 
Eles são simples, mesmo assim
frequentemente usados pelos analistas de dados, pelo menos como uma
primeira aproximação. Além disto, eles satisfazem todas as condições padrões de regularidade. Assim eles são adequados a uma
aplicação de procedimentos de máxima pseudo-verossimilhança
descritos na Seção \@ref(modpar3).

As funções escores para $\mathbf{\beta}$ e $\sigma _{e}$
correspondentes ao modelo \@ref(eq:norm1) podem ser facilmente obtidas como 
\begin{eqnarray}
\partial \log \left[ f\left( \left. y_{i}\right| \mathbf{z}_{i};\mathbf{
\beta },\sigma _{e}\right) \right] /\partial \mathbf{\beta } &=&\mathbf{z}
_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\sigma _{e}
(\#eq:norm2) \\
&\propto &\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{
\beta }\right) =\mathbf{u}_{i}\left( \mathbf{\beta }\right)  \nonumber
\end{eqnarray}
e 
\begin{eqnarray*}
\partial \log \left[ f\left( \left. y_{i}\right| \mathbf{z}_{i};\mathbf{
\beta },\sigma _{e}\right) \right] /\partial \sigma _{e} &=&\left[ \left(
y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) ^{2}-\sigma _{e}\right]
/2\sigma _{e}^{2}  (\#eq:norm3) \\
&\propto &\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right)
^{2}-\sigma _{e}=u_{i}\left( \sigma _{e}\right) \;.  
\end{eqnarray*}

### Pseudo-parâmetros do Modelo

Se todos os elementos da população tivessem sido pesquisados, os
EMVs de $\mathbf{\beta }$ e $\sigma _{e}$ do censo, denotados por 
$\mathbf{B}$ e $S_{e}$ respectivamente, poderiam ser facilmente obtidos como soluções das equações de verossimilhança do censo dadas por 
\begin{equation}
\sum\limits_{i\in U}\mathbf{u}_{i}\left( \mathbf{B}\right)
=\sum\limits_{i\in U}\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }
\mathbf{\beta }\right) =\mathbf{z}_{U}^{^{\prime }}\mathbf{y}_{U}-\left( 
\mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}\right) \mathbf{B}=\mathbf{0}
(\#eq:norm4)
\end{equation}
e 
\begin{equation}
\sum\limits_{i\in U}u_{i}\left( S_{e}\right) =\sum\limits_{i\in U}\left[
\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{B}\right) ^{2}-S_{e}\right]
=\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}\right) ^{^{\prime
}}\left( \mathbf{y}_{U}-\mathbf{zz}_{U}^{\prime }\mathbf{B}\right) -NS_{e}=0
(\#eq:norm5)
\end{equation}

onde $\mathbf{z}_{U}=\left( \mathbf{z}_{1},\ldots ,\mathbf{z}_{N}\right)
^{^{\prime }}$ e $\mathbf{y}_{U}=\left( y_{1},\ldots ,y_{N}\right)
^{^{\prime }}$.

Se $\mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}$ for não-singular, as soluções para estas equações são facilmente obtidas como 
\begin{equation}
\mathbf{B}=\left( \mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}\right) ^{-1}
\mathbf{z}_{U}^{^{\prime }}\mathbf{y}_{U}  
(\#eq:norm6)
\end{equation}
e 
\begin{equation}
S_{e}=N^{-1}\sum\limits_{i\in U}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{
B}\right) ^{2}=N^{-1}\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}
\right) ^{^{\prime }}\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}
\right) \;.  
(\#eq:norm7)
\end{equation}

Com uma parametrização que isole o termo correspondente ao
intercepto (primeira coluna do vetor $\mathbf{z}_{i}$) do modelo de
regressão \@ref(eq:norm1), pode ser facilmente mostrado ([@Silva], p. 142)
que os EMV de $\mathbf{\beta }_{2}$ (igual a $\mathbf{\beta }$
excluído o primeiro componente), $\beta _{1}$ e $\sigma _{e}$ são
dados respectivamente por

\begin{equation}
\mathbf{B}_{2}=\mathbf{S}_{\mathbf{z}}^{-1}\mathbf{S}_{\mathbf{z}y}\;,
(\#eq:norm8)
\end{equation}


\begin{equation}
B_{1}=\bar{Y}-\mathbf{\bar{Z}}^{^{\prime }}\mathbf{B}_{2}\mathbf{\;,}
(\#eq:norm9)
\end{equation}
e 

\begin{equation}
S_{e}=N^{-1}\sum\limits_{i\in U}\left( y_{i}-B_{1}-\mathbf{z}_{i}^{^{\prime
}}\mathbf{B}_{2}\right) ^{2}=N^{-1}\sum\limits_{i\in U}e_{i}^{2}\;,
(\#eq:norm10)
\end{equation}
onde $\bar{Y}=N^{-1}\sum\limits_{i\in U}y_{i}$, 
$\mathbf{\bar{Z}}=N^{-1}\sum\limits_{i\in U}\mathbf{z}_{i}$ , $\mathbf{S}_{\mathbf{z}}=N^{-1}\sum\limits_{i\in U}\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right)\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}$, $\mathbf{S}_{
\mathbf{z}y}=N^{-1}\sum\limits_{i\in U}\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) \left( y_{i}-\bar{Y}\right)$ e 
$e_{i}=y_{i}-B_{1}-\mathbf{z}_{i}^{^{\prime }}\mathbf{B}_{2}=\left( y_{i}-\bar{Y}\right) -\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}\mathbf{B}_{2}$ , sendo neste
trecho os vetores de variáveis preditoras tomados sem o termo constante
referente ao intercepto.

Os EMVs do censo dados em \@ref(eq:norm1) a \@ref(eq:norm10) coincidem com os
estimadores de mínimos quadrados ordinários, sob as hipóteses
mais fracas do modelo dadas por \@ref(eq:norm11) a seguir (ver Nathan e Holt,
1980), onde se dispensou a hipótese de normalidade dos erros, isto é 
\begin{eqnarray}
E_{M}\left( \left. Y_{i}\right| \mathbf{z}_{i}=\mathbf{z}_{i}\right)
&=&\beta _{1}+\mathbf{z}_{i}^{^{\prime }}\mathbf{\beta }_{2}  (\#eq:norm11) \\
V_{M}\left( \left. Y_{i}\right| \mathbf{z}_{i}=\mathbf{z}_{i}\right)
&=&\sigma _{e}  \nonumber \\
COV_{M}\left( \left. Y_{i},Y_{j}\right| \mathbf{z}_{i}=\mathbf{z}_{i},
\mathbf{z}_{j}=\mathbf{z}_{j}\right) &=&0\ \quad \forall i\neq j\in U. 
\nonumber
\end{eqnarray}

### Estimadores de MPV dos Parâmetros do Modelo

Quando apenas uma amostra de unidades da população é observada,
são usados pesos $w_{i}$ para obter estimadores de máxima
pseudo-verossimilhança de $\mathbf{\beta }$ e $\sigma _{e}$, ou
alternativamente de $\mathbf{B}$ e $S_{e}$, se as quantidades descritivas
populacionais correspondentes forem escolhidas para alvo da inferência.
Se os pesos $w_{i}$ satisfizerem às condições de regularidade
discutidas na Seção \@ref(modpar3), será imediato obter as equações de pseudo-verossimilhança correspondentes ao modelo \@ref(eq:norm1) como 
\begin{eqnarray}
\sum\limits_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\hat{B}}_{w}\right)
&=&\sum\limits_{i\in s}w_{i}\mathbf{z}_{i}\left( y_{i}-\mathbf{z}
_{i}^{\prime }\mathbf{\hat{B}}_{w}\right)  (\#eq:norm12) \\
&=&\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}-\left( \mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}\right) \mathbf{\hat{B}}_{w}=
\mathbf{0}  \nonumber
\end{eqnarray}
e 
\begin{eqnarray}
\sum\limits_{i\in s}w_{i}u_{i}\left( s_{e}^{w}\right) &=&\sum\limits_{i\in
s}w_{i}\left[ \left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\hat{B}}
_{w}\right) ^{2}-s_{e}^{w}\right]  (\#eq:norm13) \\
&=&\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B}}_{w}\right)
^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B
}}_{w}\right) -\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) s_{e}^{w}=0  \nonumber
\end{eqnarray}
onde $\mathbf{z}_{s}$ e $\mathbf{y}_{s}$ são os análogos amostrais
de $\mathbf{z}_{U}$ e $\mathbf{y}_{U}$, respectivamente, 
$\mathbf{W}_{s}=diag\left[ \left( w_{i_{1}},\ldots ,w_{i_{n}}\right) \right]$ é
uma matriz diagonal $n\times n$ com os pesos dos elementos da amostra na
diagonal principal, e $\mathbf{\hat{B}}_{w}$ e $s_{e}^{w}$ são
estimadores MPV de $\mathbf{\beta }$ e $\sigma _{e}$ respectivamente.

Supondo que $\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ é
não-singular e resolvendo \@ref(eq:norm12) e \@ref(eq:norm13) em $\mathbf{\hat{B}
}_{w}$ e $s_{e}^{w}$ obtemos as seguintes expressões para os estimadores
MPV dos parâmetros do modelo: 
\begin{equation}
\widehat{\mathbf{B}}_{w}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}
\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y
}_{s}  (\#eq:norm14)
\end{equation}
e 

\begin{eqnarray}
s_{e}^{w} &=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{w}\right) ^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}
\widehat{\mathbf{B}}_{w}\right)  (\#eq:norm15) \\
&=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}_{s}\right)
^{-1}\mathbf{y}_{s}^{^{\prime }}\left[ \mathbf{W}_{s}-\mathbf{W}_{s}\mathbf{z
}_{s}\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\right] \mathbf{y}_{s} 
\nonumber
\end{eqnarray}
sendo a segunda expressão para $s_{e}^{w}$ obtida mediante substituição do valor de $\widehat{\mathbf{B}}_{w}$ em \@ref(eq:norm14) na primeira
linha de \@ref(eq:norm15).

Observe que a hipótese de não-singularidade de $\mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ não seria satisfeita se 
$w_{i}=0$ para algum $i\in s$. Para evitar que se percam de vista as
questões principais com relação à estimação dos
parâmetros do modelo, admitiremos de agora em diante que $\mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}$ é não-singular.

Estimadores pontuais dos parâmetros do modelo podem ser derivados a
partir de \@ref(eq:norm14) e \@ref(eq:norm15) para vários esquemas de pondera\c{c
}ão de interesse pela simples substituição da matriz apropriada
de ponderação $\mathbf{W}_{s}$. Se todos os elementos da pesquisa
têm o mesmo peso (como no caso de planos amostrais autoponderados), ou
seja, $w_{i}=\bar{w}$ e $\mathbf{W}_{s}=\bar{w}\mathbf{I}_{n}$, os
estimadores pontuais não dependem do valor $\bar{w}$ dos pesos. Neste
caso, eles ficam reduzidos às expressões correspondentes dos
estimadores de mínimos quadrados ordinários (que são também
estimadores de máxima verossimilhança sob normalidade) dos
parâmetros do modelo, dados por: 
\begin{equation}
\widehat{\mathbf{B}}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{y}_{s}  (\#eq:norm16)
\end{equation}
e

\begin{equation}
s_{e}=n^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
^{^{\prime }}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
\;.  (\#eq:norm17)
\end{equation}

Substituindo $\mathbf{W}_{s}$ em \@ref(eq:norm14) e \@ref(eq:norm15) por $diag\left(
\pi _{i}:i\in s\right) =\mathbf{\Pi }_{s}^{-1}$, onde os $\pi _{i}$ em geral
não são todos iguais, obtemos estimadores, chamados de mínimos
quadrados $\pi -$ponderados, dados por: 
\begin{equation}
\widehat{\mathbf{B}}_{\pi }=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{y}_{s}  (\#eq:norm18)
\end{equation}
e

\begin{equation}
s_{e}^{\pi }=\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\mathbf{
1}_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{\pi }\right) ^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\left( \mathbf{y}_{s}-
\mathbf{z}_{s}\widehat{\mathbf{B}}_{\pi }\right) \;.  (\#eq:norm19)
\end{equation}

### Estimação da Variância de Estimadores de MPV

O exercício de ajustar um modelo não estará completo sem a 
avaliação da precisão e significância das estimativas dos
parâmetros. Para isto é necessária a estimação das
variâncias correspondentes. Nesta seção concentramos nossa atenção na estimação das variâncias dos estimadores de MPV
dos coeficientes de regressão $\mathbf{\beta}$. As expressões a
seguir são obtidas por aplicação direta dos resultados gerais
fornecidos na Seção \@ref(modpar3), observando-se que os escores
correspondentes a $\mathbf{\beta}$ no `ajuste do censo` do modelo \@ref(eq:norm1) são dados por 
$\mathbf{u}_{i}\left( \mathbf{B}\right) =\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{B}\right) =\mathbf{z}
_{i}e_{i}$ , 
onde $e_{i}=\left( y_{i}-\bar{Y}\right) -\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}\mathbf{B}$ para $i\in U$, com o
Jacobiano correspondente dado por

\begin{eqnarray}
J\left( \mathbf{B}\right) &=&\left. \sum\nolimits_{i\in U}\partial \mathbf{z}
_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\partial 
\mathbf{\beta }\right| _{\mathbf{\beta }=\mathbf{B}}  (\#eq:norm20) \\
&=&\left. \partial \left( \mathbf{z}_{U}^{\prime }\mathbf{y}_{U}-\mathbf{z}
_{U}^{\prime }\mathbf{z}_{U}\mathbf{\beta }\right) /\partial \mathbf{\beta }
\right| _{\mathbf{\beta }=\mathbf{B}}=-\mathbf{z}_{U}^{\prime }\mathbf{z}
_{U}\;\;.  \nonumber
\end{eqnarray}

Substituindo em \@ref(eq:norm8) e \@ref(eq:norm9)  os valores dos escores, do
jacobiano e dos estimadores $\pi$-ponderados correspondentes, obtemos as
seguintes expressões para a variância assintótica de aleatorização do estimador de MPV padrão $\widehat{\mathbf{B}}_{\pi}$ e
seu estimador consistente, dadas por

\begin{equation}
V_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_{U}^{\prime }\mathbf{z}_{U}\right) ^{-1}V_{p}\left( \sum\limits_{i\in s}\pi
_{i}^{-1}\mathbf{z}_{i}e_{i}\right) \left( \mathbf{z}_{U}^{\prime }\mathbf{z}
_{U}\right) ^{-1}  (\#eq:norm21)
\end{equation}
e 

\begin{equation}
\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\hat{V}
_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}e_{i}\right)
\left( \mathbf{z}_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right)
^{-1}\;,  (\#eq:norm22)
\end{equation}
onde

\begin{equation}
V_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}e_{i}\right)
=\sum\limits_{i\in U}\sum\limits_{j\in U}\frac{\pi _{ij}-\pi _{i}\pi _{j}}{
\pi _{i}\pi _{j}}e_{i}\mathbf{z}_{i}\mathbf{z}_{j}^{\prime }e_{j}\;\;,
(\#eq:norm23)
\end{equation}

\begin{equation}
\hat{V}_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}\hat{e}
_{i}\right) =\sum\limits_{i\in s}\sum\limits_{j\in s}\left( \pi _{i}^{-1}\pi
_{j}^{-1}-\pi _{ij}^{-1}\right) \hat{e}_{i}\mathbf{z}_{i}\mathbf{z}
_{j}^{\prime }\hat{e}_{j}\;\;,  (\#eq:norm24)
\end{equation}
e $\hat{e}_{i}=y_{i}-\mathbf{z}_{i}^{\prime }\widehat{\mathbf{B}}_{\pi }$
para $i\in s$.

Isto completa a especificação de um procedimento de máxima
pseudo-verossimilhança para ajustar modelos normais de regressão
como \@ref(eq:norm1). Este procedimento é bastante flexível e
aplicável numa ampla gama de planos amostrais.

## Modelo de Regressão Logística {#modlogist}

No modelo de regressão logística, a variável resposta $y$ é
binária, isto é, assume os valores $0$ e $1$. Considerando um vetor $\mathbf{z}$ de variáveis explanatórias tal como o empregado no
modelo de regressão linear discutido na Seção \@ref(modlinear), o
modelo de superpopulação é dado por 
\begin{equation}
f(y_{i}|\mathbf{z}_{i},\mathbf{\beta )=}\left[ p\left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) \right] ^{y_{i}}\left[ 1-p\left( 
\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) \right] ^{1-y_{i}},
(\#eq:norm25)
\end{equation}
onde, 

\[
p\left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) =P\left( \left.
Y_{i}=1\right| \mathbf{Z}_{i}=\mathbf{z}_{i}\right) =\exp \left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\left[ 1+\exp \left( \mathbf{z}
_{i}^{\prime }\mathbf{\beta }\right) \right] \;. 
\]

A função escore de $\mathbf{\beta }$ é

\begin{equation}
\mathbf{u}_{i}\left( \mathbf{\beta }\right) =\partial \log (y_{i}|\mathbf{z}_{i},\mathbf{\beta )/\partial \beta =}\left[ y_{i}-p\left( \mathbf{z}
_{i}^{\prime }\mathbf{\beta }\right) \right] \mathbf{z}_{i}  (\#eq:norm25a)
\end{equation}
e portanto a equação de verossimilhança do censo correspondente
é dada por

\begin{equation}
\sum\nolimits_{i\in U}\mathbf{u}_{i}\left( \mathbf{\beta }\right)
=\sum\nolimits_{i\in U}\left[ y_{i}-p\left( \mathbf{z}_{i}^{\prime }\mathbf{
\beta }\right) \right] \mathbf{z}_{i}=\mathbf{0\;.}  (\#eq:norm26)
\end{equation}

O estimador de MPV do vetor de coeficientes $\mathbf{\beta }$ no modelo \@ref(eq:norm25) é a solução da equação

\begin{equation}
\sum\nolimits_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\beta }\right)
=\sum\nolimits_{i\in s}w_{i}\left[ y_{i}-p\left( \mathbf{z}_{i}^{\prime }
\mathbf{\beta }\right) \right] \mathbf{z}_{i}=\mathbf{0},
(\#eq:norm27)
\end{equation}
onde $w_{i}$ é o peso da $i$-ésima observação amostral.

A matriz de covariância do estimador de MPV de $\mathbf{\beta}$ pode
ser obtida conforme indicado na Seção \@ref(modpar3), bastando
substituir os valores dos escores 
$\mathbf{u}_{i}\left( \mathbf{\beta}\right) =\left[ y_{i}-p\left(\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right)\right] \mathbf{z}_{i}$ e do jacobiano correspondentes. Para maiores
detalhes, o leitor interessado pode consultar Binder(1983), que aborda o
problema da estimação da matriz de covariância dos estimadores
de MPV na família de modelos lineares generalizados, da qual o modelo de
regressão logística é caso particular.

Vale observar que, tal como no caso da modelagem clássica, a obtenção dos estimadores de MPV dos parâmetros no modelo de regressão
logística depende da solução por métodos numéricos de um
sistema de equações. Portanto é importante dispor de um pacote
computacional adequado para efetuar os cálculos. Hoje em dia já
estão disponíveis vários pacotes com essa funcionalidade,
conforme se discute no Capítulo \@ref(pacotes).

```{example,label="pnad6"}
Análise do perfil sócio-econômico das pessoas
ocupadas no setor informal da economia na área urbana do Rio de Janeiro 
```

Utilizando dados do Suplemento Trabalho da Pesquisa Nacional por Amostra
de Domicílios (**PNAD**) de 90, Leote(1996) analisou o perfil
sócio-econômico das pessoas ocupadas no setor informal da economia
na área urbana do Rio de Janeiro.

Os dados utilizados são relativos a pessoas que:


-  moravam em domicílios urbanos do estado do Rio de Janeiro;

-  trabalhavam em atividades mercantis (não foram incluídos
trabalhadores domésticos);

-  na semana da pesquisa estavam trabalhando ou não estavam
trabalhando por estarem de férias, licença, etc., mas tinham
trabalho;

-  desenvolviam atividades não agrícolas.


As pessoas que trabalhavam em locais com até cinco pessoas ocupadas
foram classificadas no setor informal, independente da posição de
ocupação delas, enquanto as que trabalhavam em locais com mais de
cinco pessoas ocupadas foram classificadas no setor formal. O trabalho
refere-se ao trabalho principal. Para a variável renda considerou-se a
soma dos rendimentos de todos os trabalhos.

Foi considerada uma amostra de $6.507$ pessoas (após a exclusão de $9$ registros considerados atípicos), classificadas de acordo com as
variáveis descritas na Tabela \@ref(tab:varexp), todas tratadas como
fatores na análise. A variável ht foi considerada como a soma de
horas trabalhadas em todos os trabalhos, por semana. A variável re
compreende a renda média mensal de todos os trabalhos, em salários
mínimos.

|            Fatores           | Níveis   | Descrição dos níveis   |
|:----------------------------:|:--------:|:----------------------:|
|           Sexo (sx)          |  sx(1)   |        Homens          |
|              $~$             |  sx(2)   |       Mulheres         |
|      Anos de Estudo (ae)     |  ae(1)   |         Até 4          |
|              $~$             |  ae(2)   |       De 5 a 8         |
|              $~$             |  ae(3)   |       9 ou mais        |
|    Horas trabalhadas (ht)    |  ht(1)   |     Menos de 40        |
|              $~$             |  ht(2)   |      De 40 a 48        |
|              $~$             |  ht(3)   |      Mais de 48        |
| Idade em anos completos (id) |  id(1)   |        Até 17          |
|              $~$             |  id(2)   |      De 18 a 25        |
|              $~$             |  id(3)   |      De 26 a 49        |
|              $~$             |  id(4)   |      50 ou mais        |
| Rendimento Médio Mensal (re) |  re(1)   |      Menos de 1        |
|              $~$             |  re(2)   |        De 1 a 5        |
|              $~$             |  re(3)   |       Mais de 5        |

Table:(#tab:varexp)Descrição das variáveis explicativas

Os fatores considerados foram tomados como explicativos e a variável
resposta foi o indicador de pertinência ao setor informal da
economia. Foi ajustado um modelo logístico (Agresti, 1990) para
explicar a probabilidade de uma pessoa pertencer ao setor informal da
economia.

Para a seleção do modelo foi usada a função `glm` do **S-Plus**, aplicada aos dados tabelados. O modelo final selecionado
foi escolhido passo a passo, incluindo em cada passo as interações
que produziam maior decréscimo do desvio residual, considerando a perda
de graus de liberdade. O modelo selecionado foi

\begin{eqnarray}
\log \left( \frac{p_{ijklm}}{1-p_{ijklm}}\right) &=&\mu +\beta
_{i}^{sx}+\beta _{j}^{ae}+\beta _{k}^{ht}+\beta _{l}^{id}+\beta _{m}^{re}
(\#eq:norm28) \\
&&+\beta _{ij}^{sx.id}+\beta _{ik}^{sx.ht}+\beta _{jk}^{ae.ht}+\beta
_{kl}^{ht.id}+\beta _{km}^{ht.re},  \nonumber
\end{eqnarray}
onde $p_{ijklm}$ é a probabilidade de pertencer ao setor informal
correspondente à combinação de níveis das variáveis
explicativas, sendo i=1, 2 o nível de sx; j=1, 2, 3 o nível de ae;
k=1, 2, 3 o nível de ht; l=1, 2, 3, 4 o nível de id e m=1, 2, 3 o
nível de re.

Os efeitos foram adicionados sequencialmente na ordem da Tabela \@ref(tab:varexp). Depois de introduzidos os efeitos principais, as interações
de dois fatores foram introduzidas na ordem definida pela 
`função step do S-Plus`.

O $p$valor do teste de nulidade das interações não incluídas
no modelo é 0,0515, aceitando-se a hipótese de nulidade destes
efeitos ao nível $\alpha =0,05$. O modelo obtido difere do selecionado
em Leote(1996) só pela inclusão de mais um efeito, referente à
interação ae:ht.

Uma descrição detalhada do plano amostral da PNAD 90 foi apresentada
no Exemplo \@ref(exm:pnad). Como se pode observar dessa descrição, o
plano amostral da PNAD apresenta todos os aspectos de um plano amostral
complexo, incluindo estratificação (geográfica), seleção
de unidades primárias (municípios, ou setores nos municípios
auto-representativos) ou secundárias (setores nos municípios não
auto-representativos) com probabilidades desiguais, conglomeração
(de domicílios em setores, e de pessoas nos domicílios) e seleção sistemática sem reposição de unidades. Nesse caso, fica
difícil admitir a priori com confiança as hipóteses usuais de
modelagem das observações amostrais como IID. Por esse motivo foram
considerados métodos alternativos de modelagem e ajuste.

Apresentamos a seguir as estimativas dos efeitos principais e interações do modelo selecionado e seus respectivos desvios padrões,
calculadas pela função `svyglm()`da library `survey` [@R-survey]. 

As estimativas calculadas pela função `svyglm` são feitas pelo 
`Método de Máxima Pseudo-Verossimilhança`, resolvendo a equação \@ref(eq:norm27). As estimativas dos desvios padrões são
obtidas das variâncias calculadas pelo método de linearização descrito na Seção \@ref(modpar3), equação \@ref(eq:modpar5),
considerando os escores tal como apresentados na equação \@ref(eq:norm25a). Para esses cálculos, os estimadores de variância considerados
levaram em conta os pesos das observações, mas utilizaram uma
aproximação que consiste em considerar que as unidades primárias
de amostragem foram selecionadas com reposição, conforme descrito na Seção .


```{r logit, echo=FALSE, warning=FALSE, message=FALSE}
library(survey)
library(anamco) # carrega dados
# transforma variáveis sx, id, ae, ht e re em fatores
# Fixa último nível como referência
pnadrj90$sx<-as.factor(pnadrj90$sx)
pnadrj90$sx<-relevel(pnadrj90$sx,ref="2")
pnadrj90$id<-as.factor(pnadrj90$id)
pnadrj90$id<-relevel(pnadrj90$id,ref="4")
pnadrj90$ae<-as.factor(pnadrj90$ae)
pnadrj90$ae<-relevel(pnadrj90$ae,ref="3")
pnadrj90$ht<-as.factor(pnadrj90$ht)
pnadrj90$ht<-relevel(pnadrj90$ht,ref="3")
pnadrj90$re<-as.factor(pnadrj90$re)
pnadrj90$re<-relevel(pnadrj90$re,ref="3")
##transformar variável de resposta para 0,1:
pnadrj90$informal<-ifelse(pnadrj90$informal==1,1,0)
# cria objeto de desenho a partir do data frame pnadrj90
pnad.des<-svydesign(id=~psu,strata=~stra,weights=~pesopes,data=pnadrj90,nest=TRUE)
# ajusta modelo de regressão logística
inf.logit<-svyglm(informal~sx+ae+ht+id+re+sx*id+sx*ht+ae*ht+ht*id+ht*re,
  design=pnad.des,family=quasibinomial())
knitr::kable(summary(inf.logit)$coefficients, booktabs=TRUE, digits=3,
  caption= "Estmativas dos efeitos e respectivos erros padrões obtidos pela library survey do R")
```



Na Tabela \@ref(tab:testmodlogit) são apresentadas as probabilidades de
significância dos testes de nulidade dos efeitos do modelo. Todos os
efeitos incluídos no modelo são significativos, nos níveis
usuais de significância. A **PROC LOGISTIC** do pacote 
**SUDAAN** não inclui testes para os efeitos principais, por não ser
possível separar tais efeitos das interações. A coluna de $p$
valores da Tabela \@ref(tab:testmodlogit), obtida pela função `svyglm()` da library survey,
utiliza a estatística de Wald baseada no plano amostral com correção. 

Os testes da Tabela \@ref(tab:testmodlogit) indicam a significância de todas as
interações de 2 fatores que entraram no modelo selecionado. O teste
de qualidade global de ajuste, na primeira linha da Tabela \@ref(tab:testmodlogit), indica a necessidade de serem introduzidas novas interações.


```{r testmodlogit, echo=FALSE}
# testa nulidade da interação ht:re
testa_ht_re <- regTermTest(inf.logit,"ht:re")
# testa nulidade da interação ht:id
testa_ht_id <- regTermTest(inf.logit,"ht:id")
# testa nulidade da interação sx:id
testa_sx_id <- regTermTest(inf.logit,"sx:id")
# testa nulidade da interação sx:ht
testa_sx_ht <- regTermTest(inf.logit,"sx:ht")
# testa nulidade da interação ae:ht
testa_ae_ht <- regTermTest(inf.logit,"ae:ht")
# organiza resultados
res.test <- data.frame(
 Contraste = c(testa_ht_re$test.terms,testa_ht_id$test.terms,testa_sx_id$test.terms,
testa_sx_ht$test.terms,testa_ae_ht$test.terms ),
  gl_num = c(testa_ht_re$df,testa_ht_id$df,testa_sx_id$df,
testa_sx_ht$df,testa_ae_ht$df),
  gl_den = c(testa_ht_re$ddf,testa_ht_id$ddf,testa_sx_id$ddf,
testa_sx_ht$ddf,testa_ae_ht$ddf),
  Estatística_F= c(testa_ht_re$Ftest,testa_ht_id$Ftest,testa_sx_id$Ftest,
testa_sx_ht$Ftest,testa_ae_ht$Ftest),
  valor_p = c(testa_ht_re$p,testa_ht_id$p,testa_sx_id$p,
testa_sx_ht$p,testa_ae_ht$p)
)
knitr::kable(res.test, booktabs=TRUE, digits=c(0,0,0,3,3),
caption="Testes de hipóteses de Wald de nulidade dos efeitos do modelo"  
  )

```


Para comparação, apresentamos na Tabela \@ref(tab:razvant) algumas
estimativas de razões de vantagens, relevantes na análise,
calculadas pela função `svyglm()` da library survey e, na 
Tabela \@ref(tab:icvant) os correspondentes intervalos de confiança de $95\%$. Na
construção destes intervalos foi necessário utilizar estimativas
pontuais dos efeitos bem como a matriz de covariância estimada dos
estimadores dos efeitos do modelo. Deste modo, estes intervalos sumarizam,
ao mesmo tempo, discrepâncias existentes tanto nas estimativas pontuais
dos efeitos como nas variâncias e covariâncias das estimativas.


```{r razvant, echo=FALSE}
est_coef <- coef(inf.logit)
one <- rep(0, length(coef(inf.logit)))
names(one)<- names(coef(inf.logit))
# razão de vantagem quando ht=1 e ae passa de 1 para 2
raz112<- one
raz112["ae2"]<-1; raz112["ae1"]<--1; raz112["ae2:ht1"]<- 1; raz112["ae1:ht1"]<- -1
ht1_ae1_ae2 <- exp(sum(raz112*coef(inf.logit)))
# razão de vantagem quando ht=1 e ae passa de 2 para 3
raz123 <- one
raz123["ae2"]<- -1;  raz123["ae2:ht1"]<- -1
ht1_ae2_ae3 <- exp(sum(raz123*coef(inf.logit)))
# razão de vantagem quando ht=2 e ae passa de 1 para 2
raz212 <- one
raz212["ae2"]<- 1;raz212["ae1"]<- -1;   raz212["ae2:ht2"]<- 1; raz212["ae1:ht2"]<- -1
ht2_ae1_ae2 <- exp(sum(raz212*coef(inf.logit)))
# razão de vantagem quando ht=2 e ae passa de 2 para 3
raz223 <- one
raz223["ae2"]<- -1;  raz223["ae2:ht2"]<- -1
ht2_ae2_ae3 <- exp(sum(raz223*coef(inf.logit)))
# ht=3 ae de 1 para 2
raz312 <- one
raz312["ae2"]<- 1;  raz312["ae1"]<- -1
ht3_ae1_ae2 <- exp(sum(raz312*coef(inf.logit)))
# razão de vantagem quando ht=3 e ae passa de 2 para 3
raz323 <- one
raz323["ae2"]<- -1  
ht3_ae2_ae3 <- exp(sum(raz323*coef(inf.logit)))

# resumo de resultados
raz_vant <- data.frame (ht= c(1,1,2,2,3,3), 
  varia_ae=c("1 para 2", "2 para 3", "1 para 2", "2 para 3", "1 para 2","2 para 3"),
  raz_vantagem = c(ht1_ae1_ae2,ht1_ae2_ae3,ht2_ae1_ae2,ht2_ae2_ae3,ht3_ae1_ae2, ht3_ae2_ae3 )
  )
knitr::kable(raz_vant, booktabs=TRUE, digits=c(0,0,3),
 caption="Estimativas das razões de vantagens, variando-se os níveis de ae para níveis fixos
  de ht" )
```



```{r icvant, echo=FALSE}
# I.C. de 95% para razão de vantagem raz112
var_raz112 <- matrix(raz112, nrow=1)%*% vcov(inf.logit)%*%matrix(raz112, ncol=1)
ic_raz112 <- exp(sum(raz112*coef(inf.logit))*c(1,1)+1.96* as.vector(sqrt(var_raz112))*c(-1,1))
names(ic_raz112)<- NULL

# I.C. de 95% para razão de vantagem raz123
var_raz123 <- matrix(raz123, nrow=1)%*% vcov(inf.logit)%*%matrix(raz123, ncol=1)
ic_raz123 <- exp(sum(raz123*coef(inf.logit))*c(1,1)+1.96* as.vector(sqrt(var_raz123))*c(-1,1))
names(ic_raz123)<- NULL

# I.C. de 95% para razão de vantagem raz212
var_raz212 <- matrix(raz212, nrow=1)%*% vcov(inf.logit)%*%matrix(raz212, ncol=1)
ic_raz212 <- exp(sum(raz212*coef(inf.logit))*c(1,1)+1.96* as.vector(sqrt(var_raz212))*c(-1,1))
names(ic_raz212)<- NULL 

# I.C. de 95% para razão de vantagem raz223
var_raz223 <- matrix(raz223, nrow=1)%*% vcov(inf.logit)%*%matrix(raz223, ncol=1)
ic_raz223 <- exp(sum(raz223*coef(inf.logit))*c(1,1)+1.96* as.vector(sqrt(var_raz223))*c(-1,1))
names(ic_raz223)<- NULL

# I.C. de 95% para razão de vantagem raz312
var_raz312 <- matrix(raz312, nrow=1)%*% vcov(inf.logit)%*%matrix(raz312, ncol=1)
ic_raz312 <- exp(sum(raz223*coef(inf.logit))*c(1,1)+1.96*as.vector(sqrt(var_raz312))*c(-1,1))
names(ic_raz312)<- NULL

# I.C. de 95% para razão de vantagem raz323
var_raz323 <- matrix(raz323, nrow=1)%*% vcov(inf.logit)%*%matrix(raz323, ncol=1)
ic_raz323 <- exp(sum(raz323*coef(inf.logit))*c(1,1)+1.96* as.vector(sqrt(var_raz323))*c(-1,1))
names(ic_raz323)<- NULL

# resumo de resultados:
ic_frame <- data.frame(
  ht= c(1,1,2,2,3,3),
  varia_ae=c("1 para 2", "2 para 3", "1 para 2", "2 para 3", "1 para 2","2 para 3"),
  LIC <- c(ic_raz112[1],ic_raz123[1], ic_raz212[1], ic_raz223[1], ic_raz312[1], ic_raz323[1]), 
  LSC <- c(ic_raz112[2],ic_raz123[2], ic_raz212[2], ic_raz223[2], ic_raz312[2], ic_raz323[2]) 
  )
names(ic_frame)<- c("ht", "varia_ae","LIC", "LSC")
knitr::kable(ic_frame, booktabs=TRUE, digits=c(0,0,3,3),
 caption="Intervalos de confiança de 95% para razões de vantagens, variando-se os níveis de ae para níveis fixos
  de ht" )


```


Além dos ajustes aqui comparados, foram feitos (embora não
apresentados) os seguintes ajustes com a utilização do 
__S-Plus__:

1) dados individuais (resposta 0-1) considerando os pesos; 

2) dados da tabela estimada considerando os pesos e 

3) dados individuais com pesos normalizados. 

Em todas estas análises, como esperado, as estimativas
pontuais dos efeitos coincidiram com as obtidas pela __PROC LOGISTIC__
do pacote __SUDAAN__. Pode-se notar que, neste exemplo, há estreita
concordância entre as estimativas pontuais obtidas pelos dois pacotes.

A concordância das estimativas dos coeficientes pode ser explicada, em
parte, pela pequena variabilidade dos pesos das unidades, tal como se pode
verificar na Tabela \@ref(tab:pesofreq), que apresenta a distribuição de
frequências dos pesos.


```{r,pesofreq, echo=FALSE}
tab_peso <-table(pnadrj90$pesopes)
fr_peso <- data.frame (tab_peso)
names(fr_peso)<- c("Valor do peso","Frequência")
knitr::kable(fr_peso, booktabs=TRUE,
caption= "Distribuição de frequências dos pesos da amostra da PNAD-90 - Parte
Urbana do Rio de Janeiro") 
```


Como foi visto na Tabela \@ref(tab:logit), o impacto do plano amostral nas
estimativas de precisão é um pouco maior. As maiores diferenças
entre os dois métodos ocorrem na estimação dos desvios das
estimativas dos parâmetros do primeiro nível de idade (até 17
anos) e da interação deste com horas trabalhadas (tanto no nível
de menos de 40 horas semanais como no nível de 40 a 48 horas semanais
trabalhadas). Esta diferenciação maior no caso dos desvios
padrões já era esperada. Quando não levamos em conta os pesos
nem o plano amostral na estimação dos parâmetros, podemos
até chegar em uma estimativa pontual dos coeficientes bem próxima de
quando levamos ambos em conta, mas as estimativas dos desvios padrões
são mais sensíveis a esta diferença entre as análises. A
tendência revelada é de subestimação dos desvios padrões
pelo __S-Plus__ ao ignorar o plano amostral e a variação dos
pesos.

Neste exemplo, foi utilizada a função glm do __S-Plus__ na seleção do modelo. Feita a seleção, o mesmo modelo foi ajustado
através da __PROC LOGISTIC__ do  __SUDAAN__. O propósito
foi imitar uma situação onde o modelo já tivesse sido
selecionado e ajustado por usuário secundário dos dados, sem
considerar os pesos e o plano amostral, tal como é usual. Outra
possibilidade seria repetir o processo de seleção do modelo
usando-se a **PROC LOGISTIC** do **SUDAAN**. Isto poderia ser
feito passo a passo, incluindo efeitos e interações que melhorassem
mais a qualidade de ajuste, tal como foi feito automaticamente pela função **step do S-Plus**. Este procedimento possibilitaria comparar a
seleção de modelos quando são considerados os pesos e o plano
amostral na análise.

Diferentemente dos pacotes mais usados de análise estatística, tais
como SAS, S-Plus, BMDP, etc., o SUDAAN não possui, atualmente,
ferramentas usuais de diagnóstico de ajuste de modelos, como
gráficos de resíduos padronizados, etc., tornando mais difícil
seu uso na etapa de seleção de modelos. Considerando-se a maior
dificuldade de seleção de modelos através do **SUDAAN**,
preferiu-se usá-lo aqui apenas para ajustar um modelo já selecionado.

## Teste de Hipóteses

Nas Seções \@ref(modlinear) e \@ref(modlogist) discutimos formas de introduzir pesos e plano
amostral em procedimentos de estimação pontual e de variâncias
ao ajustar modelos com dados de pesquisas amostrais complexas. Neste
contexto, procedimentos estatísticos de teste de hipóteses devem,
também, sofrer adaptações. Nesta seção, esse problema
será abordado de forma sucinta, para modelos de regressão.

De modo geral, testes de hipóteses em regressão surgem inicialmente
na seleção de modelos e também para fornecer evidência
favorável ou contrária a indagações levantadas pelo
pesquisador.

Denotemos por $\mathbf{\beta }=\left( \beta _{1},\ldots ,\beta _{P}\right)
^{\prime }$ o vetor de parâmetros num modelo de regressão. Como
é sabido, para testar a hipótese $H_{0}:\beta _{j}=0$, para algum 
$j\in \left\{ 1,\ldots ,P\right\} \mathbf{,}$ usamos um teste $t,$ e para
para testar a hipótese $H_{0}:\left( \beta _{j_{1}},\ldots ,\beta
_{j_{R}}\right) ^{\prime }=\mathbf{0}_{R}$, onde $\left( j_{1},\ldots
,j_{R}\right) \subset \left( 1,\ldots ,P\right)$ e $\mathbf{0}_{R}$ é o
vetor zero $R$-dimensional, usamos um teste $\mathbf{F}$. Tais testes $t$ e 
$\mathbf{F}$, sob as hipóteses do modelo clássico de regressão
com erros normais, são testes da Razão de Máxima Verossimilhança.

é pois natural tentar adaptar testes de Razão de Máxima
Verossimilhança para pesquisas amostrais complexas, tal como
foi feito na derivação de estimadores de MPV a partir de estimadores
de Máxima Verossimilhança. A principal dificuldade é que no
contexto de pesquisas complexas, devido aos pesos distintos das observações e ao plano amostral utilizado, a função de verossimilhança usual não representa a distribuição conjunta das observações. Apesar desta dificuldade ter sido contornada na derivação
de estimadores de MPV, a adaptação fica bem mais difícil no caso
de testes da Razão de Máxima Verossimilhança.

Por essa causa, é mais fácil basear os testes na estatística
Wald, que mede a distância entre uma estimativa pontual e o valor
hipotético do parâmetro numa métrica definida pela matriz de
covariância do estimador. Pesos e plano amostral podem ser incorporados
facilmente nessa estatística, bastando para isto utilizar estimativas
apropriadas (consistentes sob aleatorização) dos parâmetros e da
matriz de covariância, tais como as que são geradas pelo método
de MPV. é essa abordagem que vamos adotar aqui.

Considere o problema de testar a hipótese linear geral 
\begin{equation}
H_{0}:\mathbf{C\beta }=\mathbf{c},  (\#eq:norm30)
\end{equation}
onde $\mathbf{C}$ é uma matriz de dimensão $R\times P$ de posto
pleno $R=P-Q$ e $\mathbf{c}$ é um vetor $R$ $\times 1.$

Um caso particular de interesse é testar a hipótese aninhada 
$H_{0}:\mathbf{\beta }_{2}=\mathbf{0}_{R}\mathbf{,}$ onde 
$\mathbf{\beta }^{\prime}=\left( \mathbf{\beta }_{1}^{\prime },\mathbf{\beta }_{2}^{\prime }\right)$
, com $\mathbf{\beta }_{1}$ de dimensão  $Q\times 1$ e $\mathbf{\beta}_{2}$ de dimensão $R\times 1$, 

$\mathbf{C}= \left[\begin{array}{lll}\mathbf{0}_{R\times Q} &  & \mathbf{I}_{R}\end{array}\right]$ e 
$c=\mathbf{0}_{R}$ , sendo $\mathbf{0}_{R\times Q}$ matriz de
zeros de dimensão $R\times Q$ e $\mathbf{I}_{R}$ a matriz identidade de
ordem $R$.

A estatística de Wald clássica para testar a hipótese nula \@ref(eq:norm30) é definida por

\begin{equation}
X_{W}^{2}=\left( \mathbf{C}\widehat{\mathbf{\beta }}-\mathbf{c}\right)
^{\prime }\left( \mathbf{C}\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}
\right) \mathbf{C}^{\prime }\right) ^{-1}\left( \mathbf{C}\widehat{\mathbf{
\beta }}\mathbf{-c}\right),  (\#eq:norm31)
\end{equation}
onde os estimadores $\widehat{\mathbf{\beta }}$ e 
$\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)$ são obtidos pela teoria de
mínimos quadrados ordinários. Sob $H_{0}$, a distribuição
assintótica da estatística $X_{W}^{2}$ é $\chi ^{2}\left(R\right)$.

Quando os dados são obtidos através de pesquisas amostrais
complexas, a estatística $X_{W}^{2}$ deixa de ter distribuição
assintótica $\chi ^{2}\left( R\right)$, e usar esta última como
distribuição de referência implica na obtenção de testes
com níveis de significância incorretos. Esse problema é
solucionado substituindo-se na expressão de 
$X_{W}^{2}$, $\mathbf{\hat{\beta}}$ pela estimativa MPV 
$\widehat{\mathbf{B}}_{\pi }$ de $\mathbf{\beta}$ dada em \@ref(eq:norm18), e $\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)$pela estimativa da matriz de covariância do estimador de MPV $\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right)$ dada em \@ref(eq:norm22).
Tais estimativas consideram os pesos diferentes das observações e o
plano amostral efetivamente utilizado. A normalidade assintótica do
estimador de MPV de $\mathbf{\beta}$ e a consistência do estimador da
matriz de covariância correspondente (Binder, 1983) implicam que 
\[
X_{W}^{2}\sim \chi^{2}\left( R\right)\mbox{, sob }H_{0}.
\]

Esta aproximação não leva em conta o erro amostral na estimação de $\mathbf{V}\left( \mathbf{\hat{\beta}}\right) .$ Uma alternativa
é usar a aproximação 
\[
X_{W}^{2}/R\sim \mathbf{F}(R,\upsilon),
\]
onde $\upsilon =$ $m-H$ é o número de UPAs da amostra menos o
n\'{u}mero de estratos considerados no plano amostral para seleção
das UPAs, que fornece uma medida de graus de liberdade apropriada para
amostras complexas quando o método do conglomerado primário é
empregado para estimar variâncias.

Com a finalidade de melhorar a aproximação da distribuição
da estatística de teste, podem ser utilizados ajustes e correções da estatística $X_{W}^{2}$, que são apresentados com mais
detalhes nos Capítulos \@ref(testqualajust) e \@ref(testetab2) para o caso da análise de dados
categóricos.

A especificação de um procedimento para testar hipóteses sobre
os parâmetros de um modelo de regressão completa a abordagem para
ajuste de modelos desse tipo partindo de dados amostrais complexos.
Entretanto, uma das partes importantes da teoria clássica para modelagem
é a que trata do diagnóstico dos modelos ajustados, muitas vezes
empregando recursos gráficos. Nessa parte a abordagem baseada em MPV e
em estatísticas de Wald deixa a desejar, pois não é possível
adaptar de maneira simples as técnicas clássicas de diagnóstico.
Por exemplo, é difícil considerar pesos ao plotar os resíduos do
ajuste dum modelo via MPV. Essa é questão que ainda merece maior
investigação e por enquanto é uma desvantagem da abordagem aqui
preconizada.

## Laboratório de R

Usar exemplo da amolim ou conseguir exemplo melhor?
Reproduzir usando a survey os resultados do Exemplo 6.1???


```{r}
library(survey)
library(anamco)
names(pnadrj90)
```
Preparação dos dados: Variáveis explicativas são fatores.
Ver tipo de variável:
```{r}
unlist(lapply(pnadrj90, mode))
```
Transformar variáveis para fatores e mudar o nível básico do fator (último)
```{r}
pnadrj90$sx<-as.factor(pnadrj90$sx)
pnadrj90$sx<-relevel(pnadrj90$sx,ref="2")
pnadrj90$id<-as.factor(pnadrj90$id)
pnadrj90$id<-relevel(pnadrj90$id,ref="4")
pnadrj90$ae<-as.factor(pnadrj90$ae)
pnadrj90$ae<-relevel(pnadrj90$ae,ref="3")
pnadrj90$ht<-as.factor(pnadrj90$ht)
pnadrj90$ht<-relevel(pnadrj90$ht,ref="3")
pnadrj90$re<-as.factor(pnadrj90$re)
pnadrj90$re<-relevel(pnadrj90$re,ref="3")
##transformar variável de resposta para 0,1:
pnadrj90$informal<-ifelse(pnadrj90$informal==1,1,0)
```

Cria objeto de desenho

```{r}
pnad.des<-svydesign(id=~psu,strata=~stra,weights=~pesopes,data=pnadrj90,nest=TRUE)
```

Ajusta modelo de regressão logística na Tabela \@ref(tab:logit)
Comparar resultado com o da página 106 de Pessoa e Silva (1998)

```{r, message=FALSE, warning=FALSE}
inf.logit<-svyglm(informal~sx+ae+ht+id+re+sx*id+sx*ht+ae*ht+ht*id+ht*re,
  design=pnad.des, family=quasibinomial())
```


```{r, results='asis'}
knitr::kable(summary(inf.logit)$coefficients,booktabs=TRUE, digits= c(3,3,3,2))
```



Teste de Wald para a hipótese $H_0: ht:re=0$

```{r}
regTermTest(inf.logit,"ht:re")
```











