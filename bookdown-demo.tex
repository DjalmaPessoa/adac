\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Análise de Dados Amostrais Complexos},
            pdfauthor={Djalma Pessoa e Pedro Nascimento Silva},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{Análise de Dados Amostrais Complexos}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Djalma Pessoa e Pedro Nascimento Silva}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{2016-12-30}

\usepackage{booktabs}

\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{Prefácio}\label{prefacio}
\addcontentsline{toc}{chapter}{Prefácio}

\chapter{Introdução}\label{introducao}

\chapter{Referencial para Inferência}\label{referencial-para-inferencia}

\chapter{Estimação Baseada no Plano Amostral}\label{planamo}

\chapter{Efeitos do Plano Amostral}\label{efeitos-do-plano-amostral}

\chapter{Ajuste de Modelos
Paramétricos}\label{ajuste-de-modelos-parametricos}

\chapter{Modelos de Regressão}\label{modelos-de-regressao}

\section{Modelo de Regressão Linear Normal}\label{modlinear}

O problema considerado nesta seção é o de estimar os parâmetros num
modelo de regressão linear normal especificado para um subconjunto das
variáveis da pesquisa. O procedimento de máxima pseudo-verossimilhança,
descrito na Seção \ref{modpar3}, é aplicado. Os resultados são derivados
considerando pesos ordinários dados pelo inverso das probabilidades de
inclusão das unidades na amostra. Resultados mais gerais considerando
outros tipos de pesos (tais como os derivados de estimadores de razão ou
regressão, por exemplo) estão discutidos em Nascimento Silva(1996, cap.
6).

\subsection{Especificação do Modelo}\label{especificacao-do-modelo}

Vamos supor que os dados da \(i\)-ésima unidade da população pesquisada
incluam um vetor
\(\mathbf{z}_{i}=\left( z_{i1},\ldots ,z_{iP}\right) ^{^{\prime }}\) de
dimensão \(P\times 1\) com os valores de variáveis \(\mathbf{z}\), que
são \texttt{preditoras} ou explanatórias num modelo de regressão \(M\).
Este modelo tem o objetivo de predizer ou explicar os valores de uma
variável da pesquisa \(y\), queé considerada como variável
\texttt{resposta}. Denotemos por \(Y_{i}\) e \(\mathbf{Z}_{i}\) a
variável e o vetor aleat'\{o\}rios que geram \(y_{i}\) e
\(\mathbf{z}_{i}\), para \(i\in U\). Sem perda de generalidade,
suponhamos também que a primeira componente do vetor \(\mathbf{z}_{i}\)
de variáveis preditorasé sempre igual a \(1\), de modo a incluir sempre
um termo de intercepto nos modelos de regressão linear considerados (tal
hipótese não é essencial, mas será adotada no restante deste capítulo).
Suponhamos agora que
\(\left( Y_{i},\mathbf{Z}_{i}^{^{\prime }}\right) ^{^{\prime }},\;i\in U\),
são vetores aleatórios independentes e identicamente distribuídos tais
que

\begin{equation}
f\left( \left. y_{i}\right|\mathbf{z}_{i};\mathbf{\beta },\sigma_{e}\right) =\left( 2\pi \sigma _{e}\right) ^{-1/2}\exp \left[ -\left( y_{i}-\mathbf{z}_{i}^{^{\prime }}\mathbf{\beta }\right) ^{2}/2\sigma _{e}\right]
\label{eq:norm1}
\end{equation}

onde
\(\mathbf{\beta }=\left( \beta _{1},\ldots ,\beta _{P}\right) ^{^{\prime }}\)
e \(\sigma_{e}>0\) são parâmetros desconhecidos do modelo.

Observe que \eqref{eq:norm1} constitui-se numa especificação (parcial) de
um modelo marginal para um conjunto de variáveis da pesquisa, e não faz
nenhuma referência direta à forma como elas se relacionam com variáveis
auxiliares \(\mathbf{x}\) que eventualmente possam estar disponíveis. A
atenção é focalizada na estimação de \(\mathbf{\beta }\) e
\(\sigma_{e}\) e sua interpretação com respeito ao modelo agregado
\eqref{eq:norm1}.

Modelos como \eqref{eq:norm1} já foram considerados por vários autores,
por exemplo Holt, Smith e Winter(1980), Nathan e Holt (1980),
Skinner(1989b, p.81), Chambers(1986, 1995). Eles são simples, mesmo
assim frequentemente usados pelos analistas de dados, pelo menos como
uma primeira aproximação. Além disto, eles satisfazem todas as condições
padrões de regularidade. Assim eles são adequados a uma aplicação de
procedimentos de máxima pseudo-verossimilhança descritos na Seção
@ref\{modpar3\}.

As funções escores para \(\mathbf{\beta}\) e \(\sigma _{e}\)
correspondentes ao modelo \eqref{eq:norm1} podem ser facilmente obtidas
como

\begin{eqnarray}
\partial \log \left[ f\left( \left. y_{i}\right| \mathbf{z}_{i};\mathbf{
\beta },\sigma _{e}\right) \right] /\partial \mathbf{\beta } &=&\mathbf{z}
_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\sigma _{e}
\label{eq:norm2} \\
&\propto &\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{
\beta }\right) =\mathbf{u}_{i}\left( \mathbf{\beta }\right)  \nonumber
\end{eqnarray}

e

\begin{eqnarray*}
\partial \log \left[ f\left( \left. y_{i}\right| \mathbf{z}_{i};\mathbf{
\beta },\sigma _{e}\right) \right] /\partial \sigma _{e} &=&\left[ \left(
y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) ^{2}-\sigma _{e}\right]
/2\sigma _{e}^{2}  \label{eq:norm3} \\
&\propto &\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right)
^{2}-\sigma _{e}=u_{i}\left( \sigma _{e}\right) \;.
\end{eqnarray*}

\subsection{Pseudo-parâmetros do
Modelo}\label{pseudo-parametros-do-modelo}

Se todos os elementos da população tivessem sido pesquisados, os EMVs de
\(\mathbf{\beta }\) e \(\sigma _{e}\) do censo, denotados por
\$\mathbf{B} \$ e \(S_{e}\) respectivamente, poderiam ser facilmente
obtidos como soluções das equações de verossimilhança do censo dadas por

\begin{equation}
\sum\limits_{i\in U}\mathbf{u}_{i}\left( \mathbf{B}\right)
=\sum\limits_{i\in U}\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }%
\mathbf{\beta }\right) =\mathbf{z}_{U}^{^{\prime }}\mathbf{y}_{U}-\left(
\mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}\right) \mathbf{B}=\mathbf{0}
\label{eq:norm4}
\end{equation}

e

\begin{equation}
\sum\limits_{i\in U}u_{i}\left( S_{e}\right) =\sum\limits_{i\in U}\left[
\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{B}\right) ^{2}-S_{e}\right]
=\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}\right) ^{^{\prime
}}\left( \mathbf{y}_{U}-\mathbf{zz}_{U}^{\prime }\mathbf{B}\right) -NS_{e}=0
\label{eq:norm5}
\end{equation}

onde
\(\mathbf{z}_{U}=\left( \mathbf{z}_{1},\ldots ,\mathbf{z}_{N}\right) ^{^{\prime }}\)
e \(\mathbf{y}_{U}=\left( y_{1},\ldots ,y_{N}\right) ^{^{\prime }}\).

Se \(\mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}\) for não-singular, as
soluções para estas equações são facilmente obtidas como

\begin{equation}
\mathbf{B}=\left( \mathbf{z}_{U}^{^{\prime }}\mathbf{z}_{U}\right) ^{-1}
\mathbf{z}_{U}^{^{\prime }}\mathbf{y}_{U}
\label{eq:norm6}
\end{equation}

e

\begin{equation}
S_{e}=N^{-1}\sum\limits_{i\in U}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{
B}\right) ^{2}=N^{-1}\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}
\right) ^{^{\prime }}\left( \mathbf{y}_{U}-\mathbf{z}_{U}^{\prime }\mathbf{B}
\right) \;.
\label{eq:norm7}
\end{equation}

Com uma parametrização que isole o termo correspondente ao intercepto
(primeira coluna do vetor \(\mathbf{z}_{i}\)) do modelo de regressão
\eqref{eq:norm1}, pode ser facilmente mostrado (Nascimento Silva, 1996,
p.~142) que os EMV de \(\mathbf{\beta }_{2}\) (igual a
\(\mathbf{\beta }\) excluído o primeiro componente), \(\beta _{1}\) e
\(\sigma _{e}\) são dados respectivamente por

\begin{equation}
\mathbf{B}_{2}=\mathbf{S}_{\mathbf{z}}^{-1}\mathbf{S}_{\mathbf{z}y}\;,
\label{eq:norm8}
\end{equation}

\begin{equation}
B_{1}=\bar{Y}-\mathbf{\bar{Z}}^{^{\prime }}\mathbf{B}_{2}\mathbf{\;,}
\label{eq:norm9}
\end{equation}

e

\begin{equation}
S_{e}=N^{-1}\sum\limits_{i\in U}\left( y_{i}-B_{1}-\mathbf{z}_{i}^{^{\prime
}}\mathbf{B}_{2}\right) ^{2}=N^{-1}\sum\limits_{i\in U}e_{i}^{2}\;,
\label{eq:norm10}
\end{equation}

onde \(\bar{Y}=N^{-1}\sum\limits_{i\in U}y_{i}\),
\(\mathbf{\bar{Z}}=N^{-1}\sum\limits_{i\in U}\mathbf{z}_{i}\) ,
\(\mathbf{S}_{\mathbf{z}}=N^{-1}\sum\limits_{i\in U}\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right)\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}\),
\(\mathbf{S}_{ \mathbf{z}y}=N^{-1}\sum\limits_{i\in U}\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) \left( y_{i}-\bar{Y}\right)\)
e
\(e_{i}=y_{i}-B_{1}-\mathbf{z}_{i}^{^{\prime }}\mathbf{B}_{2}=\left( y_{i}-\bar{Y}\right) -\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}\mathbf{B}_{2}\)
, sendo neste trecho os vetores de variáveis preditoras tomados sem o
termo constante referente ao intercepto.

Os EMVs do censo dados em \eqref{eq:norm1} a \eqref{eq:norm10} coincidem com
os estimadores de mínimos quadrados ordinários, sob as hipóteses mais
fracas do modelo dadas por \eqref{eq:norm11} a seguir (ver Nathan e Holt,
1980), onde se dispensou a hipótese de normalidade dos erros, isto é

\begin{eqnarray}
E_{M}\left( \left. Y_{i}\right| \mathbf{z}_{i}=\mathbf{z}_{i}\right)
&=&\beta _{1}+\mathbf{z}_{i}^{^{\prime }}\mathbf{\beta }_{2}  \label{eq:norm11} \\
V_{M}\left( \left. Y_{i}\right| \mathbf{z}_{i}=\mathbf{z}_{i}\right)
&=&\sigma _{e}  \nonumber \\
COV_{M}\left( \left. Y_{i},Y_{j}\right| \mathbf{z}_{i}=\mathbf{z}_{i},
\mathbf{z}_{j}=\mathbf{z}_{j}\right) &=&0\ \quad \forall i\neq j\in U.
\nonumber
\end{eqnarray}

\subsection{Estimadores de MPV dos Parâmetros do
Modelo}\label{estimadores-de-mpv-dos-parametros-do-modelo}

Quando apenas uma amostra de unidades da população é observada, são
usados pesos \(w_{i}\) para obter estimadores de máxima
pseudo-verossimilhança de \(\mathbf{\beta }\) e \(\sigma _{e}\), ou
alternativamente de \(\mathbf{B}\) e \(S_{e}\), se as quantidades
descritivas populacionais correspondentes forem escolhidas para alvo da
inferência. Se os pesos \(w_{i}\) satisfizerem às condições de
regularidade discutidas na Seção @ref\{modpar3\}, será imediato obter as
equações de pseudo-verossimilhança correspondentes ao modelo
\eqref{eq:norm1} como

\begin{eqnarray}
\sum\limits_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\hat{B}}_{w}\right)
&=&\sum\limits_{i\in s}w_{i}\mathbf{z}_{i}\left( y_{i}-\mathbf{z}
_{i}^{\prime }\mathbf{\hat{B}}_{w}\right)  \label{eq:norm12} \\
&=&\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}-\left( \mathbf{z}
_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y}_{s}\right) \mathbf{\hat{B}}_{w}=
\mathbf{0}  \nonumber
\end{eqnarray}

e

\begin{eqnarray}
\sum\limits_{i\in s}w_{i}u_{i}\left( s_{e}^{w}\right) &=&\sum\limits_{i\in
s}w_{i}\left[ \left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\hat{B}}
_{w}\right) ^{2}-s_{e}^{w}\right]  \label{eq:norm13} \\
&=&\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B}}_{w}\right)
^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\mathbf{\hat{B
}}_{w}\right) -\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) s_{e}^{w}=0  \nonumber
\end{eqnarray}

onde \(\mathbf{z}_{s}\) e \(\mathbf{y}_{s}\) são os análogos amostrais
de \(\mathbf{z}_{U}\) e \(\mathbf{y}_{U}\), respectivamente,
\$\mathbf{W}
\_\{s\}=diag\left[ \left( w_{i_{1}},\ldots ,w_{i_{n}}\right) \right] \$é
uma matriz diagonal \(n\times n\) com os pesos dos elementos da amostra
na diagonal principal, e \(\mathbf{\hat{B}}_{w}\) e \(s_{e}^{w}\) são
estimadores MPV de \(\mathbf{\beta }\) e \(\sigma _{e}\)
respectivamente.

Supondo que \(\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\)
é não-singular e resolvendo \eqref{eq:norm12} e \eqref{eq:norm13} em
\(\mathbf{\hat{B} }_{w}\) e \(s_{e}^{w}\) obtemos as seguintes
expressões para os estimadores MPV dos parâmetros do modelo:

\begin{equation}
\widehat{\mathbf{B}}_{w}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}
\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{y
}_{s}  \label{eq:norm14}
\end{equation}

e

\begin{eqnarray}
s_{e}^{w} &=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}
_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{w}\right) ^{^{\prime }}\mathbf{W}_{s}\left( \mathbf{y}_{s}-\mathbf{z}_{s}
\widehat{\mathbf{B}}_{w}\right)  \label{eq:norm15} \\
&=&\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{1}_{s}\right)
^{-1}\mathbf{y}_{s}^{^{\prime }}\left[ \mathbf{W}_{s}-\mathbf{W}_{s}\mathbf{z
}_{s}\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{W}_{s}\right] \mathbf{y}_{s}
\nonumber
\end{eqnarray}

sendo a segunda expressão para \(s_{e}^{w}\) obtida mediante
substituição do valor de \(\widehat{\mathbf{B}}_{w}\) em \eqref{eq:norm14}
na primeira linha de \eqref{eq:norm15}.

Observe que a hipótese de não-singularidade de
\(\mathbf{z} _{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\) não seria
satisfeita se \$ w\_\{i\}=0\$ para algum \(i\in s\). Para evitar que se
percam de vista as questões principais com relação à estimação dos
parâmetros do modelo, admitiremos de agora em diante que
\(\mathbf{z} _{s}^{^{\prime }}\mathbf{W}_{s}\mathbf{z}_{s}\) é
não-singular.

Estimadores pontuais dos parâmetros do modelo podem ser derivados a
partir de \eqref{eq:norm14} e \eqref{eq:norm15} para vários esquemas de
pondera\c{c
}ão de interesse pela simples substituição da matriz apropriada de
ponderação \(\mathbf{W}_{s}\). Se todos os elementos da pesquisa têm o
mesmo peso (como no caso de planos amostrais autoponderados), ou seja,
\(w_{i}=\bar{w}\) e \(\mathbf{W}_{s}=\bar{w}\mathbf{I}_{n}\), os
estimadores pontuais não dependem do valor \(\bar{w}\) dos pesos. Neste
caso, eles ficam reduzidos às expressões correspondentes dos estimadores
de mínimos quadrados ordinários (que são também estimadores de máxima
verossimilhança sob normalidade) dos parâmetros do modelo, dados por:

\begin{equation}
\widehat{\mathbf{B}}=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{z}_{s}\right)
^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{y}_{s}  \label{eq:norm16}
\end{equation}

e

\begin{equation}
s_{e}=n^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
^{^{\prime }}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}\right)
\;.  \label{eq:norm17}
\end{equation}

Substituindo \(\mathbf{W}_{s}\) em \eqref{eq:norm14} e \eqref{eq:norm15} por
\(diag\left( \pi _{i}:i\in s\right) =\mathbf{\Pi }_{s}^{-1}\), onde os
\(\pi _{i}\) em geral não são todos iguais, obtemos estimadores,
chamados de mínimos quadrados \(\pi -\)ponderados, dados por:

\begin{equation}
\widehat{\mathbf{B}}_{\pi }=\left( \mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\mathbf{z}_{s}^{^{\prime }}\mathbf{\Pi }
_{s}^{-1}\mathbf{y}_{s}  \label{eq:norm18}
\end{equation}

e

\begin{equation}
s_{e}^{\pi }=\left( \mathbf{1}_{s}^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\mathbf{
1}_{s}\right) ^{-1}\left( \mathbf{y}_{s}-\mathbf{z}_{s}\widehat{\mathbf{B}}
_{\pi }\right) ^{^{\prime }}\mathbf{\Pi }_{s}^{-1}\left( \mathbf{y}_{s}-
\mathbf{z}_{s}\widehat{\mathbf{B}}_{\pi }\right) \;.  \label{eq:norm19}
\end{equation}

\subsection{Estimação da Variância de Estimadores de
MPV}\label{estimacao-da-variancia-de-estimadores-de-mpv}

O exercício de ajustar um modelo não estará completo sem a avalia ção da
precisão e significância das estimativas dos parâmetros. Para isto é
necessária a estimação das variâncias correspondentes. Nesta seção
concentramos nossa atenção na estimação das variâncias dos estimadores
de MPV dos coeficientes de regressão \(\mathbf{\beta }\). As expressões
a seguir são obtidas por aplicação direta dos resultados gerais
fornecidos na Seção \ref{modpar3}, observando-se que os escores
correspondentes a \(\mathbf{\beta}\) no \texttt{ajuste\ do\ censo} do
modelo \eqref{eq:norm1} são dados por
\(\mathbf{u}_{i}\left( \mathbf{B}\right) =\mathbf{z}_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{B}\right) =\mathbf{z} _{i}e_{i}\)
, onde
\(e_{i}=\left( y_{i}-\bar{Y}\right) -\left( \mathbf{z}_{i}-\mathbf{\bar{Z}}\right) ^{^{\prime }}\mathbf{B}\)
para \(i\in U\), com o Jacobiano correspondente dado por

\begin{eqnarray}
J\left( \mathbf{B}\right) &=&\left. \sum\nolimits_{i\in U}\partial \mathbf{z}
_{i}\left( y_{i}-\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\partial
\mathbf{\beta }\right| _{\mathbf{\beta }=\mathbf{B}}  \label{eq:norm20} \\
&=&\left. \partial \left( \mathbf{z}_{U}^{\prime }\mathbf{y}_{U}-\mathbf{z}
_{U}^{\prime }\mathbf{z}_{U}\mathbf{\beta }\right) /\partial \mathbf{\beta }
\right| _{\mathbf{\beta }=\mathbf{B}}=-\mathbf{z}_{U}^{\prime }\mathbf{z}
_{U}\;\;.  \nonumber
\end{eqnarray}

Substituindo em \eqref{eq:norm8} e \eqref{eq:norm9} os valores dos escores,
do jacobiano e dos estimadores \$\pi \$-ponderados correspondentes,
obtemos as seguintes expressões para a variância assintótica de
aleatorização do estimador de MPV padrão \(\widehat{\mathbf{B}}_{\pi }\)
e seu estimador consistente, dadas por

\begin{equation}
V_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_{U}^{\prime }\mathbf{z}_{U}\right) ^{-1}V_{p}\left( \sum\limits_{i\in s}\pi
_{i}^{-1}\mathbf{z}_{i}e_{i}\right) \left( \mathbf{z}_{U}^{\prime }\mathbf{z}
_{U}\right) ^{-1}  \label{eq:norm21}
\end{equation}

e

\begin{equation}
\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right) =\left( \mathbf{z}
_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right) ^{-1}\hat{V}
_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}e_{i}\right)
\left( \mathbf{z}_{s}^{\prime }\mathbf{\Pi }_{s}^{-1}\mathbf{z}_{s}\right)
^{-1}\;,  \label{eq:norm22}
\end{equation}

onde

\begin{equation}
V_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}e_{i}\right)
=\sum\limits_{i\in U}\sum\limits_{j\in U}\frac{\pi _{ij}-\pi _{i}\pi _{j}}{
\pi _{i}\pi _{j}}e_{i}\mathbf{z}_{i}\mathbf{z}_{j}^{\prime }e_{j}\;\;,
\label{eq:norm23}
\end{equation}

\begin{equation}
\hat{V}_{p}\left( \sum\limits_{i\in s}\pi _{i}^{-1}\mathbf{z}_{i}\hat{e}
_{i}\right) =\sum\limits_{i\in s}\sum\limits_{j\in s}\left( \pi _{i}^{-1}\pi
_{j}^{-1}-\pi _{ij}^{-1}\right) \hat{e}_{i}\mathbf{z}_{i}\mathbf{z}
_{j}^{\prime }\hat{e}_{j}\;\;,  \label{eq:norm24}
\end{equation}

e
\(\hat{e}_{i}=y_{i}-\mathbf{z}_{i}^{\prime }\widehat{\mathbf{B}}_{\pi }\)
para \(i\in s\).

Isto completa a especificação de um procedimento de máxima
pseudo-verossimilhança para ajustar modelos normais de regressão como
\eqref{eq:norm1}. Este procedimento é bastante flexível e aplicável numa
ampla gama de planos amostrais.

\section{Modelo de Regressão Logística}\label{modlogist}

No modelo de regressão logística, a variável resposta \(y\) é binária,
isto é, assume os valores \(0\) e \(1\). Considerando um vetor
\(\mathbf{z}\) de variáveis explanatórias tal como o empregado no modelo
de regressão linear discutido na Seção \ref{modlinear}, o modelo de
superpopulação é dado por

\begin{equation}
f(y_{i}|\mathbf{z}_{i},\mathbf{\beta )=}\left[ p\left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) \right] ^{y_{i}}\left[ 1-p\left(
\mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) \right] ^{1-y_{i}},
\label{eq:norm25}
\end{equation}

onde,

\[
p\left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) =P\left( \left.
Y_{i}=1\right| \mathbf{Z}_{i}=\mathbf{z}_{i}\right) =\exp \left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) /\left[ 1+\exp \left( \mathbf{z}
_{i}^{\prime }\mathbf{\beta }\right) \right] \;.
\]

A função escore de \(\mathbf{\beta }\) é

\begin{equation}
\mathbf{u}_{i}\left( \mathbf{\beta }\right) =\partial \log (y_{i}|\mathbf{z}_{i},\mathbf{\beta )/\partial \beta =}\left[ y_{i}-p\left( \mathbf{z}
_{i}^{\prime }\mathbf{\beta }\right) \right] \mathbf{z}_{i}  \label{eq:norm25a}
\end{equation}

e portanto a equação de verossimilhança do censo correspondente é dada
por

\begin{equation}
\sum\nolimits_{i\in U}\mathbf{u}_{i}\left( \mathbf{\beta }\right)
=\sum\nolimits_{i\in U}\left[ y_{i}-p\left( \mathbf{z}_{i}^{\prime }\mathbf{
\beta }\right) \right] \mathbf{z}_{i}=\mathbf{0\;.}  \label{eq:norm26}
\end{equation}

O estimador de MPV do vetor de coeficientes \(\mathbf{\beta }\) no
modelo \eqref{eq:norm25} é a solução da equação

\begin{equation}
\sum\nolimits_{i\in s}w_{i}\mathbf{u}_{i}\left( \mathbf{\beta }\right)
=\sum\nolimits_{i\in s}w_{i}\left[ y_{i}-p\left( \mathbf{z}_{i}^{\prime }
\mathbf{\beta }\right) \right] \mathbf{z}_{i}=\mathbf{0},
\label{eq:norm27}
\end{equation}

onde \(w_{i}\) é o peso da \(i\)-ésima observação amostral.

A matriz de covariância do estimador de MPV de \(\mathbf{\beta }\) pode
ser obtida conforme indicado na Seção \ref{modpar3}, bastando substituir
os valores dos escores
\(\mathbf{u}_{i}\left( \mathbf{\beta } \right) =\left[ y_{i}-p\left( \mathbf{z}_{i}^{\prime }\mathbf{\beta }\right) \right] \mathbf{z}_{i}\)
e do jacobiano correspondentes. Para maiores detalhes, o leitor
interessado pode consultar Binder(1983), que aborda o problema da
estimação da matriz de covariância dos estimadores de MPV na família de
modelos lineares generalizados, da qual o modelo de regressão logística
é caso particular.

Vale observar que, tal como no caso da modelagem clássica, a obtenção
dos estimadores de MPV dos parâmetros no modelo de regressão logística
depende da solução por métodos numéricos de um sistema de equações.
Portanto é importante dispor de um pacote computacional adequado para
efetuar os cálculos. Hoje em dia já estão disponíveis vários pacotes com
essa funcionalidade, conforme se discute no Capítulo 10.

\BeginKnitrBlock{example}
\protect\hypertarget{ex:pnad}{}{\label{ex:pnad}}Análise do perfil
sócio-econômico das pessoas ocupadas no setor informal da economia na
área urbana do Rio de Janeiro
\EndKnitrBlock{example}

Utilizando dados do Suplemento Trabalho da Pesquisa Nacional por
Amos-tra de Domicílios (\textbf{PNAD}) de 90, Leote(1996) analisou o
perfil sócio-econômico das pessoas ocupadas no setor informal da
economia na área urbana do Rio de Janeiro.

Os dados utilizados são relativos a pessoas que:

\begin{itemize}
\item
  moravam em domicílios urbanos do estado do Rio de Janeiro;
\item
  trabalhavam em atividades mercantis (não foram incluídos trabalhadores
  domésticos);
\item
  na semana da pesquisa estavam trabalhando ou não estavam trabalhando
  por estarem de férias, licença, etc., mas tinham trabalho;
\item
  desenvolviam atividades não agrícolas.
\end{itemize}

As pessoas que trabalhavam em locais com até cinco pessoas ocupadas
foram classificadas no setor informal, independente da posição de
ocupação delas, enquanto as que trabalhavam em locais com mais de cinco
pessoas ocupadas foram classificadas no setor formal. O trabalho
refere-se ao trabalho principal. Para a variável renda considerou-se a
soma dos rendimentos de todos os trabalhos.

Foi considerada uma amostra de \(6.507\) pessoas (após a exclusão de
\(9\) registros considerados atípicos), classificadas de acordo com as
variáveis descritas na Tabela \ref{tab61}, todas tratadas como fatores
na análise. A variável ht foi considerada como a soma de horas
trabalhadas em todos os trabalhos, por semana. A variável re compreende
a renda média mensal de todos os trabalhos, em salários mínimos.

\begin{center}
%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Descrição das variáveis explicativas }\bigskip \label{tab61}
\begin{tabular}{|c|c|c|}
\hline\hline
\textbf{Fatores} & \textbf{Níveis} & \textbf{Descrição dos
níveis} \\ \hline\hline
Sexo (sx) & sx(1) & Homens \\
& sx(2) & Mulheres \\ \hline
Anos de estudo (ae) & ae(1) & Até 4 \\
& ae(2) & De 5 a 8 \\
& ae(3) & 9 ou mais \\ \hline
Horas trabalhadas (ht) & ht(1) & Menos de 40 \\
& ht(2) & De 40 a 48 \\
& ht(3) & Mais de 48 \\ \hline
Idade em anos completos (id) & id(1) & Até 17 \\
& id(2) & De 18 a 25 \\
& id(3) & De 26 a 49 \\
& id(4) & 50 ou mais \\ \hline
Rendimento médio mensal (re) & re(1) & Menos de 1 \\
& re(2) & De 1 a 5 \\
& re(3) & Mais de 5 \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion
\end{center}

\begin{longtable}[]{@{}cll@{}}
\toprule
\begin{minipage}[b]{0.48\columnwidth}\centering\strut
Fatores\strut
\end{minipage} & \begin{minipage}[b]{0.20\columnwidth}\raggedright\strut
Níveis D\strut
\end{minipage} & \begin{minipage}[b]{0.21\columnwidth}\raggedright\strut
escrição dos níveis\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.48\columnwidth}\centering\strut
Sexo(sx)\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright\strut
sx(1) sx(2)\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright\strut
Homens Mulheres\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\centering\strut
Anos de estudo(ht)\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright\strut
ae(1) ae(3)\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright\strut
Até 4 ae(2) De 5 a 8 9 ou mais\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\centering\strut
Horas trabalhadas(ht)\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright\strut
ht(1) ht(2) ht(3)\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright\strut
Menos de 40 De 40 a 48 Mais de 48\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\centering\strut
Idade e anos completos(id)\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright\strut
id(1) id(3) id(4)\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright\strut
Até 17 id(2) De 18 a 25 De 26 a 49 50 ou mais\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.48\columnwidth}\centering\strut
Rendimento médio mensal(re)\strut
\end{minipage} & \begin{minipage}[t]{0.20\columnwidth}\raggedright\strut
re(1) re(2) re(3)\strut
\end{minipage} & \begin{minipage}[t]{0.21\columnwidth}\raggedright\strut
Menos de 1 De 1 a 5 Mais de 5\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Os fatores considerados foram tomados como explicativos e a variável
resposta foi o indicador de pertinência ao setor informal da economia.
Foi ajus-tado um modelo logís-tico (Agresti, 1990) para explicar a
probabilidade de uma pessoa pertencer ao setor informal da economia.

Para a seleção do modelo foi usada a função \texttt{glm} do
\textbf{S-Plus}, aplicada aos dados tabelados. O modelo final
selecionado foi escolhido passo a passo, incluindo em cada passo as
interações que produziam maior decréscimo do desvio residual,
considerando a perda de graus de liberdade. O modelo selecionado foi

\begin{eqnarray}
\log \left( \frac{p_{ijklm}}{1-p_{ijklm}}\right) &=&\mu +\beta
_{i}^{sx}+\beta _{j}^{ae}+\beta _{k}^{ht}+\beta _{l}^{id}+\beta _{m}^{re}
\label{eq:norm28} \\
&&+\beta _{ij}^{sx.id}+\beta _{ik}^{sx.ht}+\beta _{jk}^{ae.ht}+\beta
_{kl}^{ht.id}+\beta _{km}^{ht.re},  \nonumber
\end{eqnarray}

onde \(p_{ijklm}\) é a probabilidade de pertencer ao setor informal
correspondente à combinação de níveis das variáveis explicativas, sendo
i=1, 2 o nível de sx; j=1, 2, 3 o nível de ae; k=1, 2, 3 o nível de ht;
l=1, 2, 3, 4 o nível de id e m=1, 2, 3 o nível de re.

Os efeitos foram adicionados sequencialmente na ordem da Tabela \ref
{tab61}. Depois de introduzidos os efeitos principais, as interações de
dois fatores foram introduzidas na ordem definida pela
\texttt{função\ step\ do\ S-Plus}.

O \(p\)valor do teste de nulidade das interações não incluídas no modelo
é 0,0515, aceitando-se a hipótese de nulidade destes efeitos ao nível
\(\alpha =0,05\). O modelo obtido difere do selecionado em Leote(1996)
só pela inclusão de mais um efeito, referente à interação ae:ht.

Uma descrição detalhada do plano amostral da PNAD 90 foi apresentada no
Exemplo \ref{ex:pnad}. Como se pode observar dessa descrição, o plano
amostral da PNAD apresenta todos os aspectos de um plano amostral
complexo, incluindo estratificação (geográfica), seleção de unidades
primárias (municípios, ou setores nos municípios auto-representativos)
ou secundárias (setores nos municípios não auto-representativos) com
probabilidades desiguais, conglomeração (de domicílios em setores, e de
pessoas nos domicílios) e seleção sistemática sem reposição de unidades.
Nesse caso, fica difícil admitir a priori com confiança as hipóteses
usuais de modelagem das observações amostrais como IID. Por esse motivo
foram considerados métodos alternativos de modelagem e ajuste.

Apresentamos a seguir as estimativas dos efeitos principais e interações
do modelo selecionado e seus respectivos desvios padrões, calculadas
pela \textbf{PROC LOGISTIC} do pacote \textbf{SUDAAN}. Para facilitar a
comparação incluímos na Tabela \ref{tab62} os valores correspondentes
estimados pelo \textbf{S-Plus}.

As estimativas calculadas pelo pacote \textbf{SUDAAN} são feitas pelo
\texttt{Método\ de\ Máxima\ Pseudo-Verossimilhança}, resolvendo a
equação \eqref{eq:norm27}. As estimativas dos desvios padrões são obtidas
das variâncias calculadas pelo método de linearização descrito na Seção
\ref{modpar3}, equação (\ref{5.9}), considerando os escores tal como
apresentados na equação \eqref{eq:norm25a}. Para esses cálculos, os
estimadores de variância considerados levaram em conta os pesos das
observações, mas utilizaram uma aproximação que consiste em considerar
que as unidades primárias de amostragem foram selecionadas com
reposição, especificando a opção WR do pacote SUDAAN. Veja
\citep{SUDAAN92}, p.~4) e \citep{W85}, eq. 7.7.2.

\begin{center}
%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Estimativas dos efeitos e dos respectivos desvios padrões obtidas
pelo {\bf SUDAAN} e pelo {\bf S-Plus} }\bigskip \label{tab62}
\begin{tabular}{|c|cc|cc|}
\hline\hline
Variáveis & \multicolumn{2}{|r}{Ajuste no \textbf{SUDAAN}} &
\multicolumn{2}{|r|}{Ajuste no \textbf{S-Plus}} \\ \cline{2-5}
independentes & Estimativa & Desvio & Estimativa & Desvio \\
e efeitos & do efeito & Padrão & do efeito & Padrão \\ \hline\hline
Intercepto & \multicolumn{1}{|r}{$-0,515$} & \multicolumn{1}{r|}{$0,260$} &
\multicolumn{1}{|r}{$-0,514$} & \multicolumn{1}{r|}{$0,269$} \\
sx & \multicolumn{1}{|r}{$0,148$} & \multicolumn{1}{r|}{$0,222$} &
\multicolumn{1}{|r}{$0,156$} & \multicolumn{1}{r|}{$0,228$} \\
ae1 & \multicolumn{1}{|r}{$0,745$} & \multicolumn{1}{r|}{$0,165$} &
\multicolumn{1}{|r}{$0,740$} & \multicolumn{1}{r|}{$0,165$} \\
ae2 & \multicolumn{1}{|r}{$0,496$} & \multicolumn{1}{r|}{$0,156$} &
\multicolumn{1}{|r}{$0,497$} & \multicolumn{1}{r|}{$0,159$} \\
ht1 & \multicolumn{1}{|r}{$-0,377$} & \multicolumn{1}{r|}{$0,317$} &
\multicolumn{1}{|r}{$-0,386$} & \multicolumn{1}{r|}{$0,312$} \\
ht2 & \multicolumn{1}{|r}{$-0,697$} & \multicolumn{1}{r|}{$0,275$} &
\multicolumn{1}{|r}{$-0,698$} & \multicolumn{1}{r|}{$0,268$} \\
id1 & \multicolumn{1}{|r}{$-0,239$} & \multicolumn{1}{r|}{$0,540$} &
\multicolumn{1}{|r}{$-0,243$} & \multicolumn{1}{r|}{$0,492$} \\
id2 & \multicolumn{1}{|r}{$-0,729$} & \multicolumn{1}{r|}{$0,302$} &
\multicolumn{1}{|r}{$-0,724$} & \multicolumn{1}{r|}{$0,314$} \\
id3 & \multicolumn{1}{|r}{$0,227$} & \multicolumn{1}{r|}{$0,231$} &
\multicolumn{1}{|r}{$0,227$} & \multicolumn{1}{r|}{$0,234$} \\
re1 & \multicolumn{1}{|r}{$0,286$} & \multicolumn{1}{r|}{$0,277$} &
\multicolumn{1}{|r}{$0,293$} & \multicolumn{1}{r|}{$0,245$} \\
re2 & \multicolumn{1}{|r}{$0,065$} & \multicolumn{1}{r|}{$0,144$} &
\multicolumn{1}{|r}{$0,062$} & \multicolumn{1}{r|}{$0,145$} \\
ht1.re1 & \multicolumn{1}{|r}{$1,529$} & \multicolumn{1}{r|}{$0,356$} &
\multicolumn{1}{|r}{$1,531$} & \multicolumn{1}{r|}{$0,332$} \\
ht2.re1 & \multicolumn{1}{|r}{$0,338$} & \multicolumn{1}{r|}{$0,320$} &
\multicolumn{1}{|r}{$0,336$} & \multicolumn{1}{r|}{$0,284$} \\
ht1.re2 & \multicolumn{1}{|r}{$0,490$} & \multicolumn{1}{r|}{$0,233$} &
\multicolumn{1}{|r}{$0,498$} & \multicolumn{1}{r|}{$0,221$} \\
ht2.re2 & \multicolumn{1}{|r}{$-0,115$} & \multicolumn{1}{r|}{$0,183$} &
\multicolumn{1}{|r}{$-0,112$} & \multicolumn{1}{r|}{$0,178$} \\
ht1.id1 & \multicolumn{1}{|r}{$-1,420$} & \multicolumn{1}{r|}{$0,605$} &
\multicolumn{1}{|r}{$-1,408$} & \multicolumn{1}{r|}{$0,515$} \\
ht2.id1 & \multicolumn{1}{|r}{$-0,413$} & \multicolumn{1}{r|}{$0,506$} &
\multicolumn{1}{|r}{$-0,397$} & \multicolumn{1}{r|}{$0,465$} \\
ht1.id2 & \multicolumn{1}{|r}{$-0,124$} & \multicolumn{1}{r|}{$0,354$} &
\multicolumn{1}{|r}{$-0,129$} & \multicolumn{1}{r|}{$0,351$} \\
ht2.id2 & \multicolumn{1}{|r}{$-0,109$} & \multicolumn{1}{r|}{$0,279$} &
\multicolumn{1}{|r}{$-0,106$} & \multicolumn{1}{r|}{$0,286$} \\
ht1.id3 & \multicolumn{1}{|r}{$-0,220$} & \multicolumn{1}{r|}{$0,248$} &
\multicolumn{1}{|r}{$-0,216$} & \multicolumn{1}{r|}{$0,253$} \\
ht2.id3 & \multicolumn{1}{|r}{$-0,537$} & \multicolumn{1}{r|}{$0,205$} &
\multicolumn{1}{|r}{$-0,533$} & \multicolumn{1}{r|}{$0,201$} \\
sx.id1 & \multicolumn{1}{|r}{$0,878$} & \multicolumn{1}{r|}{$0,348$} &
\multicolumn{1}{|r}{$0,870$} & \multicolumn{1}{r|}{$0,335$} \\
sx.id2 & \multicolumn{1}{|r}{$0,300$} & \multicolumn{1}{r|}{$0,231$} &
\multicolumn{1}{|r}{$0,294$} & \multicolumn{1}{r|}{$0,226$} \\
sx.id3 & \multicolumn{1}{|r}{$-0,259$} & \multicolumn{1}{r|}{$0,190$} &
\multicolumn{1}{|r}{$-0,263$} & \multicolumn{1}{r|}{$0,186$} \\
sx.ht1 & \multicolumn{1}{|r}{$-0,736$} & \multicolumn{1}{r|}{$0,206$} &
\multicolumn{1}{|r}{$-0,737$} & \multicolumn{1}{r|}{$0,211$} \\
sx.ht2 & \multicolumn{1}{|r}{$-0,089$} & \multicolumn{1}{r|}{$0,185$} &
\multicolumn{1}{|r}{$-0,093$} & \multicolumn{1}{r|}{$0,182$} \\
ae1.ht1 & \multicolumn{1}{|r}{$0,792$} & \multicolumn{1}{r|}{$0,240$} &
\multicolumn{1}{|r}{$0,792$} & \multicolumn{1}{r|}{$0,239$} \\
ae2.ht1 & \multicolumn{1}{|r}{$0,739$} & \multicolumn{1}{r|}{$0,227$} &
\multicolumn{1}{|r}{$0,735$} & \multicolumn{1}{r|}{$0,226$} \\
ae1.ht2 & \multicolumn{1}{|r}{$0,026$} & \multicolumn{1}{r|}{$0,197$} &
\multicolumn{1}{|r}{$0,029$} & \multicolumn{1}{r|}{$0,196$} \\
ae2.ht2 & \multicolumn{1}{|r}{$0,089$} & \multicolumn{1}{r|}{$0,183$} &
\multicolumn{1}{|r}{$0,087$} & \multicolumn{1}{r|}{$0,189$} \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion
\end{center}

Na Tabela \ref{tab63} são apresentadas as probabilidades de
significância dos tes-tes de nulidade dos efeitos do modelo. Todos os
efeitos incluídos no modelo são significativos, nos níveis usuais de
significância. A \textbf{PROC LOGISTIC} do pacote \textbf{
SUDAAN} não inclui testes para os efeitos principais, por não ser
possível separar tais efeitos das interações. A coluna de \(p\) valores
da Tabela \ref{tab63}, obtida pela PROC LOGISTIC do pacote SUDAAN,
utiliza a estatística de Wald baseada no plano amostral com correção.
Mais detalhes são encontrados em Shah et al.(1993).

Os testes da Tabela \ref{tab63} indicam a significância de todas as
interações de 2 fatores que entraram no modelo selecionado. O teste de
qualidade global de ajuste, na primeira linha da\textbf{\ }Tabela \ref
{tab63}, indica a necessidade de serem introduzidas novas interações.

\begin{center}
%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Testes de hipóteses de nulidade dos efeitos do modelo}\bigskip
\label{tab63}
\begin{tabular}{|c|c|c|c|c|}
\hline\hline
&  & Graus de &  & $p$valor da \\
Contraste & Graus de & liberdade & Estatística F & estatística F \\
& liberdade & ajustados & ajustada & ajustada \\ \hline\hline
Modelo Global & $30$ & $26,132$ & $37,510$ & $0,000$ \\
Bondade do ajuste & $29$ & $25,692$ & $28,179$ & $0,000$ \\
ht:re & $4$ & $3,946$ & $6,040$ & $0,000$ \\
ht:id & $6$ & $5,764$ & $4,110$ & $0,001$ \\
sx:id & $3$ & $2,969$ & $7,168$ & $0,000$ \\
sx:ht & $2$ & $1,993$ & $9,166$ & $0,000$ \\
ae$:$ht & $4$ & $3,959$ & $4,814$ & $0,001$ \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion
\end{center}

Para comparação, apresentamos na Tabela \ref{tab64} algumas estimativas
de razões de vantagens, relevantes na análise, calculadas tanto pela
função glm do \textbf{S-Plus} como pela \textbf{PROC LOGISTIC} do pacote
\textbf{SUDAAN} e, na\textbf{\ }Tabela \ref
{tab65}\textbf{,} os correspondentes intervalos de confiança de
\(95\%\). Na construção destes intervalos foi necessário utilizar
estimativas pontuais dos efeitos bem como a matriz de covariância
estimada dos estimadores dos efeitos do modelo. Deste modo, estes
intervalos sumarizam, ao mesmo tempo, discrepâncias existentes tanto nas
estimativas pontuais dos efeitos como nas variâncias e covariâncias das
estimativas.

\begin{center}
%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Estimativas das razões de vantagens, variando-se os níveis de ae
para níveis fixos de ht }\bigskip \label{tab64}
\begin{tabular}{|c|c|c|c|}
\hline\hline
ht & Mudança de & \textbf{S-Plus} & \textbf{SUDAAN} \\
& nível de ae & \hspace{1cm}\quad \hspace{1cm} &  \\ \hline\hline
1 & 1 para 2 & $0,741$ & $0,739$ \\
1 & 2 para 3 & $0,291$ & $0,291$ \\ \hline
2 & 1 para 2 & $0,831$ & $0,830$ \\
2 & 2 para 3 & $0,558$ & $0,557$ \\ \hline
3 & 1 para 2 & $0,785$ & $0,780$ \\
3 & 2 para 3 & $0,608$ & $0,608$ \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion

%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Intervalos de confiança de $95\%$ para razões de vantagens,
variando-se os níveis de ae para níveis fixos de ht}\bigskip \label{tab65}
\begin{tabular}{|c|c|c|c|}
\hline\hline
ht & Mudança de & \textbf{S-Plus} & \textbf{SUDAAN} \\
& nível de ae & \hspace{1cm}\quad \hspace{1cm} &  \\ \hline\hline
1 & 1 para 2 & $(0,530;1,036).$ & $(0,516;1,059)$ \\
1 & 2 para 3 & $(0,213;0,399)$ & $(0,212;0,398)$ \\ \hline
2 & 1 para 2 & $(0,697;0,991)$ & $(0,693;0,994)$ \\
2 & 2 para 3 & $(0,457;0,680)$ & $(0,452;0,687)$ \\ \hline
3 & 1 para 2 & $(0,586;1,050)$ & $(0,577;1,053)$ \\
3 & 2 para 3 & $(0,445;0,831)$ & $(0,448;0,827)$ \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion
\end{center}

Além dos ajustes aqui comparados, foram feitos (embora não apresentados)
os seguintes ajustes com a utilização do \textbf{S-Plus%
}: 1) dados individuais (resposta 0-1) considerando os pesos; 2) dados
da tabela estimada considerando os pesos e 3) dados individuais com
pesos normalizados. Em todas estas análises, como esperado, as
estimativas pontuais dos efeitos coincidiram com as obtidas pela
\textbf{PROC LOGISTIC} do pacote \textbf{SUDAAN}. Pode-se notar que,
neste exemplo, há estreita concordância entre as estimativas pontuais
obtidas pelos dois pacotes.

A concordância das estimativas dos coeficientes pode ser explicada, em
parte, pela pequena variabilidade dos pesos das unidades, tal como se
pode verificar na Tabela \ref{tab66}, que apresenta a distribuição de
freq"\{u\}ências dos pesos.

\begin{center}
%TCIMACRO{\TeXButton{B}{\begin{table}[tbp] \centering}}
%BeginExpansion
\begin{table}[tbp] \centering%
%EndExpansion
\caption{Distribuição de freqüências dos pesos da amostra da PNAD-90 - Parte
Urbana do Rio de Janeiro}\bigskip \label{tab66}
\begin{tabular}{|c|c|}
\hline\hline
Valor do peso & Freq\"{u}ência \\ \hline\hline
$674$ & $127$ \\
$675$ & $784$ \\
$711$ & $3288$ \\
$712$ & $712$ \\ \hline\hline
\end{tabular}
%TCIMACRO{\TeXButton{E}{\end{table}}}
%BeginExpansion
\end{table}%
%EndExpansion
\end{center}

Como foi visto na Tabela \ref{tab62}, o impacto do plano amostral nas
estimativas de precisão é um pouco maior. As maiores diferenças entre os
dois métodos ocorrem na estimação dos desvios das estimativas dos
parâmetros do primeiro nível de idade (até 17 anos) e da interação deste
com horas trabalhadas (tanto no nível de menos de 40 horas semanais como
no nível de 40 a 48 horas semanais trabalhadas). Esta diferenciação
maior no caso dos desvios padrões já era esperada. Quando não levamos em
conta os pesos nem o plano amostral na estimação dos parâmetros, podemos
até chegar em uma estimativa pontual dos coeficientes bem próxima de
quando levamos ambos em conta, mas as estimativas dos desvios padrões
são mais sensíveis a esta diferença entre as análises. A tendência
revelada é de subestimação dos desvios padrões pelo \textbf{S-Plus} ao
ignorar o plano amostral e a variação dos pesos.

Neste exemplo, foi utilizada a função glm do \textbf{S-Plus} na seleção
do modelo. Feita a seleção, o mesmo modelo foi ajustado através da
\textbf{PROC LOGISTIC} do \textbf{SUDAAN}. O propósito foi imitar uma
situação onde o modelo já tivesse sido selecionado e ajustado por
usuário secundário dos dados, sem considerar os pesos e o plano
amostral, tal como é usual. Outra possibilidade seria repetir o processo
de seleção do modelo usando-se a \textbf{PROC LOGISTIC} do
\textbf{SUDAAN}. Isto poderia ser feito passo a passo, incluindo efeitos
e interações que melhorassem mais a qualidade de ajuste, tal como foi
feito automaticamente pela função \textbf{step do S-Plus}. Este
procedimento possibilitaria comparar a seleção de modelos quando são
considerados os pesos e o plano amostral na análise.

Diferentemente dos pacotes mais usados de análise estatística, tais como
SAS, S-Plus, BMDP, etc., o SUDAAN não possui, atualmente, ferramentas
usuais de diagnóstico de ajuste de modelos, como gráficos de resíduos
padronizados, etc., tornando mais difícil seu uso na etapa de seleção de
modelos. Considerando-se a maior dificuldade de seleção de modelos
através do \textbf{SUDAAN}, preferiu-se usá-lo aqui apenas para ajustar
um modelo já selecionado.

\section{Teste de Hipóteses}\label{teste-de-hipoteses}

Nas secões 6.1 e 6.2 discutimos formas de introduzir pesos e plano
amostral em procedimentos de estimação pontual e de variâncias ao
ajustar modelos com dados de pesquisas amostrais complexas. Neste
contexto, procedimentos estatísticos de teste de hipóteses devem,
também, sofrer adaptações. Nesta seção, esse problema será abordado de
forma sucinta, para modelos de regressão.

De modo geral, testes de hipóteses em regressão surgem inicialmente na
seleção de modelos e também para fornecer evidência favorável ou
contrária a indagações levantadas pelo pesquisador.

Denotemos por
\(\mathbf{\beta }=\left( \beta _{1},\ldots ,\beta _{P}\right) ^{\prime }\)
o vetor de parâmetros num modelo de regressão. Como é sabido, para
testar a hipótese \(H_{0}:\beta _{j}=0\), para algum
\(j\in \left\{ 1,\ldots ,P\right\} \mathbf{,}\) usamos um teste \(t,\) e
para para testar a hipótese
\(H_{0}:\left( \beta _{j_{1}},\ldots ,\beta _{j_{R}}\right) ^{\prime }=\mathbf{0}_{R}\),
onde
\(\left( j_{1},\ldots ,j_{R}\right) \subset \left( 1,\ldots ,P\right)\)
e \(\mathbf{0}_{R}\) é o vetor zero \(R\)-dimensional, usamos um teste
\(\mathbf{F}\). Tais testes \(t\) e \(\mathbf{F}\), sob as hipóteses do
modelo clássico de regressão com erros normais, são testes da Razão de
Máxima Verossimilhança.

é pois natural tentar adaptar testes de Razão de Máxima Verossimilhança
para pesquisas amostrais complexas, tal como foi feito na derivação de
estimadores de MPV a partir de estimadores de Máxima Verossimilhança. A
principal dificuldade é que no contexto de pesquisas complexas, devido
aos pesos distintos das observações e ao plano amostral utilizado, a
função de verossimilhança usual não representa a distribuição conjunta
das observações. Apesar desta dificuldade ter sido contornada na
derivação de estimadores de MPV, a adaptação fica bem mais difícil no
caso de testes da Razão de Máxima Verossimilhança.

Por essa causa, é mais fácil basear os testes na estatística Wald, que
mede a distância entre uma estimativa pontual e o valor hipotético do
parâmetro numa métrica definida pela matriz de covariância do estimador.
Pesos e plano amostral podem ser incorporados facilmente nessa
estatística, bastando para isto utilizar estimativas apropriadas
(consistentes sob aleatorização) dos parâmetros e da matriz de
covariância, tais como as que são geradas pelo método de MPV. é essa
abordagem que vamos adotar aqui.

Considere o problema de testar a hipótese linear geral

\begin{equation}
H_{0}:\mathbf{C\beta }=\mathbf{c},  \label{eq:norm30}
\end{equation}

onde \(\mathbf{C}\) é uma matriz de dimensão \(R\times P\) de posto
pleno \(R=P-Q\) e \(\mathbf{c}\) é um vetor \(R\) \(\times 1.\)

Um caso particular de interesse é testar a hipótese aninhada
\(H_{0}:\mathbf{\beta }_{2}=\mathbf{0}_{R}\mathbf{,}\) onde
\(\mathbf{\beta }^{\prime}=\left( \mathbf{\beta }_{1}^{\prime },\mathbf{\beta }_{2}^{\prime }\right)\)
, com \(\mathbf{\beta }_{1}\) de dimensão \(Q\times 1\) e
\(\mathbf{\beta}_{2}\) de dimensão \(R\times 1,\) \$\mathbf{C}=\left{[}

\begin{array}{lll}
\mathbf{0}_{R\times Q} &  & \mathbf{I}_{R}
\end{array}

\right{]} \$ e \(c=\mathbf{0}_{R}\) , sendo \(\mathbf{0}_{R\times Q}\)
matriz de zeros de dimensão \(R\times Q\) e \(\mathbf{I}_{R}\) a matriz
identidade de ordem \(R\).

A estatística de Wald clássica para testar a hipótese nula
\eqref{eq:norm30} é definida por

\begin{equation}
X_{W}^{2}=\left( \mathbf{C}\widehat{\mathbf{\beta }}-\mathbf{c}\right)
^{\prime }\left( \mathbf{C}\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}
\right) \mathbf{C}^{\prime }\right) ^{-1}\left( \mathbf{C}\widehat{\mathbf{
\beta }}\mathbf{-c}\right),  \label{eq:norm31}
\end{equation}

onde os estimadores \(\widehat{\mathbf{\beta }}\) e
\(\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)\) são obtidos
pela teoria de mínimos quadrados ordinários. Sob \(H_{0}\), a
distribuição assintótica da estatística \(X_{W}^{2}\) é
\(\chi ^{2}\left(R\right)\).

Quando os dados são obtidos através de pesquisas amostrais complexas, a
estatística \(X_{W}^{2}\) deixa de ter distribuição assintótica
\(\chi ^{2}\left( R\right)\), e usar esta '\{u\}ltima como distribuição
de referência implica na obtenção de testes com níveis de significância
incorretos. Esse problema é solucionado substituindo-se na expressão de
\(X_{W}^{2}\), \(\mathbf{\hat{\beta}}\) pela estimativa MPV
\(\widehat{\mathbf{B}}_{\pi }\) de \(\mathbf{\beta}\) dada em
\eqref{eq:norm18}, e
\(\widehat{\mathbf{V}}\left( \mathbf{\hat{\beta}}\right)\)pela
estimativa da matriz de covariância do estimador de MPV
\(\hat{V}_{p}\left( \widehat{\mathbf{B}}_{\pi }\right)\) dada em
\eqref{eq:norm22}. Tais estimativas consideram os pesos diferentes das
observações e o plano amostral efetivamente utilizado. A normalidade
assintótica do estimador de MPV de \(\mathbf{\beta}\) e a consistência
do estimador da matriz de covariância correspondente (Binder, 1983)
implicam que \[
X_{W}^{2}\sim \chi^{2}\left( R\right)\mbox{, sob }H_{0}.
\]

Esta aproximação não leva em conta o erro amostral na estimação de
\(\mathbf{V}\left( \mathbf{\hat{\beta}}\right) .\) Uma alternativa é
usar a aproximação \[
X_{W}^{2}/R\sim \mathbf{F}(R,\upsilon),
\] onde \(\upsilon =\) \(m-H\) é o número de UPAs da amostra menos o
n'\{u\}mero de estratos considerados no plano amostral para seleção das
UPAs, que fornece uma medida de graus de liberdade apropriada para
amostras complexas quando o método do conglomerado primário é empregado
para estimar variâncias.

Com a finalidade de melhorar a aproximação da distribuição da
estatística de teste, podem ser utilizados ajustes e correções da
estatística \(X_{W}^{2}\), que são apresentados com mais detalhes nos
Capítulos 7 e 8 para o caso da análise de dados categóricos.

A especificação de um procedimento para testar hipóteses sobre os
parâmetros de um modelo de regressão completa a abordagem para ajuste de
modelos desse tipo partindo de dados amostrais complexos. Entretanto,
uma das partes importantes da teoria clássica para modelagem é a que
trata do diagnóstico dos modelos ajustados, muitas vezes empregando
recursos gráficos. Nessa parte a abordagem baseada em MPV e em
estatísticas de Wald deixa a desejar, pois não é possível adaptar de
maneira simples as técnicas clássicas de diagnóstico. Por exemplo, é
difícil considerar pesos ao plotar os resíduos do ajuste dum modelo via
MPV. Essa é questão que ainda merece maior investigação e por enquanto é
uma desvantagem da abordagem aqui preconizada.

\section{Laboratório de R}\label{laboratorio-de-r}

Usar exemplo da amolim ou conseguir exemplo melhor? Reproduzir usando a
survey os resultados do Exemplo 6.1???

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(survey)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: grid
\end{verbatim}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## Loading required package: survival
\end{verbatim}

\begin{verbatim}
##
## Attaching package: 'survey'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:graphics':
##
##     dotchart
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{source}\NormalTok{(}\StringTok{"~}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{GitHub}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{adac}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{data}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pnadrj90.R"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(pnadrj90)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "stra"     "psu"      "pesopes"  "informal" "sx"       "id"
##  [7] "ae"       "ht"       "re"       "um"
\end{verbatim}

Preparação dos dados: Variáveis explicativas são fatores. Ver tipo de
variável:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{unlist}\NormalTok{(}\KeywordTok{lapply}\NormalTok{(pnadrj90, mode))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      stra       psu   pesopes  informal        sx        id        ae
## "numeric" "numeric" "numeric" "numeric" "numeric" "numeric" "numeric"
##        ht        re        um
## "numeric" "numeric" "numeric"
\end{verbatim}

Transformar variáveis para fatores e mudar o nível básico do fator
(último)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pnadrj90$sx<-}\KeywordTok{as.factor}\NormalTok{(pnadrj90$sx)}
\NormalTok{pnadrj90$sx<-}\KeywordTok{relevel}\NormalTok{(pnadrj90$sx,}\DataTypeTok{ref=}\StringTok{"2"}\NormalTok{)}
\NormalTok{pnadrj90$id<-}\KeywordTok{as.factor}\NormalTok{(pnadrj90$id)}
\NormalTok{pnadrj90$id<-}\KeywordTok{relevel}\NormalTok{(pnadrj90$id,}\DataTypeTok{ref=}\StringTok{"4"}\NormalTok{)}
\NormalTok{pnadrj90$ae<-}\KeywordTok{as.factor}\NormalTok{(pnadrj90$ae)}
\NormalTok{pnadrj90$ae<-}\KeywordTok{relevel}\NormalTok{(pnadrj90$ae,}\DataTypeTok{ref=}\StringTok{"3"}\NormalTok{)}
\NormalTok{pnadrj90$ht<-}\KeywordTok{as.factor}\NormalTok{(pnadrj90$ht)}
\NormalTok{pnadrj90$ht<-}\KeywordTok{relevel}\NormalTok{(pnadrj90$ht,}\DataTypeTok{ref=}\StringTok{"3"}\NormalTok{)}
\NormalTok{pnadrj90$re<-}\KeywordTok{as.factor}\NormalTok{(pnadrj90$re)}
\NormalTok{pnadrj90$re<-}\KeywordTok{relevel}\NormalTok{(pnadrj90$re,}\DataTypeTok{ref=}\StringTok{"3"}\NormalTok{)}
\NormalTok{##transformar variável de resposta para 0,1:}
\NormalTok{pnadrj90$informal<-}\KeywordTok{ifelse}\NormalTok{(pnadrj90$informal==}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Cria objeto de desenho

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pnad.des<-}\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{id=}\NormalTok{~psu,}\DataTypeTok{strata=}\NormalTok{~stra,}\DataTypeTok{weights=}\NormalTok{~pesopes,}\DataTypeTok{data=}\NormalTok{pnadrj90,}\DataTypeTok{nest=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ajusta modelo de regressão logística na Tabela 6.2 Comparar resultado
com o da página 106 de Pessoa e Silva (1998)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inf.logit<-}\KeywordTok{svyglm}\NormalTok{(informal~sx+ae+ht+id+re+sx*id+sx*ht+ae*ht+ht*id+ht*re,}\DataTypeTok{design=}\NormalTok{pnad.des,}\DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: non-integer #successes in a binomial glm!
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(xtable)}
\KeywordTok{print}\NormalTok{(}\KeywordTok{xtable}\NormalTok{(inf.logit, }\DataTypeTok{digits=} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)),}\DataTypeTok{type=}\StringTok{"html"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Estimate

Std. Error

t value

Pr(\textgreater{}\textbar{}t\textbar{})

(Intercept)

-0.515

0.260

-1.98

0.048

sx1

0.148

0.222

0.67

0.506

ae1

0.745

0.165

4.53

0.000

ae2

0.496

0.156

3.18

0.002

ht1

-0.377

0.317

-1.19

0.236

ht2

-0.697

0.275

-2.53

0.012

id1

-0.239

0.540

-0.44

0.659

id2

-0.729

0.302

-2.41

0.016

id3

0.227

0.231

0.98

0.327

re1

0.286

0.277

1.03

0.302

re2

0.065

0.144

0.45

0.652

sx1:id1

0.878

0.348

2.52

0.012

sx1:id2

0.300

0.231

1.30

0.195

sx1:id3

-0.259

0.190

-1.36

0.173

sx1:ht1

-0.736

0.206

-3.57

0.000

sx1:ht2

-0.089

0.185

-0.48

0.631

ae1:ht1

0.792

0.240

3.29

0.001

ae2:ht1

0.739

0.227

3.26

0.001

ae1:ht2

0.026

0.197

0.13

0.895

ae2:ht2

0.089

0.183

0.49

0.626

ht1:id1

-1.420

0.605

-2.35

0.019

ht2:id1

-0.413

0.506

-0.82

0.414

ht1:id2

-0.124

0.355

-0.35

0.726

ht2:id2

-0.109

0.279

-0.39

0.696

ht1:id3

-0.220

0.248

-0.89

0.375

ht2:id3

-0.537

0.205

-2.62

0.009

ht1:re1

1.529

0.356

4.29

0.000

ht2:re1

0.338

0.320

1.06

0.292

ht1:re2

0.490

0.233

2.10

0.036

ht2:re2

-0.115

0.183

-0.63

0.530

Teste de Wald para a hipótese \(H_0: ht:re=0\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{regTermTest}\NormalTok{(inf.logit,}\StringTok{"ht:re"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Wald test for ht:re
##  in svyglm(formula = informal ~ sx + ae + ht + id + re + sx * id +
##     sx * ht + ae * ht + ht * id + ht * re, design = pnad.des,
##     family = binomial)
## F =  6.742662  on  4  and  616  df: p= 2.58e-05
\end{verbatim}

\chapter{Testes de Qualidade de
Ajuste}\label{testes-de-qualidade-de-ajuste}

\chapter{Testes em Tabelas de Duas
Entradas}\label{testes-em-tabelas-de-duas-entradas}

\chapter{Agregação vs.~Desagregação}\label{agregacao-vs.desagregacao}

\chapter{Pacotes para Analisar Dados
Amostrais}\label{pacotes-para-analisar-dados-amostrais}

\chapter{Placeholder}\label{placeholder}

\bibliography{packages,book}


\end{document}
